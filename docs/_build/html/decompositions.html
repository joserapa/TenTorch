
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Decompositions &#8212; TensorKrowch 1.1.5 documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="_static/tensorkrowch_favicon_light.svg"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Embeddings" href="embeddings.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/tensorkrowch_logo_light.svg" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Contents:
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="tutorials.html">
   Tutorials
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="tutorials/0_first_steps.html">
     First Steps with TensorKrowch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="tutorials/1_creating_tensor_network.html">
     Creating a Tensor Network in TensorKrowch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="tutorials/2_contracting_tensor_network.html">
     Contracting and Differentiating the Tensor Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="tutorials/3_memory_management.html">
     How to save Memory and Time with TensorKrowch (ADVANCED)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="tutorials/4_types_of_nodes.html">
     The different Types of Nodes (ADVANCED)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="tutorials/5_subclass_tensor_network.html">
     How to subclass TensorNetwork to build Custom Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="tutorials/6_mix_with_pytorch.html">
     Creating a Hybrid Neural-Tensor Network Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="examples.html">
   Examples
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="examples/training_mps.html">
     Training MPS in different ways
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="examples/hybrid_tnn_model.html">
     Hybrid Tensorial Neural Network model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="examples/tensorizing_nn.html">
     Tensorizing Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="examples/mps_dmrg.html">
     DMRG-like training of MPS
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="examples/mps_dmrg_hybrid.html">
     Hybrid DMRG-like training of MPS
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="api.html">
   API Reference
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="components.html">
     Components
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="operations.html">
     Operations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="models.html">
     Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="initializers.html">
     Initializers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="embeddings.html">
     Embeddings
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Decompositions
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/joserapa98/tensorkrowch"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/decompositions.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vec-to-mps">
   vec_to_mps
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mat-to-mpo">
   mat_to_mpo
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tt-rss">
   tt_rss
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Decompositions</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vec-to-mps">
   vec_to_mps
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mat-to-mpo">
   mat_to_mpo
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tt-rss">
   tt_rss
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="decompositions">
<h1>Decompositions<a class="headerlink" href="#decompositions" title="Permalink to this headline">#</a></h1>
<section id="vec-to-mps">
<h2>vec_to_mps<a class="headerlink" href="#vec-to-mps" title="Permalink to this headline">#</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="tensorkrowch.decompositions.vec_to_mps">
<span class="sig-prename descclassname"><span class="pre">tensorkrowch.decompositions.</span></span><span class="sig-name descname"><span class="pre">vec_to_mps</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vec</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_batches</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cum_percentage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cutoff</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">renormalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/decompositions/svd_decompositions.html#vec_to_mps"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.decompositions.vec_to_mps" title="Permalink to this definition">#</a></dt>
<dd><p>Splits a vector into a sequence of MPS tensors via consecutive SVD
decompositions. The resultant tensors can be used to instantiate a
<a class="reference internal" href="models.html#tensorkrowch.models.MPS" title="tensorkrowch.models.MPS"><code class="xref py py-class docutils literal notranslate"><span class="pre">MPS</span></code></a> with <code class="docutils literal notranslate"><span class="pre">boundary</span> <span class="pre">=</span> <span class="pre">&quot;obc&quot;</span></code>.</p>
<p>The number of resultant tensors and their respective physical dimensions
depend on the shape of the input vector. That is, if one expects to recover
a MPS with physical dimensions</p>
<div class="math notranslate nohighlight">
\[d_1 \times \cdots \times d_n\]</div>
<p>the input vector will have to be provided with that shape. This can be done
with <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.reshape.html">reshape</a>.</p>
<p>If the input vector has batch dimensions, having as shape</p>
<div class="math notranslate nohighlight">
\[b_1 \times \cdots \times b_m \times d_1 \times \cdots \times d_n\]</div>
<p>the number of batch dimensions <span class="math notranslate nohighlight">\(m\)</span> can be specified in <code class="docutils literal notranslate"><span class="pre">n_batches</span></code>.
In this case, the resultant tensors will all have the extra batch dimensions.
These tensors can be used to instantiate a <a class="reference internal" href="models.html#tensorkrowch.models.MPSData" title="tensorkrowch.models.MPSData"><code class="xref py py-class docutils literal notranslate"><span class="pre">MPSData</span></code></a>
with <code class="docutils literal notranslate"><span class="pre">boundary</span> <span class="pre">=</span> <span class="pre">&quot;obc&quot;</span></code>.</p>
<p>To specify the bond dimension of each cut done via SVD, one can use the
arguments <code class="docutils literal notranslate"><span class="pre">rank</span></code>, <code class="docutils literal notranslate"><span class="pre">cum_percentage</span></code> and <code class="docutils literal notranslate"><span class="pre">cutoff</span></code>. If more than
one is specified, the resulting rank will be the one that satisfies all
conditions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vec</strong> (<em>torch.Tensor</em>) – Input vector to decompose.</p></li>
<li><p><strong>n_batches</strong> (<em>int</em>) – Number of batch dimensions of the input vector. Each resultant tensor
will have also the corresponding batch dimensions. It should be between
0 and the rank of <code class="docutils literal notranslate"><span class="pre">vec</span></code>.</p></li>
<li><p><strong>rank</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of singular values to keep.</p></li>
<li><p><strong>cum_percentage</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>Proportion that should be satisfied between the sum of all singular
values kept and the total sum of all singular values.</p>
<div class="math notranslate nohighlight">
\[\frac{\sum_{i \in \{kept\}}{s_i}}{\sum_{i \in \{all\}}{s_i}} \ge
cum\_percentage\]</div>
</p></li>
<li><p><strong>cutoff</strong> (<em>float</em><em>, </em><em>optional</em>) – Quantity that lower bounds singular values in order to be kept.</p></li>
<li><p><strong>renormalize</strong> (<em>bool</em>) – Indicates whether nodes should be renormalized after SVD/QR
decompositions. If not, it may happen that the norm explodes as it
is being accumulated from all nodes. Renormalization aims to avoid
this undesired behavior by extracting the norm of each node on a
logarithmic scale after SVD/QR decompositions are computed. Finally,
the normalization factor is evenly distributed among all nodes of
the MPS.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>List[torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="mat-to-mpo">
<h2>mat_to_mpo<a class="headerlink" href="#mat-to-mpo" title="Permalink to this headline">#</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="tensorkrowch.decompositions.mat_to_mpo">
<span class="sig-prename descclassname"><span class="pre">tensorkrowch.decompositions.</span></span><span class="sig-name descname"><span class="pre">mat_to_mpo</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mat</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cum_percentage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cutoff</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">renormalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/decompositions/svd_decompositions.html#mat_to_mpo"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.decompositions.mat_to_mpo" title="Permalink to this definition">#</a></dt>
<dd><p>Splits a matrix into a sequence of MPO tensors via consecutive SVD
decompositions. The resultant tensors can be used to instantiate a
<a class="reference internal" href="models.html#tensorkrowch.models.MPO" title="tensorkrowch.models.MPO"><code class="xref py py-class docutils literal notranslate"><span class="pre">MPO</span></code></a> with <code class="docutils literal notranslate"><span class="pre">boundary</span> <span class="pre">=</span> <span class="pre">&quot;obc&quot;</span></code>.</p>
<p>The number of resultant tensors and their respective input/output dimensions
depend on the shape of the input matrix. That is, if one expects to recover
a MPO with input/output dimensions</p>
<div class="math notranslate nohighlight">
\[in_1 \times out_1 \times \cdots \times in_n \times out_n\]</div>
<p>the input matrix will have to be provided with that shape. Thus it must
have an even number of dimensions. To accomplish this, it may happen that
some input/output dimensions are 1. This can be done with
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.reshape.html">reshape</a>.</p>
<p>To specify the bond dimension of each cut done via SVD, one can use the
arguments <code class="docutils literal notranslate"><span class="pre">rank</span></code>, <code class="docutils literal notranslate"><span class="pre">cum_percentage</span></code> and <code class="docutils literal notranslate"><span class="pre">cutoff</span></code>. If more than
one is specified, the resulting rank will be the one that satisfies all
conditions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mat</strong> (<em>torch.Tensor</em>) – Input matrix to decompose. It must have an even number of dimensions.</p></li>
<li><p><strong>rank</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of singular values to keep.</p></li>
<li><p><strong>cum_percentage</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>Proportion that should be satisfied between the sum of all singular
values kept and the total sum of all singular values.</p>
<div class="math notranslate nohighlight">
\[\frac{\sum_{i \in \{kept\}}{s_i}}{\sum_{i \in \{all\}}{s_i}} \ge
cum\_percentage\]</div>
</p></li>
<li><p><strong>cutoff</strong> (<em>float</em><em>, </em><em>optional</em>) – Quantity that lower bounds singular values in order to be kept.</p></li>
<li><p><strong>renormalize</strong> (<em>bool</em>) – Indicates whether nodes should be renormalized after SVD/QR
decompositions. If not, it may happen that the norm explodes as it
is being accumulated from all nodes. Renormalization aims to avoid
this undesired behavior by extracting the norm of each node on a
logarithmic scale after SVD/QR decompositions are computed. Finally,
the normalization factor is evenly distributed among all nodes of
the MPS.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>List[torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="tt-rss">
<h2>tt_rss<a class="headerlink" href="#tt-rss" title="Permalink to this headline">#</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="tensorkrowch.decompositions.tt_rss">
<span class="sig-prename descclassname"><span class="pre">tensorkrowch.decompositions.</span></span><span class="sig-name descname"><span class="pre">tt_rss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sketch_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">domain</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">domain_multiplier</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_position</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cum_percentage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_info</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/decompositions/tt_decompositions.html#tt_rss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.decompositions.tt_rss" title="Permalink to this definition">#</a></dt>
<dd><p>Tensor Train - Recursive Sketching from Samples.</p>
<p>Decomposes a scalar or vector-valued function of <span class="math notranslate nohighlight">\(N\)</span> input variables
in a Matrix Product State of <span class="math notranslate nohighlight">\(N\)</span> cores, each corresponding to one
input variable, in the same order as they are provided to the function. To
turn each input variable into a vector that can be contracted with the
corresponding MPS core, an embedding function is required. The dimension of
the embedding will be used as the input dimension of the MPS.</p>
<p>If the function is vector-valued, it will be seen as a <span class="math notranslate nohighlight">\(N + 1\)</span> scalar
function, returning a MPS with <span class="math notranslate nohighlight">\(N + 1\)</span> cores. The output variable will
use the embedding <code class="xref py py-func docutils literal notranslate"><span class="pre">basis()</span></code>, which maps integers
(corresponding to indices of the output vector) to basis vectors:
<span class="math notranslate nohighlight">\(i \mapsto \langle i \rvert\)</span>. It can be specified the position in
which the output core will be. By default, it will be in the middle of the
MPS.</p>
<p>To specify the bond dimension of each MPS core, one can use the arguments
<code class="docutils literal notranslate"><span class="pre">rank</span></code> and <code class="docutils literal notranslate"><span class="pre">cum_percentage</span></code>. If more than one is specified, the
resulting rank will be the one that satisfies all conditions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>function</strong> (<em>Callable</em>) – Function that is going to be decomposed. It needs to have a single
input argument, the data, which is a tensor of shape
<code class="docutils literal notranslate"><span class="pre">batch_size</span> <span class="pre">x</span> <span class="pre">n_features</span></code> or <code class="docutils literal notranslate"><span class="pre">batch_size</span> <span class="pre">x</span> <span class="pre">n_features</span> <span class="pre">x</span> <span class="pre">in_dim</span></code>. It
must return a tensor of shape <code class="docutils literal notranslate"><span class="pre">batch_size</span> <span class="pre">x</span> <span class="pre">out_dim</span></code>. If the function
is scalar, <code class="docutils literal notranslate"><span class="pre">out_dim</span> <span class="pre">=</span> <span class="pre">1</span></code>.</p></li>
<li><p><strong>embedding</strong> (<em>Callable</em>) – Embedding function that maps the data tensor to a higher dimensional
space. It needs to have a single argument. It is a function that
transforms the given data tensor of shape <code class="docutils literal notranslate"><span class="pre">batch_size</span> <span class="pre">x</span> <span class="pre">n_features</span></code> or
<code class="docutils literal notranslate"><span class="pre">batch_size</span> <span class="pre">x</span> <span class="pre">n_features</span> <span class="pre">x</span> <span class="pre">in_dim</span></code> and returns an embedded tensor of
shape <code class="docutils literal notranslate"><span class="pre">batch_size</span> <span class="pre">x</span> <span class="pre">n_features</span> <span class="pre">x</span> <span class="pre">embed_dim</span></code>.</p></li>
<li><p><strong>sketch_samples</strong> (<em>torch.Tensor</em>) – Samples that will be used as sketches to decompose the function. It has
to be a tensor of shape <code class="docutils literal notranslate"><span class="pre">batch_size</span> <span class="pre">x</span> <span class="pre">n_features</span></code> or
<code class="docutils literal notranslate"><span class="pre">batch_size</span> <span class="pre">x</span> <span class="pre">n_features</span> <span class="pre">x</span> <span class="pre">in_dim</span></code>.</p></li>
<li><p><strong>labels</strong> (<em>torch.Tensor</em><em>, </em><em>optional</em>) – Tensor of output labels of the <code class="docutils literal notranslate"><span class="pre">function</span></code> with shape <code class="docutils literal notranslate"><span class="pre">batch_size</span></code>.
If <code class="docutils literal notranslate"><span class="pre">function</span></code> is vector-valued, <code class="docutils literal notranslate"><span class="pre">labels</span></code> will be used to select
an element from each output vector. If <code class="docutils literal notranslate"><span class="pre">labels</span></code> are not given, these
will be obtained according to the distribution represented by the output
vectors (assuming these represent square roots of probabilities for each
class).</p></li>
<li><p><strong>domain</strong> (<em>torch.Tensor</em><em> or </em><em>list</em><em>[</em><em>torch.Tensor</em><em>]</em><em>, </em><em>optional</em>) – Domain of the input variables. It should be given as a finite set of
possible values that can take each variable. If all variables live in
the same domain, it should be given as a tensor with shape <code class="docutils literal notranslate"><span class="pre">n_values</span></code>
or <code class="docutils literal notranslate"><span class="pre">n_values</span> <span class="pre">x</span> <span class="pre">in_dim</span></code>, where the possible <code class="docutils literal notranslate"><span class="pre">n_values</span></code> should be at
least as large as the desired input dimension of the MPS cores, which
is the <code class="docutils literal notranslate"><span class="pre">embed_dim</span></code> of the <code class="docutils literal notranslate"><span class="pre">embedding</span></code>. The more values are given,
the more accurate will be the tensorization but more costly will be to
do it. If <code class="docutils literal notranslate"><span class="pre">domain</span></code> is given as a list, it should have the same
number of elements as input variables, so that each variable can live
in a different domain. If <code class="docutils literal notranslate"><span class="pre">domain</span></code> is not given, it will be obtained
from the values each variable takes in the <code class="docutils literal notranslate"><span class="pre">sketch_samples</span></code>.</p></li>
<li><p><strong>domain_multiplier</strong> (<em>int</em>) – Upper bound for how many values are used for the input variable domain
if <code class="docutils literal notranslate"><span class="pre">domain</span></code> is not provided. If <code class="docutils literal notranslate"><span class="pre">domain</span></code> is not provided, the
domain of the input variables will be inferred from the unique values
each variable takes in the <code class="docutils literal notranslate"><span class="pre">sketch_samples</span></code>. In this case, only
<code class="docutils literal notranslate"><span class="pre">domain_multiplier</span> <span class="pre">*</span> <span class="pre">embed_dim</span></code> values will be taken randomly.</p></li>
<li><p><strong>out_position</strong> (<em>int</em><em>, </em><em>optional</em>) – If the <code class="docutils literal notranslate"><span class="pre">function</span></code> is vector-valued, position of the output core in
the resulting MPS.</p></li>
<li><p><strong>rank</strong> (<em>int</em><em>, </em><em>optional</em>) – Upper bound for the bond dimension of all cores.</p></li>
<li><p><strong>cum_percentage</strong> (<em>float</em><em>, </em><em>optional</em>) – When getting the proper bond dimension of each core via truncated SVD,
this is the proportion that should be satisfied between the sum of all
singular values kept and the total sum of all singular values. Therefore,
it specifies the rank of each core independently, allowing for
varying bond dimensions.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Batch size used to process <code class="docutils literal notranslate"><span class="pre">sketch_samples</span></code> with <code class="docutils literal notranslate"><span class="pre">DataLoaders</span></code>
during the decomposition.</p></li>
<li><p><strong>device</strong> (<em>torch.device</em><em>, </em><em>optional</em>) – Device to which <code class="docutils literal notranslate"><span class="pre">sketch_samples</span></code> will be sent to compute sketches. It
should coincide with the device the <code class="docutils literal notranslate"><span class="pre">function</span></code> is in, in the case the
function is a call to a <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> or uses tensors that are in a
specific device. This also applies to the <code class="docutils literal notranslate"><span class="pre">embedding</span></code> function.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) – Default is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
<li><p><strong>return_info</strong> (<em>bool</em>) – Boolean indicating if an additional dictionary with total time and
validation error should be returned.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>list[torch.Tensor]</em> – List of tensor cores of the MPS.</p></li>
<li><p><em>dictionary</em> – If <code class="docutils literal notranslate"><span class="pre">return_info</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="embeddings.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Embeddings</p>
        </div>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By José Ramón Pareja Monturiol<br/>
  
      &copy; Copyright 2023, José Ramón Pareja Monturiol.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>