
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Components &#8212; TensorKrowch 00.00.01 documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="_static/tensorkrowch_favicon_light.png"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Initializers" href="initializers.html" />
    <link rel="prev" title="API Reference" href="api.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/tensorkrowch_logo_light.png" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Contents:
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="tutorials.html">
   Tutorials
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="tutorials/basics.html">
     Basics
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="examples.html">
   Experiments
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="examples/jose_mps_mnist.html">
     MPS and Canonical Form - MNIST
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="examples/jose_mps_canonical_mnist.html">
     MPS and Canonical Form initializing also in canonical form - MNIST
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="examples/jose_mps_fashion_mnist.html">
     MPS and Canonical Form - FashionMNIST
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="examples/cirac_snake_sbs_fashion_mnist.html">
     SnakeSBS - FashionMNIST
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="examples/cirac_cnn_snake_sbs_fashion_mnist.html">
     CNN-SnakeSBS - FashionMNIST
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="examples/jose_convmps_fashion_mnist.html">
     ConvMPS - FashionMNIST
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="examples/jose_convtree_fashion_mnist.html">
     ConvTree - FashionMNIST
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="examples/miles_mps_dmrg_mnist.html">
     MPS with DMRG - MNIST
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="examples/jose_mps_mnist_binarized.html">
     MPS - MNIST Binarized
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="api.html">
   API Reference
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Components
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="initializers.html">
     Initializers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="embeddings.html">
     Embeddings
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="operations.html">
     Operations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="models.html">
     Models
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/joserapa98/tensorkrowch"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/components.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#axis">
   Axis
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nodes">
   Nodes
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#abstractnode">
     AbstractNode
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#node">
     Node
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#paramnode">
     ParamNode
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stacknode">
     StackNode
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#paramstacknode">
     ParamStackNode
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#edges">
   Edges
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#edge">
     Edge
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stackedge">
     StackEdge
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#successor">
   Successor
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tensor-network">
   Tensor Network
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Components</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#axis">
   Axis
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nodes">
   Nodes
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#abstractnode">
     AbstractNode
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#node">
     Node
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#paramnode">
     ParamNode
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stacknode">
     StackNode
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#paramstacknode">
     ParamStackNode
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#edges">
   Edges
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#edge">
     Edge
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stackedge">
     StackEdge
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#successor">
   Successor
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tensor-network">
   Tensor Network
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="components">
<h1>Components<a class="headerlink" href="#components" title="Permalink to this headline">#</a></h1>
<section id="axis">
<h2>Axis<a class="headerlink" href="#axis" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tensorkrowch.Axis">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tensorkrowch.</span></span><span class="sig-name descname"><span class="pre">Axis</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#Axis"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.Axis" title="Permalink to this definition">#</a></dt>
<dd><p>Axes are the objects that stick edges to nodes. Each instance of the
<a class="reference internal" href="#tensorkrowch.AbstractNode" title="tensorkrowch.AbstractNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractNode</span></code></a> class has a list of <span class="math notranslate nohighlight">\(N\)</span> axes, each corresponding
to one edge. Each axis stores information that facilitates accessing that
edge, such as its <a class="reference internal" href="#tensorkrowch.Axis.name" title="tensorkrowch.Axis.name"><code class="xref py py-attr docutils literal notranslate"><span class="pre">name</span></code></a> and <a class="reference internal" href="#tensorkrowch.Axis.num" title="tensorkrowch.Axis.num"><code class="xref py py-attr docutils literal notranslate"><span class="pre">num</span></code></a> (index). Additionally, an axis
keeps track of its <a class="reference internal" href="#tensorkrowch.Axis.is_batch" title="tensorkrowch.Axis.is_batch"><code class="xref py py-meth docutils literal notranslate"><span class="pre">batch</span></code></a> and <a class="reference internal" href="#tensorkrowch.Axis.is_node1" title="tensorkrowch.Axis.is_node1"><code class="xref py py-meth docutils literal notranslate"><span class="pre">node1</span></code></a>
attributes.</p>
<ul>
<li><p><strong>batch</strong>: If the axis name contains the word “<cite>batch</cite>”, the edge will be
a batch edge, which means that it cannot be connected to other nodes.
Instead, it specifies a dimension that allows for batch operations (e.g.,
batch contraction). If the name of the axis is changed and no longer contains
the word “<cite>batch</cite>”, the corresponding edge will no longer be a batch edge.
Furthermore, instances of the <a class="reference internal" href="#tensorkrowch.StackNode" title="tensorkrowch.StackNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">StackNode</span></code></a> and <a class="reference internal" href="#tensorkrowch.ParamStackNode" title="tensorkrowch.ParamStackNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParamStackNode</span></code></a>
classes always have an axis with name “<cite>stack</cite>” whose edge is a batch edge.</p></li>
<li><p><strong>node1</strong>: When two dangling edges are connected the result is a new
edge linking two nodes, say <code class="docutils literal notranslate"><span class="pre">nodeA</span></code> and <code class="docutils literal notranslate"><span class="pre">nodeB</span></code>. If the
connection is performed in the following order:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">new_edge</span> <span class="o">=</span> <span class="n">nodeA</span><span class="p">[</span><span class="n">edgeA</span><span class="p">]</span> <span class="o">^</span> <span class="n">nodeB</span><span class="p">[</span><span class="n">edgeB</span><span class="p">]</span>
</pre></div>
</div>
<p>Then <code class="docutils literal notranslate"><span class="pre">nodeA</span></code> will be the <code class="docutils literal notranslate"><span class="pre">node1</span></code> of <code class="docutils literal notranslate"><span class="pre">new_edge</span></code> and <code class="docutils literal notranslate"><span class="pre">nodeB</span></code>, the
<code class="docutils literal notranslate"><span class="pre">node2</span></code>. Hence, to access one of the nodes from <code class="docutils literal notranslate"><span class="pre">new_edge</span></code> one needs
to know if it is <code class="docutils literal notranslate"><span class="pre">node1</span></code> or <code class="docutils literal notranslate"><span class="pre">node2</span></code>.</p>
</li>
</ul>
<p>Even though we can create <code class="docutils literal notranslate"><span class="pre">Axis</span></code> instances, that will not be usually the
case, since axes are automatically created when instantiating a new
<a class="reference internal" href="#tensorkrowch.AbstractNode" title="tensorkrowch.AbstractNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">node</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num</strong> (<em>int</em>) – Index of the axis in the node’s axes list.</p></li>
<li><p><strong>name</strong> (<em>str</em>) – Axis name, should not contain blank spaces or special characters. If it
contains the word “<cite>batch</cite>”, the axis will correspond to a batch edge.
The word “<cite>stack</cite>” cannot be used in the name, since it is reserved for
stacks.</p></li>
<li><p><strong>node</strong> (<a class="reference internal" href="#tensorkrowch.AbstractNode" title="tensorkrowch.AbstractNode"><em>AbstractNode</em></a><em>, </em><em>optional</em>) – Node to which the axis belongs.</p></li>
<li><p><strong>node1</strong> (<em>bool</em>) – Boolean indicating whether <code class="docutils literal notranslate"><span class="pre">node1</span></code> of the edge attached to this axis
is the node that contains the axis (<code class="docutils literal notranslate"><span class="pre">True</span></code>). Otherwise, the node is
<code class="docutils literal notranslate"><span class="pre">node2</span></code> of the edge (<code class="docutils literal notranslate"><span class="pre">False</span></code>).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Although Axis will not be usually explicitly instantiated, it can be done
like so:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">axis</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">Axis</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;left&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">axis</span>
<span class="go">Axis( left (0) )</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">axis</span><span class="o">.</span><span class="n">is_node1</span><span class="p">()</span>
<span class="go">True</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">axis</span><span class="o">.</span><span class="n">is_batch</span><span class="p">()</span>
<span class="go">False</span>
</pre></div>
</div>
<p>Since “<cite>batch</cite>” is not contained in “<cite>left</cite>”, <code class="docutils literal notranslate"><span class="pre">axis</span></code> does not correspond
to a batch edge, but that can be changed:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">axis</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;mybatch&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">axis</span><span class="o">.</span><span class="n">is_batch</span><span class="p">()</span>
<span class="go">True</span>
</pre></div>
</div>
<p>Also, as explained before, knowing if a node is the <code class="docutils literal notranslate"><span class="pre">node1</span></code> or <code class="docutils literal notranslate"><span class="pre">node2</span></code>
of an edge enables users to access that node from the edge:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">nodeA</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_edge</span> <span class="o">=</span> <span class="n">nodeA</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">nodeB</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># nodeA is node1 and nodeB is node2 of new_edge</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeA</span> <span class="o">==</span> <span class="n">new_edge</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="mi">1</span> <span class="o">-</span> <span class="n">nodeA</span><span class="o">.</span><span class="n">get_axis</span><span class="p">(</span><span class="s1">&#39;right&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">is_node1</span><span class="p">()]</span>
<span class="go">True</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span> <span class="o">==</span> <span class="n">new_edge</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">nodeA</span><span class="o">.</span><span class="n">get_axis</span><span class="p">(</span><span class="s1">&#39;right&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">is_node1</span><span class="p">()]</span>
<span class="go">True</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">node1</span></code> attribute is extended to <code class="docutils literal notranslate"><span class="pre">resultant</span></code> nodes that inherit
edges.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">nodeA</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeC</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">edge1</span> <span class="o">=</span> <span class="n">nodeA</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">nodeB</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">edge2</span> <span class="o">=</span> <span class="n">nodeB</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">nodeC</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">nodeA</span> <span class="o">@</span> <span class="n">nodeB</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># result inherits the edges nodeA[&#39;left&#39;] and edge2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">nodeA</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span>
<span class="go">True</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">edge2</span>
<span class="go">True</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># result is still node1 of edge2, since nodeA was</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span><span class="o">.</span><span class="n">is_node1</span><span class="p">(</span><span class="s1">&#39;right&#39;</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.Axis.num">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">num</span></span><a class="headerlink" href="#tensorkrowch.Axis.num" title="Permalink to this definition">#</a></dt>
<dd><p>Index in the node’s axes list.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.Axis.name">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#tensorkrowch.Axis.name" title="Permalink to this definition">#</a></dt>
<dd><p>Axis name, used to access edges by name of the axis. It cannot contain
blank spaces or special characters. If it contains the word “<cite>batch</cite>”,
the axis will correspond to a batch edge. The word “<cite>stack</cite>” cannot be
used in the name, since it is reserved for stacks.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.Axis.node">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">node</span></span><a class="headerlink" href="#tensorkrowch.Axis.node" title="Permalink to this definition">#</a></dt>
<dd><p>Node to which the axis belongs.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.Axis.is_node1">
<span class="sig-name descname"><span class="pre">is_node1</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#Axis.is_node1"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.Axis.is_node1" title="Permalink to this definition">#</a></dt>
<dd><p>Returns boolean indicating whether <code class="docutils literal notranslate"><span class="pre">node1</span></code> of the edge attached to this
axis is the node that contains the axis. Otherwise, the node is <code class="docutils literal notranslate"><span class="pre">node2</span></code>
of the edge.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.Axis.is_batch">
<span class="sig-name descname"><span class="pre">is_batch</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#Axis.is_batch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.Axis.is_batch" title="Permalink to this definition">#</a></dt>
<dd><p>Returns boolean indicating whether the edge in this axis is used as a
batch edge.</p>
</dd></dl>

</dd></dl>

</section>
<section id="nodes">
<h2>Nodes<a class="headerlink" href="#nodes" title="Permalink to this headline">#</a></h2>
<section id="abstractnode">
<h3>AbstractNode<a class="headerlink" href="#abstractnode" title="Permalink to this headline">#</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tensorkrowch.</span></span><span class="sig-name descname"><span class="pre">AbstractNode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">network</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">virtual</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">override_node</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">edges</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">override_edges</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node1_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode" title="Permalink to this definition">#</a></dt>
<dd><p>Abstract class for all types of nodes. Defines what a node is and most of its
properties and methods. Since it is an abstract class, cannot be instantiated.</p>
<p>Nodes are the elements that make up a <a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a>. At its most
basic level, a node is a container for a <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code> that stores other
relevant information which enables to build any network and operate nodes
to contract it (and train it!). Some of the information that is carried by
the nodes includes:</p>
<ul class="simple">
<li><p><strong>Shape</strong>: Every node needs a shape to know if connections with other
nodes are possible. Even if the tensor is not specified, an empty node
needs a shape.</p></li>
<li><p><strong>Tensor</strong>: The key ingredient of the node. Although the node acts as a
<cite>container</cite> for the tensor, the node does not <cite>contain</cite> it. Actually,
for efficiency purposes, the tensors are stored in a sort of memory that
is shared by all the nodes of the <a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a>. Therefore, all
that nodes <cite>contain</cite> is a memory address. Furthermore, some nodes can share
the same (or a part of the same) tensor, thus containing the same address.
Sometimes, to maintain consistency, when two nodes share a tensor, one
stores its memory address, and the other one stores a reference to the
former.</p></li>
<li><p><strong>Axes</strong>: A list of <a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code></a> that make it easy to access edges
just using a name or an index.</p></li>
<li><p><strong>Edges</strong>: A list of <a class="reference internal" href="#tensorkrowch.Edge" title="tensorkrowch.Edge"><code class="xref py py-class docutils literal notranslate"><span class="pre">Edges</span></code></a>, one for each dimension of the
node. Each edge is attached to the node via an <a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axis</span></code></a>. Edges are
useful to connect several nodes, creating a <a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a>.</p></li>
<li><p><strong>Network</strong>: The <a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a> to which the node belongs. If
the network is not specified when creating the node, a new <code class="docutils literal notranslate"><span class="pre">TensorNetwork</span></code>
is created to contain the node. Although the network can be thought of
as a graph, it is a <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>, so it is much more than that.
Actually, the <code class="docutils literal notranslate"><span class="pre">TensorNetwork</span></code> can contain different types of nodes,
not all of them being part of the graph, but being used for different
purposes.</p></li>
<li><p><strong>Successors</strong>: A dictionary with information about the nodes that result
from <a class="reference internal" href="operations.html#tensorkrowch.Operation" title="tensorkrowch.Operation"><code class="xref py py-class docutils literal notranslate"><span class="pre">Operations</span></code></a> in which the current node was involved.
See <a class="reference internal" href="#tensorkrowch.Successor" title="tensorkrowch.Successor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Successor</span></code></a>.</p></li>
</ul>
<p>Carrying this information with the node is what makes it easy to:</p>
<ul class="simple">
<li><p>Perform tensor network <a class="reference internal" href="operations.html#tensorkrowch.Operation" title="tensorkrowch.Operation"><code class="xref py py-class docutils literal notranslate"><span class="pre">Operations</span></code></a> such as <a class="reference internal" href="operations.html#tensorkrowch.contract_between" title="tensorkrowch.contract_between"><code class="xref py py-func docutils literal notranslate"><span class="pre">contraction</span></code></a> of two neighbouring nodes, without having to worry about
tensor’s shapes, order of axes, etc.</p></li>
<li><p>Perform more advanced operations such as <a class="reference internal" href="operations.html#tensorkrowch.stack" title="tensorkrowch.stack"><code class="xref py py-func docutils literal notranslate"><span class="pre">stack()</span></code></a> or <a class="reference internal" href="operations.html#tensorkrowch.unbind" title="tensorkrowch.unbind"><code class="xref py py-func docutils literal notranslate"><span class="pre">unbind()</span></code></a>
saving memory and time.</p></li>
<li><p>Keep track of operations in which a node has taken place, so that several
steps can be skipped in further training iterations.
See <a class="reference internal" href="#tensorkrowch.TensorNetwork.trace" title="tensorkrowch.TensorNetwork.trace"><code class="xref py py-meth docutils literal notranslate"><span class="pre">TensorNetwork.trace()</span></code></a>.</p></li>
</ul>
<p>Also, there are <strong>4 excluding types</strong> of nodes that will have different
roles in the <a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a>:</p>
<ul class="simple">
<li><p><strong>leaf</strong>: These are the nodes that form the <a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a>
(together with the <code class="docutils literal notranslate"><span class="pre">data</span></code> nodes). Usually, these will be the <cite>trainable</cite>
nodes. These nodes can store their own tensors or use other node’s tensor.</p></li>
<li><p><strong>data</strong>: These are similar to <code class="docutils literal notranslate"><span class="pre">leaf</span></code> nodes, but they are never <cite>trainable</cite>,
and are used to store the temporary tensors coming from input data. These
nodes can store their own tensors or use other node’s tensor.</p></li>
<li><p><strong>virtual</strong>: These nodes are a sort of ancillary, <cite>hidden</cite> nodes that
accomplish some useful task (e.g. in uniform tensor networks a virtual
node can store the shared tensor, while all the other nodes in the
network just have a reference to it). These nodes always store their own
tensors.</p></li>
<li><p><strong>resultant</strong>: These are nodes that result from an <a class="reference internal" href="operations.html#tensorkrowch.Operation" title="tensorkrowch.Operation"><code class="xref py py-class docutils literal notranslate"><span class="pre">Operation</span></code></a>.
They are intermediate nodes that (almost always) inherit edges from <code class="docutils literal notranslate"><span class="pre">leaf</span></code>
and <code class="docutils literal notranslate"><span class="pre">data</span></code> nodes, the ones that really form the network. These nodes can
store their own tensors or use other node’s tensor.</p></li>
</ul>
<p>See <a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a> to learn more about the importance of these 4
types of nodes.</p>
<p>Refer to the subclasses of <code class="docutils literal notranslate"><span class="pre">AbstractNode</span></code> to see how to instantiate nodes:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node"><code class="xref py py-class docutils literal notranslate"><span class="pre">Node</span></code></a></p></li>
<li><p><a class="reference internal" href="#tensorkrowch.ParamNode" title="tensorkrowch.ParamNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParamNode</span></code></a></p></li>
<li><p><a class="reference internal" href="#tensorkrowch.StackNode" title="tensorkrowch.StackNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">StackNode</span></code></a></p></li>
<li><p><a class="reference internal" href="#tensorkrowch.ParamStackNode" title="tensorkrowch.ParamStackNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParamStackNode</span></code></a></p></li>
</ul>
<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.tensor">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">tensor</span></span><a class="headerlink" href="#tensorkrowch.AbstractNode.tensor" title="Permalink to this definition">#</a></dt>
<dd><p>Node’s tensor. It can be a <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.nn.Parameter</span></code> or
<code class="docutils literal notranslate"><span class="pre">None</span></code> if the node is empty.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#tensorkrowch.AbstractNode.shape" title="Permalink to this definition">#</a></dt>
<dd><p>Shape of node’s <a class="reference internal" href="#tensorkrowch.AbstractNode.tensor" title="tensorkrowch.AbstractNode.tensor"><code class="xref py py-attr docutils literal notranslate"><span class="pre">tensor</span></code></a>. It is of type <code class="docutils literal notranslate"><span class="pre">torch.Size</span></code>.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.rank">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">rank</span></span><a class="headerlink" href="#tensorkrowch.AbstractNode.rank" title="Permalink to this definition">#</a></dt>
<dd><p>Length of node’s <a class="reference internal" href="#tensorkrowch.AbstractNode.shape" title="tensorkrowch.AbstractNode.shape"><code class="xref py py-attr docutils literal notranslate"><span class="pre">shape</span></code></a>, that is, number of edges of the node.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.dtype">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dtype</span></span><a class="headerlink" href="#tensorkrowch.AbstractNode.dtype" title="Permalink to this definition">#</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">torch.dtype</span></code> of node’s <a class="reference internal" href="#tensorkrowch.AbstractNode.tensor" title="tensorkrowch.AbstractNode.tensor"><code class="xref py py-attr docutils literal notranslate"><span class="pre">tensor</span></code></a>.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.device">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#tensorkrowch.AbstractNode.device" title="Permalink to this definition">#</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">torch.device</span></code> of node’s <a class="reference internal" href="#tensorkrowch.AbstractNode.tensor" title="tensorkrowch.AbstractNode.tensor"><code class="xref py py-attr docutils literal notranslate"><span class="pre">tensor</span></code></a>.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.axes">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">axes</span></span><a class="headerlink" href="#tensorkrowch.AbstractNode.axes" title="Permalink to this definition">#</a></dt>
<dd><p>List of nodes’s <a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><code class="xref py py-class docutils literal notranslate"><span class="pre">axes</span></code></a>.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.axes_names">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">axes_names</span></span><a class="headerlink" href="#tensorkrowch.AbstractNode.axes_names" title="Permalink to this definition">#</a></dt>
<dd><p>List of names of node’s <a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><code class="xref py py-class docutils literal notranslate"><span class="pre">axes</span></code></a>.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.edges">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">edges</span></span><a class="headerlink" href="#tensorkrowch.AbstractNode.edges" title="Permalink to this definition">#</a></dt>
<dd><p>List of node’s <a class="reference internal" href="#tensorkrowch.Edge" title="tensorkrowch.Edge"><code class="xref py py-class docutils literal notranslate"><span class="pre">edges</span></code></a>.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.network">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">network</span></span><a class="headerlink" href="#tensorkrowch.AbstractNode.network" title="Permalink to this definition">#</a></dt>
<dd><p><a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a> where the node belongs. If the node is moved to
another <a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a>, the entire connected component of the
graph where the node is will be moved.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.successors">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">successors</span></span><a class="headerlink" href="#tensorkrowch.AbstractNode.successors" title="Permalink to this definition">#</a></dt>
<dd><p>Dictionary with <a class="reference internal" href="operations.html#tensorkrowch.Operation" title="tensorkrowch.Operation"><code class="xref py py-class docutils literal notranslate"><span class="pre">Operations</span></code></a>’ names as keys, and the
list of <a class="reference internal" href="#tensorkrowch.Successor" title="tensorkrowch.Successor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Successors</span></code></a> of the node as values.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.name">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#tensorkrowch.AbstractNode.name" title="Permalink to this definition">#</a></dt>
<dd><p>Node’s name, used to access the node from the <a class="reference internal" href="#tensorkrowch.AbstractNode.network" title="tensorkrowch.AbstractNode.network"><code class="xref py py-attr docutils literal notranslate"><span class="pre">tensor</span> <span class="pre">network</span></code></a>
where it belongs. It cannot contain blank spaces.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.is_leaf">
<span class="sig-name descname"><span class="pre">is_leaf</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.is_leaf"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.is_leaf" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a boolean indicating if the node is a <code class="docutils literal notranslate"><span class="pre">leaf</span></code> node. These are
the nodes that form the <a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a> (together with the
<code class="docutils literal notranslate"><span class="pre">data</span></code> nodes). Usually, these will be the <cite>trainable</cite> nodes. These
nodes can store their own tensors or use other node’s tensor.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.is_data">
<span class="sig-name descname"><span class="pre">is_data</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.is_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.is_data" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a boolean indicating if the node is a <code class="docutils literal notranslate"><span class="pre">data</span></code> node. These nodes
are similar to <code class="docutils literal notranslate"><span class="pre">leaf</span></code> nodes, but they are never <cite>trainable</cite>, and are
used to store the temporary tensors coming from input data. These nodes
can store their own tensors or use other node’s tensor.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.is_virtual">
<span class="sig-name descname"><span class="pre">is_virtual</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.is_virtual"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.is_virtual" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a boolean indicating if the node is a <code class="docutils literal notranslate"><span class="pre">virtual</span></code> node. These
nodes are a sort of ancillary, <cite>hidden</cite> nodes that accomplish some useful
task (e.g. in uniform tensor networks a virtual node can store the shared
tensor, while all the other nodes in the network just have a reference
to it). These nodes always store their own tensors.</p>
<p>If a <code class="docutils literal notranslate"><span class="pre">virtual</span></code> node is used as the node storing the shared tensor in
a uniform (translationally invariant) <a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a>, it is
recommended to use the string <strong>“virtual_uniform”</strong> in the node’s name
(e.g. “virtual_uniform_mps”).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.is_resultant">
<span class="sig-name descname"><span class="pre">is_resultant</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.is_resultant"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.is_resultant" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a boolean indicating if the node is a <code class="docutils literal notranslate"><span class="pre">resultant</span></code> node. These
are nodes that result from an <a class="reference internal" href="operations.html#tensorkrowch.Operation" title="tensorkrowch.Operation"><code class="xref py py-class docutils literal notranslate"><span class="pre">Operation</span></code></a>. They are intermediate
nodes that (almost always) inherit edges from <code class="docutils literal notranslate"><span class="pre">leaf</span></code> and <code class="docutils literal notranslate"><span class="pre">data</span></code>
nodes, the ones that really form the network. These nodes can store
their own tensors or use other node’s tensor.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.size">
<span class="sig-name descname"><span class="pre">size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.size" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the size of the node’s tensor. If <code class="docutils literal notranslate"><span class="pre">axis</span></code> is specified, returns
the size of that axis; otherwise returns the shape of the node (same as
<a class="reference internal" href="#tensorkrowch.AbstractNode.shape" title="tensorkrowch.AbstractNode.shape"><code class="xref py py-attr docutils literal notranslate"><span class="pre">shape</span></code></a>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> (<em>int</em><em>, </em><em>str</em><em> or </em><a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><em>Axis</em></a><em>, </em><em>optional</em>) – Axis for which to retrieve the size.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>int or torch.Size</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.is_node1">
<span class="sig-name descname"><span class="pre">is_node1</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.is_node1"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.is_node1" title="Permalink to this definition">#</a></dt>
<dd><p>Returns <a class="reference internal" href="#tensorkrowch.Axis.is_node1" title="tensorkrowch.Axis.is_node1"><code class="xref py py-meth docutils literal notranslate"><span class="pre">node1</span></code></a> attribute of axes of the node. If
<code class="docutils literal notranslate"><span class="pre">axis</span></code> is specified, returns only the <code class="docutils literal notranslate"><span class="pre">node1</span></code> of that axis; otherwise
returns the <code class="docutils literal notranslate"><span class="pre">node1</span></code> of all axes of the node.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> (<em>int</em><em>, </em><em>str</em><em> or </em><a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><em>Axis</em></a><em>, </em><em>optional</em>) – Axis for which to retrieve the <code class="docutils literal notranslate"><span class="pre">node1</span></code>.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>bool or list[bool]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.neighbours">
<span class="sig-name descname"><span class="pre">neighbours</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.neighbours"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.neighbours" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the neighbours of the node, the nodes to which it is connected.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> (<em>int</em><em>, </em><em>str</em><em> or </em><a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><em>Axis</em></a><em>, </em><em>optional</em>) – Axis for which to retrieve the neighbour.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#tensorkrowch.AbstractNode" title="tensorkrowch.AbstractNode">AbstractNode</a> or list[<a class="reference internal" href="#tensorkrowch.AbstractNode" title="tensorkrowch.AbstractNode">AbstractNode</a>]</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">nodeA</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeC</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">nodeA</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">nodeB</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">nodeB</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">nodeC</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">set</span><span class="p">(</span><span class="n">nodeB</span><span class="o">.</span><span class="n">neighbours</span><span class="p">())</span> <span class="o">==</span> <span class="nb">set</span><span class="p">([</span><span class="n">nodeA</span><span class="p">,</span> <span class="n">nodeC</span><span class="p">])</span>
<span class="go">True</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span><span class="o">.</span><span class="n">neighbours</span><span class="p">(</span><span class="s1">&#39;right&#39;</span><span class="p">)</span> <span class="o">==</span> <span class="n">nodeC</span>
<span class="go">True</span>
</pre></div>
</div>
<p>Nodes <code class="docutils literal notranslate"><span class="pre">resultant</span></code> from operations are still connected to original
neighbours.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">nodeA</span> <span class="o">@</span> <span class="n">nodeB</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span><span class="o">.</span><span class="n">neighbours</span><span class="p">(</span><span class="s1">&#39;right&#39;</span><span class="p">)</span> <span class="o">==</span> <span class="n">nodeC</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.get_axis">
<span class="sig-name descname"><span class="pre">get_axis</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.get_axis"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.get_axis" title="Permalink to this definition">#</a></dt>
<dd><p>Returns <a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axis</span></code></a> given its <code class="docutils literal notranslate"><span class="pre">name</span></code> or <code class="docutils literal notranslate"><span class="pre">num</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.get_axis_num">
<span class="sig-name descname"><span class="pre">get_axis_num</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.get_axis_num"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.get_axis_num" title="Permalink to this definition">#</a></dt>
<dd><p>Returns axis’ <code class="docutils literal notranslate"><span class="pre">num</span></code> given the <a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axis</span></code></a> or its <code class="docutils literal notranslate"><span class="pre">name</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.get_edge">
<span class="sig-name descname"><span class="pre">get_edge</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.get_edge"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.get_edge" title="Permalink to this definition">#</a></dt>
<dd><p>Returns <a class="reference internal" href="#tensorkrowch.Edge" title="tensorkrowch.Edge"><code class="xref py py-class docutils literal notranslate"><span class="pre">Edge</span></code></a> given the <a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axis</span></code></a> (or its <code class="docutils literal notranslate"><span class="pre">name</span></code>
or <code class="docutils literal notranslate"><span class="pre">num</span></code>) where it is attached to the node.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.in_which_axis">
<span class="sig-name descname"><span class="pre">in_which_axis</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">edge</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.in_which_axis"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.in_which_axis" title="Permalink to this definition">#</a></dt>
<dd><p>Returns <a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axis</span></code></a> given the <a class="reference internal" href="#tensorkrowch.Edge" title="tensorkrowch.Edge"><code class="xref py py-class docutils literal notranslate"><span class="pre">Edge</span></code></a> that is attached
to the node through it.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.reattach_edges">
<span class="sig-name descname"><span class="pre">reattach_edges</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">override</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.reattach_edges"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.reattach_edges" title="Permalink to this definition">#</a></dt>
<dd><p>Substitutes current edges by copies of them that are attached to the node.
It can happen that an edge is not attached to the node if it is the result
of an <a class="reference internal" href="operations.html#tensorkrowch.Operation" title="tensorkrowch.Operation"><code class="xref py py-class docutils literal notranslate"><span class="pre">Operation</span></code></a> and, hence, it inherits edges from the operands.
In that case, the new copied edges will be attached to the resultant node,
replacing each previous <code class="docutils literal notranslate"><span class="pre">node1</span></code> or <code class="docutils literal notranslate"><span class="pre">node2</span></code> with it (according to the
<code class="docutils literal notranslate"><span class="pre">node1</span></code> attribute of each axis).</p>
<p>Used for in-place operations like <a class="reference internal" href="operations.html#tensorkrowch.permute_" title="tensorkrowch.permute_"><code class="xref py py-func docutils literal notranslate"><span class="pre">permute_()</span></code></a> or <a class="reference internal" href="operations.html#tensorkrowch.split_" title="tensorkrowch.split_"><code class="xref py py-func docutils literal notranslate"><span class="pre">split_()</span></code></a> and
to (de)parameterize nodes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>override</strong> (<em>bool</em>) – Boolean indicating if the new, reattached edges should also replace
the corresponding edges in the node’s neighbours (<code class="docutils literal notranslate"><span class="pre">True</span></code>). Otherwise,
the neighbours’ edges will be pointing to the original nodes from which
the current node inherits its edges (<code class="docutils literal notranslate"><span class="pre">False</span></code>).</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">nodeA</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeC</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">nodeA</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">nodeB</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">nodeB</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">nodeC</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">nodeA</span> <span class="o">@</span> <span class="n">nodeB</span>
</pre></div>
</div>
<p>Node <code class="docutils literal notranslate"><span class="pre">result</span></code> inherits its <code class="docutils literal notranslate"><span class="pre">right</span></code> edge from <code class="docutils literal notranslate"><span class="pre">nodeB</span></code>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">nodeB</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span>
<span class="go">True</span>
</pre></div>
</div>
<p>However, <code class="docutils literal notranslate"><span class="pre">nodeB['right']</span></code> still connects <code class="docutils literal notranslate"><span class="pre">nodeB</span></code> and <code class="docutils literal notranslate"><span class="pre">nodeC</span></code>.
There is no reference to <code class="docutils literal notranslate"><span class="pre">result</span></code>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">nodes</span>
<span class="go">False</span>
</pre></div>
</div>
<p>One can reattach its edges so that <code class="docutils literal notranslate"><span class="pre">result</span></code>’s edges do have references
to it.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">result</span><span class="o">.</span><span class="n">reattach_edges</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">nodes</span>
<span class="go">True</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">override</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, <code class="docutils literal notranslate"><span class="pre">nodeB['right']</span></code> would be replaced by the
new <code class="docutils literal notranslate"><span class="pre">result['right']</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.disconnect">
<span class="sig-name descname"><span class="pre">disconnect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.disconnect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.disconnect" title="Permalink to this definition">#</a></dt>
<dd><p>Disconnects all edges of the node if they were connected to other nodes.
If <code class="docutils literal notranslate"><span class="pre">axis</span></code> is sepcified, only the corresponding edge is disconnected.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> (<em>int</em><em>, </em><em>str</em><em> or </em><a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><em>Axis</em></a><em>, </em><em>optional</em>) – Axis whose edge will be disconnected.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">nodeA</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeC</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">nodeA</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">nodeB</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">nodeB</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">nodeC</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">set</span><span class="p">(</span><span class="n">nodeB</span><span class="o">.</span><span class="n">neighbours</span><span class="p">())</span> <span class="o">==</span> <span class="nb">set</span><span class="p">([</span><span class="n">nodeA</span><span class="p">,</span> <span class="n">nodeC</span><span class="p">])</span>
<span class="go">True</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span><span class="o">.</span><span class="n">disconnect</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span><span class="o">.</span><span class="n">neighbours</span><span class="p">()</span> <span class="o">==</span> <span class="p">[]</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.make_tensor">
<span class="sig-name descname"><span class="pre">make_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'zeros'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">device(type='cpu')</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.make_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.make_tensor" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a tensor that can be put in the node, and is initialized according
to <code class="docutils literal notranslate"><span class="pre">init_method</span></code>. By default, it has the same shape as the node.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> (<em>list</em><em>[</em><em>int</em><em>]</em><em>, </em><em>tuple</em><em>[</em><em>int</em><em>] or </em><em>torch.Size</em><em>, </em><em>optional</em>) – Shape of the tensor. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, node’s shape will be used.</p></li>
<li><p><strong>init_method</strong> (<em>{&quot;zeros&quot;</em><em>, </em><em>&quot;ones&quot;</em><em>, </em><em>&quot;copy&quot;</em><em>, </em><em>&quot;rand&quot;</em><em>, </em><em>&quot;randn&quot;}</em><em>, </em><em>optional</em>) – Initialization method.</p></li>
<li><p><strong>device</strong> (<em>torch.device</em><em>, </em><em>optional</em>) – Device where to initialize the tensor.</p></li>
<li><p><strong>kwargs</strong> (<em>float</em>) – <p>Keyword arguments for the different initialization methods:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">low</span></code>, <code class="docutils literal notranslate"><span class="pre">high</span></code> for uniform initialization. See
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.rand.html">torch.rand()</a></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mean</span></code>, <code class="docutils literal notranslate"><span class="pre">std</span></code> for normal initialization. See
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.randn.html">torch.randn()</a></p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>ValueError</strong> – If <code class="docutils literal notranslate"><span class="pre">init_method</span></code> is not one of “zeros”, “ones”, “copy”, “rand”, “randn”.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.set_tensor">
<span class="sig-name descname"><span class="pre">set_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'zeros'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.set_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.set_tensor" title="Permalink to this definition">#</a></dt>
<dd><p>Sets new node’s tensor or creates one with <a class="reference internal" href="#tensorkrowch.AbstractNode.make_tensor" title="tensorkrowch.AbstractNode.make_tensor"><code class="xref py py-meth docutils literal notranslate"><span class="pre">make_tensor()</span></code></a> and sets
it. Before setting it, it is casted to the correct type: <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>
for <a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node"><code class="xref py py-class docutils literal notranslate"><span class="pre">Node</span></code></a> and <code class="docutils literal notranslate"><span class="pre">torch.nn.Parameter</span></code> for <a class="reference internal" href="#tensorkrowch.ParamNode" title="tensorkrowch.ParamNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParamNode</span></code></a>.</p>
<p>When a tensor is <strong>set</strong> in the node, it means the node stores it, that
is, the node has its own memory address for its tensor, rather than a
reference to other node’s tensor. Because of this, <code class="docutils literal notranslate"><span class="pre">set_tensor</span></code> cannot
be applied for nodes that have a reference to other node’s tensor, since
that tensor would be changed also in the referenced node. To overcome
this issue, see <a class="reference internal" href="#tensorkrowch.AbstractNode.reset_tensor_address" title="tensorkrowch.AbstractNode.reset_tensor_address"><code class="xref py py-meth docutils literal notranslate"><span class="pre">reset_tensor_address()</span></code></a>.</p>
<p>This can only be used for <strong>non</strong> <code class="docutils literal notranslate"><span class="pre">resultant``nodes</span> <span class="pre">that</span> <span class="pre">store</span> <span class="pre">their</span>
<span class="pre">own</span> <span class="pre">tensors.</span> <span class="pre">For</span> <span class="pre">``resultant</span></code> nodes, tensors are set automatically when
computing <a class="reference internal" href="operations.html#tensorkrowch.Operation" title="tensorkrowch.Operation"><code class="xref py py-class docutils literal notranslate"><span class="pre">Operations</span></code></a>.</p>
<p>Although this can also be used for <code class="docutils literal notranslate"><span class="pre">data</span></code> nodes, input data will be
usually automatically set into nodes when calling the <a class="reference internal" href="#tensorkrowch.TensorNetwork.forward" title="tensorkrowch.TensorNetwork.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">TensorNetwork.forward()</span></code></a>
method of <a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a> with a data tensor or a sequence of
tensors. This method calls <a class="reference internal" href="#tensorkrowch.TensorNetwork.add_data" title="tensorkrowch.TensorNetwork.add_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">TensorNetwork.add_data()</span></code></a>, which can
also be used to set data tensors into the <code class="docutils literal notranslate"><span class="pre">data</span></code> nodes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> (<em>torch.Tensor</em><em>, </em><em>optional</em>) – Tensor to be set in the node. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, and <code class="docutils literal notranslate"><span class="pre">init_method</span></code> is
provided, the tensor is created with <a class="reference internal" href="#tensorkrowch.AbstractNode.make_tensor" title="tensorkrowch.AbstractNode.make_tensor"><code class="xref py py-meth docutils literal notranslate"><span class="pre">make_tensor()</span></code></a>. Otherwise,
a <code class="docutils literal notranslate"><span class="pre">None</span></code> is set as node’s tensor.</p></li>
<li><p><strong>init_method</strong> (<em>{&quot;zeros&quot;</em><em>, </em><em>&quot;ones&quot;</em><em>, </em><em>&quot;copy&quot;</em><em>, </em><em>&quot;rand&quot;</em><em>, </em><em>&quot;randn&quot;}</em><em>, </em><em>optional</em>) – Initialization method.</p></li>
<li><p><strong>device</strong> (<em>torch.device</em><em>, </em><em>optional</em>) – Device where to initialize the tensor.</p></li>
<li><p><strong>kwargs</strong> (<em>float</em>) – Keyword arguments for the different initialization methods. See
<a class="reference internal" href="#tensorkrowch.AbstractNode.make_tensor" title="tensorkrowch.AbstractNode.make_tensor"><code class="xref py py-meth docutils literal notranslate"><span class="pre">make_tensor()</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the node is a <code class="docutils literal notranslate"><span class="pre">resultant</span></code> node or if it does not store its own
    tensor.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">node</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Call set_tensor without arguments uses the</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># default init_method (&quot;zeros&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">node</span><span class="o">.</span><span class="n">set_tensor</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="go">True</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">node</span><span class="o">.</span><span class="n">set_tensor</span><span class="p">(</span><span class="n">init_method</span><span class="o">=</span><span class="s1">&#39;randn&#39;</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">2.</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">))</span>
<span class="go">False</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">node</span><span class="o">.</span><span class="n">device</span>
<span class="go">device(type=&#39;cuda&#39;, index=0)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">node</span><span class="o">.</span><span class="n">set_tensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.unset_tensor">
<span class="sig-name descname"><span class="pre">unset_tensor</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.unset_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.unset_tensor" title="Permalink to this definition">#</a></dt>
<dd><p>Replaces node’s tensor with <code class="docutils literal notranslate"><span class="pre">None</span></code>. This can only be used for <strong>non</strong>
<code class="docutils literal notranslate"><span class="pre">resultant</span></code> nodes that store their own tensors.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">node</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span> <span class="ow">is</span> <span class="kc">None</span>
<span class="go">False</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">node</span><span class="o">.</span><span class="n">unset_tensor</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span> <span class="ow">is</span> <span class="kc">None</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.set_tensor_from">
<span class="sig-name descname"><span class="pre">set_tensor_from</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.set_tensor_from"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.set_tensor_from" title="Permalink to this definition">#</a></dt>
<dd><p>Sets node’s tensor as the tensor used by <code class="docutils literal notranslate"><span class="pre">other</span></code> node. That is, when
setting the tensor this way, the current node will store a reference to
the <code class="docutils literal notranslate"><span class="pre">other</span></code> node’s tensor, instead of having its own tensor.</p>
<p>The node and <code class="docutils literal notranslate"><span class="pre">other</span></code> should be both the same type (<a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node"><code class="xref py py-class docutils literal notranslate"><span class="pre">Node</span></code></a> or
<a class="reference internal" href="#tensorkrowch.ParamNode" title="tensorkrowch.ParamNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParamNode</span></code></a>). Also, they should be in the same <a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>other</strong> (<a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node"><em>Node</em></a><em> or </em><a class="reference internal" href="#tensorkrowch.ParamNode" title="tensorkrowch.ParamNode"><em>ParamNode</em></a>) – Node whose tensor is to be set in current node.</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>TypeError</strong> – If <code class="docutils literal notranslate"><span class="pre">other</span></code> is a different type than the current node, or if it is
    in a different network.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">nodeA</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
<span class="gp">... </span>                 <span class="n">name</span><span class="o">=</span><span class="s1">&#39;nodeA&#39;</span><span class="p">,</span>
<span class="gp">... </span>                 <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
<span class="gp">... </span>                 <span class="n">name</span><span class="o">=</span><span class="s1">&#39;nodeB&#39;</span><span class="p">,</span>
<span class="gp">... </span>                 <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">),</span>
<span class="gp">... </span>                 <span class="n">network</span><span class="o">=</span><span class="n">nodeA</span><span class="o">.</span><span class="n">network</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span><span class="o">.</span><span class="n">set_tensor_from</span><span class="p">(</span><span class="n">nodeA</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span><span class="o">.</span><span class="n">tensor_address</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;nodeA&#39;</span>
<span class="go">True</span>
</pre></div>
</div>
<p>Since <code class="docutils literal notranslate"><span class="pre">nodeB</span></code> has a reference to <code class="docutils literal notranslate"><span class="pre">nodeA</span></code>’s tensor, if this one is
changed, <code class="docutils literal notranslate"><span class="pre">nodeB</span></code> will reproduce all the changes.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">nodeA</span><span class="o">.</span><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nodeA</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">nodeA</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">nodeB</span><span class="o">.</span><span class="n">tensor</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.tensor_address">
<span class="sig-name descname"><span class="pre">tensor_address</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.tensor_address"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.tensor_address" title="Permalink to this definition">#</a></dt>
<dd><p>Returns address of the node’s tensor in the network’s memory.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.reset_tensor_address">
<span class="sig-name descname"><span class="pre">reset_tensor_address</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.reset_tensor_address"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.reset_tensor_address" title="Permalink to this definition">#</a></dt>
<dd><p>Resets memory address of node’s tensor to reference the node itself.
Thus the node will store its own tensor, instead of having a reference
to other node’s tensor.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">nodeA</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
<span class="gp">... </span>                 <span class="n">name</span><span class="o">=</span><span class="s1">&#39;nodeA&#39;</span><span class="p">,</span>
<span class="gp">... </span>                 <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
<span class="gp">... </span>                 <span class="n">name</span><span class="o">=</span><span class="s1">&#39;nodeB&#39;</span><span class="p">,</span>
<span class="gp">... </span>                 <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">),</span>
<span class="gp">... </span>                 <span class="n">network</span><span class="o">=</span><span class="n">nodeA</span><span class="o">.</span><span class="n">network</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span><span class="o">.</span><span class="n">set_tensor_from</span><span class="p">(</span><span class="n">nodeA</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span><span class="o">.</span><span class="n">tensor_address</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;nodeA&#39;</span>
<span class="go">True</span>
</pre></div>
</div>
<p>Now one cannot set in <code class="docutils literal notranslate"><span class="pre">nodeB</span></code> a different tensor from the one in
<code class="docutils literal notranslate"><span class="pre">nodeA</span></code>, unless tensor address is reset in <code class="docutils literal notranslate"><span class="pre">nodeB</span></code>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span><span class="o">.</span><span class="n">reset_tensor_address</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span><span class="o">.</span><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nodeB</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">nodeA</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">nodeB</span><span class="o">.</span><span class="n">tensor</span><span class="p">)</span>
<span class="go">False</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.move_to_network">
<span class="sig-name descname"><span class="pre">move_to_network</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visited</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.move_to_network"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.move_to_network" title="Permalink to this definition">#</a></dt>
<dd><p>Moves node to another network. All other nodes connected to it, or
to a node connected to it, etc. are also moved to the new network.</p>
<p>If a node does not store its own tensor, and is moved to other network,
it will recover the “ownership” of its tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>network</strong> (<a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><em>TensorNetwork</em></a>) – Tensor Network to which the nodes will be moved.</p></li>
<li><p><strong>visited</strong> (<em>list</em><em>[</em><a class="reference internal" href="#tensorkrowch.AbstractNode" title="tensorkrowch.AbstractNode"><em>AbstractNode</em></a><em>]</em><em>, </em><em>optional</em>) – List indicating the nodes that have been already moved to the new
network, used by this DFS-like algorithm.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">TensorNetwork</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeA</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
<span class="gp">... </span>                <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">),</span>
<span class="gp">... </span>                <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
<span class="gp">... </span>                <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">),</span>
<span class="gp">... </span>                <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeC</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
<span class="gp">... </span>                <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">),</span>
<span class="gp">... </span>                <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">nodeA</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">nodeB</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">nodeA</span></code> is moved to other network, <code class="docutils literal notranslate"><span class="pre">nodeB</span></code> will also move, but
<code class="docutils literal notranslate"><span class="pre">nodeC</span></code> will not.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">net2</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">TensorNetwork</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeA</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">net2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeA</span><span class="o">.</span><span class="n">network</span> <span class="o">==</span> <span class="n">nodeB</span><span class="o">.</span><span class="n">network</span>
<span class="go">True</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">nodeA</span><span class="o">.</span><span class="n">network</span> <span class="o">!=</span> <span class="n">nodeC</span><span class="o">.</span><span class="n">network</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.sum">
<span class="sig-name descname"><span class="pre">sum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.sum"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.sum" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the sum of all elements in the node’s tensor. If an <code class="docutils literal notranslate"><span class="pre">axis</span></code> is
specified, the sum is over that axis. If <code class="docutils literal notranslate"><span class="pre">axis</span></code> is a sequence of axes,
reduce over all of them.</p>
<p>This is not a node <a class="reference internal" href="operations.html#tensorkrowch.Operation" title="tensorkrowch.Operation"><code class="xref py py-class docutils literal notranslate"><span class="pre">Operation</span></code></a>, hence it returns a <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>
instead of a <a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node"><code class="xref py py-class docutils literal notranslate"><span class="pre">Node</span></code></a>.</p>
<p>See also <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.sum.html">torch.sum()</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> (<em>int</em><em>, </em><em>str</em><em>, </em><a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><em>Axis</em></a><em> or </em><em>list</em><em>[</em><em>int</em><em>, </em><em>str</em><em> or </em><a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><em>Axis</em></a><em>]</em><em>, </em><em>optional</em>) – Axis or sequence of axes over which to reduce.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">node</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span>
<span class="go">tensor([[-0.2799, -0.4383, -0.8387],</span>
<span class="go">        [ 1.6225, -0.3370, -1.2316]])</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">node</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="go">tensor(-1.5029)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">node</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
<span class="go">tensor([ 1.3427, -0.7752, -2.0704])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.mean">
<span class="sig-name descname"><span class="pre">mean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.mean"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.mean" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the mean of all elements in the node’s tensor. If an <code class="docutils literal notranslate"><span class="pre">axis</span></code> is
specified, the mean is over that axis. If <code class="docutils literal notranslate"><span class="pre">axis</span></code> is a sequence of axes,
reduce over all of them.</p>
<p>This is not a node <a class="reference internal" href="operations.html#tensorkrowch.Operation" title="tensorkrowch.Operation"><code class="xref py py-class docutils literal notranslate"><span class="pre">Operation</span></code></a>, hence it returns a <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>
instead of a <a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node"><code class="xref py py-class docutils literal notranslate"><span class="pre">Node</span></code></a>.</p>
<p>See also <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.mean.html">torch.mean()</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> (<em>int</em><em>, </em><em>str</em><em>, </em><a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><em>Axis</em></a><em> or </em><em>list</em><em>[</em><em>int</em><em>, </em><em>str</em><em> or </em><a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><em>Axis</em></a><em>]</em><em>, </em><em>optional</em>) – Axis or sequence of axes over which to reduce.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">node</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span>
<span class="go">tensor([[ 1.4005, -0.0521, -1.2091],</span>
<span class="go">        [ 1.9844,  0.3513, -0.5920]])</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">node</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="go">tensor(0.3139)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">node</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
<span class="go">tensor([ 1.6925,  0.1496, -0.9006])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.std">
<span class="sig-name descname"><span class="pre">std</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.std"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.std" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the std of all elements in the node’s tensor. If an <code class="docutils literal notranslate"><span class="pre">axis</span></code> is
specified, the std is over that axis. If <code class="docutils literal notranslate"><span class="pre">axis</span></code> is a sequence of axes,
reduce over all of them.</p>
<p>This is not a node <a class="reference internal" href="operations.html#tensorkrowch.Operation" title="tensorkrowch.Operation"><code class="xref py py-class docutils literal notranslate"><span class="pre">Operation</span></code></a>, hence it returns a <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>
instead of a <a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node"><code class="xref py py-class docutils literal notranslate"><span class="pre">Node</span></code></a>.</p>
<p>See also <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.std.html">torch.std()</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axis</strong> (<em>int</em><em>, </em><em>str</em><em>, </em><a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><em>Axis</em></a><em> or </em><em>list</em><em>[</em><em>int</em><em>, </em><em>str</em><em> or </em><a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><em>Axis</em></a><em>]</em><em>, </em><em>optional</em>) – Axis or sequence of axes over which to reduce.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">node</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span>
<span class="go">tensor([[ 0.2111, -0.9551, -0.7812],</span>
<span class="go">        [ 0.2254,  0.3381, -0.2461]])</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">node</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="go">tensor(0.5567)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">node</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
<span class="go">tensor([0.0101, 0.9145, 0.3784])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.norm">
<span class="sig-name descname"><span class="pre">norm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#AbstractNode.norm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.AbstractNode.norm" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the norm of all elements in the node’s tensor. If an <code class="docutils literal notranslate"><span class="pre">axis</span></code> is
specified, the norm is over that axis. If <code class="docutils literal notranslate"><span class="pre">axis</span></code> is a sequence of axes,
reduce over all of them.</p>
<p>This is not a node <a class="reference internal" href="operations.html#tensorkrowch.Operation" title="tensorkrowch.Operation"><code class="xref py py-class docutils literal notranslate"><span class="pre">Operation</span></code></a>, hence it returns a <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>
instead of a <a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node"><code class="xref py py-class docutils literal notranslate"><span class="pre">Node</span></code></a>.</p>
<p>See also <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.norm.html">torch.norm()</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<em>int</em><em>, </em><em>float</em>) – The order of the norm.</p></li>
<li><p><strong>axis</strong> (<em>int</em><em>, </em><em>str</em><em>, </em><a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><em>Axis</em></a><em> or </em><em>list</em><em>[</em><em>int</em><em>, </em><em>str</em><em> or </em><a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><em>Axis</em></a><em>]</em><em>, </em><em>optional</em>) – Axis or sequence of axes over which to reduce.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">node</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span>
<span class="go">tensor([[ 1.5570,  1.8441, -0.0743],</span>
<span class="go">        [ 0.4572,  0.7592,  0.6356]])</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">node</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span>
<span class="go">tensor(2.6495)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">node</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
<span class="go">tensor([1.6227, 1.9942, 0.6399])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.contract_between">
<span class="sig-name descname"><span class="pre">contract_between</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tensorkrowch.AbstractNode.contract_between" title="Permalink to this definition">#</a></dt>
<dd><p>Contracts all edges shared between two nodes. Batch contraction is
automatically performed when both nodes have batch edges with the same
names. It can also be performed using the operator <code class="docutils literal notranslate"><span class="pre">&#64;</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>node2</strong> (<a class="reference internal" href="#tensorkrowch.AbstractNode" title="tensorkrowch.AbstractNode"><em>AbstractNode</em></a>) – Second node of the contraction. Its non-contracted edges will appear
last in the list of inherited edges of the resultant node.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node">Node</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.contract_between_">
<span class="sig-name descname"><span class="pre">contract_between_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tensorkrowch.AbstractNode.contract_between_" title="Permalink to this definition">#</a></dt>
<dd><p>In-place version of <a class="reference internal" href="#tensorkrowch.AbstractNode.contract_between" title="tensorkrowch.AbstractNode.contract_between"><code class="xref py py-func docutils literal notranslate"><span class="pre">contract_between()</span></code></a>.</p>
<p>Following the <strong>PyTorch</strong> convention, names of functions ended with an
underscore indicate <strong>in-place</strong> operations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>node2</strong> (<a class="reference internal" href="#tensorkrowch.AbstractNode" title="tensorkrowch.AbstractNode"><em>AbstractNode</em></a>) – Second node of the contraction. Its non-contracted edges will appear
last in the list of inherited edges of the resultant node.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node">Node</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.permute">
<span class="sig-name descname"><span class="pre">permute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axes</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tensorkrowch.AbstractNode.permute" title="Permalink to this definition">#</a></dt>
<dd><p>Permutes the nodes’ tensor, as well as its axes and edges to match the new
shape.</p>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.permute.html">permute</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axes</strong> (<em>list</em><em>[</em><em>int</em><em>, </em><em>str</em><em> or </em><a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><em>Axis</em></a><em>]</em>) – List of axes in the permuted order.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.permute_">
<span class="sig-name descname"><span class="pre">permute_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axes</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tensorkrowch.AbstractNode.permute_" title="Permalink to this definition">#</a></dt>
<dd><p>Permutes the nodes’ tensor, as well as its axes and edges to match the new
shape (in-place).</p>
<p>Following the <strong>PyTorch</strong> convention, names of functions ended with an
underscore indicate <strong>in-place</strong> operations.</p>
<p>See <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.permute.html">permute</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>axes</strong> (<em>list</em><em>[</em><em>int</em><em>, </em><em>str</em><em> or </em><a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><em>Axis</em></a><em>]</em>) – List of axes in the permuted order.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.split">
<span class="sig-name descname"><span class="pre">split</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node1_axes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node2_axes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'svd'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">side</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'left'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cum_percentage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cutoff</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tensorkrowch.AbstractNode.split" title="Permalink to this definition">#</a></dt>
<dd><p>Splits one node in two via the decomposition specified in <code class="docutils literal notranslate"><span class="pre">mode</span></code>. See
<a class="reference internal" href="operations.html#tensorkrowch.split" title="tensorkrowch.split"><code class="xref py py-func docutils literal notranslate"><span class="pre">split()</span></code></a> for a more complete explanation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>node1_axes</strong> (<em>list</em><em>[</em><em>int</em><em>, </em><em>str</em><em> or </em><a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><em>Axis</em></a><em>]</em>) – First set of edges, will appear as the edges of the first (left)
resultant node.</p></li>
<li><p><strong>node2_axes</strong> (<em>list</em><em>[</em><em>int</em><em>, </em><em>str</em><em> or </em><a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><em>Axis</em></a><em>]</em>) – Second set of edges, will appear as the edges of the second (right)
resultant node.</p></li>
<li><p><strong>mode</strong> (<em>{&quot;svd&quot;</em><em>, </em><em>&quot;svdr&quot;</em><em>, </em><em>&quot;qr&quot;</em><em>, </em><em>&quot;rq&quot;}</em>) – Decomposition to be used.</p></li>
<li><p><strong>side</strong> (<em>str</em><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">mode</span></code> is “svd” or “svdr”, indicates the side to which the diagonal
matrix <span class="math notranslate nohighlight">\(S\)</span> should be contracted. If “left”, the first resultant
node’s tensor will be <span class="math notranslate nohighlight">\(US\)</span>, and the other node’s tensor will be
<span class="math notranslate nohighlight">\(V^{\dagger}\)</span>. If “right”, their tensors will be <span class="math notranslate nohighlight">\(U\)</span> and
<span class="math notranslate nohighlight">\(SV^{\dagger}\)</span>, respectively.</p></li>
<li><p><strong>rank</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of singular values to keep.</p></li>
<li><p><strong>cum_percentage</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>Proportion that should be satisfied between the sum of all singular
values kept and the total sum of all singular values.</p>
<div class="math notranslate nohighlight">
\[\frac{\sum_{i \in \{kept\}}{s_i}}{\sum_{i \in \{all\}}{s_i}} \ge
cum\_percentage\]</div>
</p></li>
<li><p><strong>cutoff</strong> (<em>float</em><em>, </em><em>optional</em>) – Quantity that lower bounds singular values in order to be kept.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>tuple[<a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node">Node</a>, <a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node">Node</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.AbstractNode.split_">
<span class="sig-name descname"><span class="pre">split_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node1_axes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node2_axes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'svd'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">side</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'left'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cum_percentage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cutoff</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tensorkrowch.AbstractNode.split_" title="Permalink to this definition">#</a></dt>
<dd><p>In-place version of <a class="reference internal" href="#tensorkrowch.AbstractNode.split" title="tensorkrowch.AbstractNode.split"><code class="xref py py-func docutils literal notranslate"><span class="pre">split()</span></code></a>.</p>
<p>Following the <strong>PyTorch</strong> convention, names of functions ended with an
underscore indicate <strong>in-place</strong> operations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>node1_axes</strong> (<em>list</em><em>[</em><em>int</em><em>, </em><em>str</em><em> or </em><a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><em>Axis</em></a><em>]</em>) – First set of edges, will appear as the edges of the first (left)
resultant node.</p></li>
<li><p><strong>node2_axes</strong> (<em>list</em><em>[</em><em>int</em><em>, </em><em>str</em><em> or </em><a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><em>Axis</em></a><em>]</em>) – Second set of edges, will appear as the edges of the second (right)
resultant node.</p></li>
<li><p><strong>mode</strong> (<em>{&quot;svd&quot;</em><em>, </em><em>&quot;svdr&quot;</em><em>, </em><em>&quot;qr&quot;</em><em>, </em><em>&quot;rq&quot;}</em>) – Decomposition to be used.</p></li>
<li><p><strong>side</strong> (<em>str</em><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">mode</span></code> is “svd” or “svdr”, indicates the side to which the diagonal
matrix <span class="math notranslate nohighlight">\(S\)</span> should be contracted. If “left”, the first resultant
node’s tensor will be <span class="math notranslate nohighlight">\(US\)</span>, and the other node’s tensor will be
<span class="math notranslate nohighlight">\(V^{\dagger}\)</span>. If “right”, their tensors will be <span class="math notranslate nohighlight">\(U\)</span> and
<span class="math notranslate nohighlight">\(SV^{\dagger}\)</span>, respectively.</p></li>
<li><p><strong>rank</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of singular values to keep.</p></li>
<li><p><strong>cum_percentage</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>Proportion that should be satisfied between the sum of all singular
values kept and the total sum of all singular values.</p>
<div class="math notranslate nohighlight">
\[\frac{\sum_{i \in \{kept\}}{s_i}}{\sum_{i \in \{all\}}{s_i}} \ge
cum\_percentage\]</div>
</p></li>
<li><p><strong>cutoff</strong> (<em>float</em><em>, </em><em>optional</em>) – Quantity that lower bounds singular values in order to be kept.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>tuple[<a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node">Node</a>, <a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node">Node</a>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="node">
<h3>Node<a class="headerlink" href="#node" title="Permalink to this headline">#</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="tensorkrowch.Node">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tensorkrowch.</span></span><span class="sig-name descname"><span class="pre">Node</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">network</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">virtual</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">override_node</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">edges</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">override_edges</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node1_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#Node"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.Node" title="Permalink to this definition">#</a></dt>
<dd><p>Base class for non-trainable nodes. Should be subclassed by any class of nodes
that are not intended to be trained (e.g. <a class="reference internal" href="#tensorkrowch.StackNode" title="tensorkrowch.StackNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">StackNode</span></code></a>).</p>
<p>Can be used for fixed nodes of the <a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a>, or intermediate
nodes that are resultant from an <a class="reference internal" href="operations.html#tensorkrowch.Operation" title="tensorkrowch.Operation"><code class="xref py py-class docutils literal notranslate"><span class="pre">Operation</span></code></a> between nodes.</p>
<p>All <strong>4 types of nodes</strong> (<code class="docutils literal notranslate"><span class="pre">leaf</span></code>, <code class="docutils literal notranslate"><span class="pre">data</span></code>, <code class="docutils literal notranslate"><span class="pre">virtual</span></code> and <code class="docutils literal notranslate"><span class="pre">resultant</span></code>)
can be <code class="docutils literal notranslate"><span class="pre">Node</span></code>. In fact, <code class="docutils literal notranslate"><span class="pre">data</span></code> and <code class="docutils literal notranslate"><span class="pre">resultant</span></code> nodes can <strong>only</strong> be
of class <code class="docutils literal notranslate"><span class="pre">Node</span></code>, since they are not intended to be trainable. To learn
more about these 4 types of nodes, see <a class="reference internal" href="#tensorkrowch.AbstractNode" title="tensorkrowch.AbstractNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractNode</span></code></a>.</p>
<p>For a complete list of properties and methods, see also <a class="reference internal" href="#tensorkrowch.AbstractNode" title="tensorkrowch.AbstractNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractNode</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> (<em>list</em><em>[</em><em>int</em><em>]</em><em>, </em><em>tuple</em><em>[</em><em>int</em><em>]</em><em>, </em><em>torch.Size</em><em>, </em><em>optional</em>) – Node’s shape, that is, the shape of its tensor. If <code class="docutils literal notranslate"><span class="pre">shape</span></code> and
<code class="docutils literal notranslate"><span class="pre">init_method</span></code> are provided, a tensor will be made for the node. Otherwise,
<code class="docutils literal notranslate"><span class="pre">tensor</span></code> would be required.</p></li>
<li><p><strong>axes_names</strong> (<em>list</em><em>[</em><em>str</em><em>]</em><em>, </em><em>tuple</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – Sequence of names for each of the node’s axes. Names are used to access
the edge that is attached to the node in a certain axis. Hence they should
be all distinct. They cannot contain blank spaces or special characters.
By default, axes names will be <code class="docutils literal notranslate"><span class="pre">&quot;axis_0&quot;</span></code>, …, <code class="docutils literal notranslate"><span class="pre">&quot;axis_n&quot;</span></code>, being
<code class="docutils literal notranslate"><span class="pre">n</span></code> the nummber of axes.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – Node’s name, used to access the node from de <a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a> where
it belongs. It cannot contain blank spaces. By default, it is the name
of the class (e.g. <code class="docutils literal notranslate"><span class="pre">&quot;node&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;paramnode&quot;</span></code>).</p></li>
<li><p><strong>network</strong> (<a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><em>TensorNetwork</em></a><em>, </em><em>optional</em>) – Tensor network where the node should belong. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, a new tensor
network will be created to contain the node.</p></li>
<li><p><strong>data</strong> (<em>bool</em>) – Boolean indicating if the node is a <code class="docutils literal notranslate"><span class="pre">data</span></code> node.</p></li>
<li><p><strong>virtual</strong> (<em>bool</em>) – Boolean indicating if the node is a <code class="docutils literal notranslate"><span class="pre">virtual</span></code> node.</p></li>
<li><p><strong>override_node</strong> (<em>bool</em>) – Boolean indicating whether the node should override (<code class="docutils literal notranslate"><span class="pre">True</span></code>) another
node in the network that has the same name (e.g. if a node is parameterized,
it would be required that a new <a class="reference internal" href="#tensorkrowch.ParamNode" title="tensorkrowch.ParamNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParamNode</span></code></a> replaces the
non-parameterized node in the network).</p></li>
<li><p><strong>tensor</strong> (<em>torch.Tensor</em><em>, </em><em>optional</em>) – Tensor that is to be stored in the node. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, <code class="docutils literal notranslate"><span class="pre">shape</span></code> and
<code class="docutils literal notranslate"><span class="pre">init_method</span></code> will be required.</p></li>
<li><p><strong>edges</strong> (<em>list</em><em>[</em><a class="reference internal" href="#tensorkrowch.Edge" title="tensorkrowch.Edge"><em>Edge</em></a><em>]</em><em>, </em><em>optional</em>) – List of edges that are to be attached to the node. This can be used in
case the node inherits the edges from other node(s), like results from
<a class="reference internal" href="operations.html#tensorkrowch.Operation" title="tensorkrowch.Operation"><code class="xref py py-class docutils literal notranslate"><span class="pre">Operations</span></code></a>.</p></li>
<li><p><strong>override_edges</strong> (<em>bool</em>) – Boolean indicating whether the provided <code class="docutils literal notranslate"><span class="pre">edges</span></code> should be overriden
(<code class="docutils literal notranslate"><span class="pre">True</span></code>) when reattached (e.g. if a node is parameterized, it would
be required that the new <a class="reference internal" href="#tensorkrowch.ParamNode" title="tensorkrowch.ParamNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParamNode</span></code></a>’s edges are indeed connected
to it, instead of to the original non-parameterized node).</p></li>
<li><p><strong>node1_list</strong> (<em>list</em><em>[</em><em>bool</em><em>]</em><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">edges</span></code> are provided, the list of <code class="docutils literal notranslate"><span class="pre">node1</span></code> attributes of each edge
should also be provided.</p></li>
<li><p><strong>init_method</strong> (<em>{&quot;zeros&quot;</em><em>, </em><em>&quot;ones&quot;</em><em>, </em><em>&quot;copy&quot;</em><em>, </em><em>&quot;rand&quot;</em><em>, </em><em>&quot;randn&quot;}</em><em>, </em><em>optional</em>) – Initialization method.</p></li>
<li><p><strong>device</strong> (<em>torch.device</em><em>, </em><em>optional</em>) – Device where to initialize the tensor if <code class="docutils literal notranslate"><span class="pre">init_method</span></code> is provided.</p></li>
<li><p><strong>kwargs</strong> (<em>float</em>) – Keyword arguments for the different initialization methods. See
<a class="reference internal" href="#tensorkrowch.AbstractNode.make_tensor" title="tensorkrowch.AbstractNode.make_tensor"><code class="xref py py-meth docutils literal notranslate"><span class="pre">AbstractNode.make_tensor()</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">node</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<span class="gp">... </span>               <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">),</span>
<span class="gp">... </span>               <span class="n">name</span><span class="o">=</span><span class="s1">&#39;my_node&#39;</span><span class="p">,</span>
<span class="gp">... </span>               <span class="n">init_method</span><span class="o">=</span><span class="s1">&#39;randn&#39;</span><span class="p">,</span>
<span class="gp">... </span>               <span class="n">mean</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span>
<span class="gp">... </span>               <span class="n">std</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
</pre></div>
</div>
<p>Also, one can use one of the <a class="reference internal" href="initializers.html#initializers"><span class="std std-ref">Initializers</span></a> to simplify:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">node</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.Node.parameterize">
<span class="sig-name descname"><span class="pre">parameterize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">set_param</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#Node.parameterize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.Node.parameterize" title="Permalink to this definition">#</a></dt>
<dd><p>Replaces the node with a parameterized version of it, that is, turns a
fixed <a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node"><code class="xref py py-class docutils literal notranslate"><span class="pre">Node</span></code></a> into a trainable <a class="reference internal" href="#tensorkrowch.ParamNode" title="tensorkrowch.ParamNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParamNode</span></code></a>.</p>
<p>Since the node is <strong>replaced</strong>, it will be completely removed from the
network, and its neighbours will point to the new parameterized node.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>set_param</strong> (<em>bool</em>) – Boolean indicating whether the node should be parameterized (<code class="docutils literal notranslate"><span class="pre">True</span></code>).
Otherwise (<code class="docutils literal notranslate"><span class="pre">False</span></code>), the non-parameterized node itself will be
returned.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The original node or a parameterized version of it.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node">Node</a> or <a class="reference internal" href="#tensorkrowch.ParamNode" title="tensorkrowch.ParamNode">ParamNode</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">nodeA</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">nodeA</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">^</span> <span class="n">nodeB</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">paramnodeA</span> <span class="o">=</span> <span class="n">nodeA</span><span class="o">.</span><span class="n">parameterize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span><span class="o">.</span><span class="n">neighbours</span><span class="p">()</span> <span class="o">==</span> <span class="p">[</span><span class="n">paramnodeA</span><span class="p">]</span>
<span class="go">True</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">isinstance</span><span class="p">(</span><span class="n">paramnodeA</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">nodeA</span></code> still exists and has an edge pointing to <code class="docutils literal notranslate"><span class="pre">nodeB</span></code>, but the
latter does not “see” the former. It should be deleted.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">del</span> <span class="n">nodeA</span>
</pre></div>
</div>
<p>To overcome this issue, one should override <code class="docutils literal notranslate"><span class="pre">nodeA</span></code>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">nodeA</span> <span class="o">=</span> <span class="n">nodeA</span><span class="o">.</span><span class="n">parameterize</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.Node.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">share_tensor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#Node.copy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.Node.copy" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a copy of the node. That is, returns a node whose tensor is a copy
of the original, whose edges are directly inherited (these are not copies,
but the exact same edges) and whose name is extended with the suffix
<code class="docutils literal notranslate"><span class="pre">&quot;_copy&quot;</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>share_tensor</strong> (<em>bool</em>) – Boolean indicating whether the copied node should store its own
copy of the tensor (<code class="docutils literal notranslate"><span class="pre">False</span></code>) or share it with the original node
(<code class="docutils literal notranslate"><span class="pre">True</span></code>) storing a reference to it.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node">Node</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">node</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;node&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">copy</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">node</span><span class="o">.</span><span class="n">tensor_address</span><span class="p">()</span> <span class="o">!=</span> <span class="n">copy</span><span class="o">.</span><span class="n">tensor_address</span><span class="p">()</span>
<span class="go">True</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">copy</span><span class="o">.</span><span class="n">tensor</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
<p>If tensor is shared:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">copy</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">node</span><span class="o">.</span><span class="n">tensor_address</span><span class="p">()</span> <span class="o">==</span> <span class="n">copy</span><span class="o">.</span><span class="n">tensor_address</span><span class="p">()</span>
<span class="go">True</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">copy</span><span class="o">.</span><span class="n">tensor</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="paramnode">
<h3>ParamNode<a class="headerlink" href="#paramnode" title="Permalink to this headline">#</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="tensorkrowch.ParamNode">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tensorkrowch.</span></span><span class="sig-name descname"><span class="pre">ParamNode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">network</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">virtual</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">override_node</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">edges</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">override_edges</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node1_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#ParamNode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.ParamNode" title="Permalink to this definition">#</a></dt>
<dd><p>Class for trainable nodes. Should be subclassed by any class of nodes that
are intended to be trained (e.g. <a class="reference internal" href="#tensorkrowch.ParamStackNode" title="tensorkrowch.ParamStackNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParamStackNode</span></code></a>).</p>
<p>Should be used as the initial nodes conforming the <a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a>,
if it is going to be trained. When operating these initial nodes, the resultant
nodes will be non-parameterized (e.g. <a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node"><code class="xref py py-class docutils literal notranslate"><span class="pre">Node</span></code></a>, <a class="reference internal" href="#tensorkrowch.StackNode" title="tensorkrowch.StackNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">StackNode</span></code></a>).</p>
<p>The main difference with <a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node"><code class="xref py py-class docutils literal notranslate"><span class="pre">Nodes</span></code></a> is that <code class="docutils literal notranslate"><span class="pre">ParamNodes</span></code> have
<code class="docutils literal notranslate"><span class="pre">torch.nn.Parameter</span></code> tensors instead of <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>. Therefore, a
<code class="docutils literal notranslate"><span class="pre">ParamNode</span></code> is a sort of <cite>parameter</cite> that is attached to the
<a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a> (which is itself a <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>). That is,
the list of parameters of the tensor network module contains the tensors
of all <code class="docutils literal notranslate"><span class="pre">ParamNodes</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">ParamNodes</span></code> can only be <code class="docutils literal notranslate"><span class="pre">leaf</span></code> and <code class="docutils literal notranslate"><span class="pre">virtual</span></code> (e.g. a <code class="docutils literal notranslate"><span class="pre">virtual</span></code> node
used in a uniform <a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a> to store the tensor that is shared
by all the trainable nodes must also be a <code class="docutils literal notranslate"><span class="pre">ParamNode</span></code>, since it stores
a <code class="docutils literal notranslate"><span class="pre">torch.nn.Parameter</span></code>.</p>
<p>For a complete list of properties and methods, see also <a class="reference internal" href="#tensorkrowch.AbstractNode" title="tensorkrowch.AbstractNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractNode</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> (<em>list</em><em>[</em><em>int</em><em>]</em><em>, </em><em>tuple</em><em>[</em><em>int</em><em>]</em><em>, </em><em>torch.Size</em><em>, </em><em>optional</em>) – Node’s shape, that is, the shape of its tensor. If <code class="docutils literal notranslate"><span class="pre">shape</span></code> and
<code class="docutils literal notranslate"><span class="pre">init_method</span></code> are provided, a tensor will be made for the node. Otherwise,
<code class="docutils literal notranslate"><span class="pre">tensor</span></code> would be required.</p></li>
<li><p><strong>axes_names</strong> (<em>list</em><em>[</em><em>str</em><em>]</em><em>, </em><em>tuple</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – Sequence of names for each of the node’s axes. Names are used to access
the edge that is attached to the node in a certain axis. Hence they should
be all distinct. They cannot contain blank spaces or special characters.
By default, axes names will be <code class="docutils literal notranslate"><span class="pre">&quot;axis_0&quot;</span></code>, …, <code class="docutils literal notranslate"><span class="pre">&quot;axis_n&quot;</span></code>, being
<code class="docutils literal notranslate"><span class="pre">n</span></code> the nummber of axes.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – Node’s name, used to access the node from de <a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a> where
it belongs. It cannot contain blank spaces. By default, it is the name
of the class (e.g. <code class="docutils literal notranslate"><span class="pre">&quot;node&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;paramnode&quot;</span></code>).</p></li>
<li><p><strong>network</strong> (<a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><em>TensorNetwork</em></a><em>, </em><em>optional</em>) – Tensor network where the node should belong. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, a new tensor
network will be created to contain the node.</p></li>
<li><p><strong>virtual</strong> (<em>bool</em>) – Boolean indicating if the node is a <code class="docutils literal notranslate"><span class="pre">virtual</span></code> node.</p></li>
<li><p><strong>override_node</strong> (<em>bool</em>) – Boolean indicating whether the node should override (<code class="docutils literal notranslate"><span class="pre">True</span></code>) another
node in the network that has the same name (e.g. if a node is parameterized,
it would be required that a new <a class="reference internal" href="#tensorkrowch.ParamNode" title="tensorkrowch.ParamNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParamNode</span></code></a> replaces the
non-parameterized node in the network).</p></li>
<li><p><strong>tensor</strong> (<em>torch.Tensor</em><em>, </em><em>optional</em>) – Tensor that is to be stored in the node. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, <code class="docutils literal notranslate"><span class="pre">shape</span></code> and
<code class="docutils literal notranslate"><span class="pre">init_method</span></code> will be required.</p></li>
<li><p><strong>edges</strong> (<em>list</em><em>[</em><a class="reference internal" href="#tensorkrowch.Edge" title="tensorkrowch.Edge"><em>Edge</em></a><em>]</em><em>, </em><em>optional</em>) – List of edges that are to be attached to the node. This can be used in
case the node inherits the edges from other node(s), like results from
<a class="reference internal" href="operations.html#tensorkrowch.Operation" title="tensorkrowch.Operation"><code class="xref py py-class docutils literal notranslate"><span class="pre">Operations</span></code></a>.</p></li>
<li><p><strong>override_edges</strong> (<em>bool</em>) – Boolean indicating whether the provided <code class="docutils literal notranslate"><span class="pre">edges</span></code> should be overriden
(<code class="docutils literal notranslate"><span class="pre">True</span></code>) when reattached (e.g. if a node is parameterized, it would
be required that the new <a class="reference internal" href="#tensorkrowch.ParamNode" title="tensorkrowch.ParamNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParamNode</span></code></a>’s edges are indeed connected
to it, instead of to the original non-parameterized node).</p></li>
<li><p><strong>node1_list</strong> (<em>list</em><em>[</em><em>bool</em><em>]</em><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">edges</span></code> are provided, the list of <code class="docutils literal notranslate"><span class="pre">node1</span></code> attributes of each edge
should also be provided.</p></li>
<li><p><strong>init_method</strong> (<em>{&quot;zeros&quot;</em><em>, </em><em>&quot;ones&quot;</em><em>, </em><em>&quot;copy&quot;</em><em>, </em><em>&quot;rand&quot;</em><em>, </em><em>&quot;randn&quot;}</em><em>, </em><em>optional</em>) – Initialization method.</p></li>
<li><p><strong>device</strong> (<em>torch.device</em><em>, </em><em>optional</em>) – Device where to initialize the tensor if <code class="docutils literal notranslate"><span class="pre">init_method</span></code> is provided.</p></li>
<li><p><strong>kwargs</strong> (<em>float</em>) – Keyword arguments for the different initialization methods. See
<a class="reference internal" href="#tensorkrowch.AbstractNode.make_tensor" title="tensorkrowch.AbstractNode.make_tensor"><code class="xref py py-meth docutils literal notranslate"><span class="pre">AbstractNode.make_tensor()</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">node</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">ParamNode</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<span class="gp">... </span>                    <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">),</span>
<span class="gp">... </span>                    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;my_node&#39;</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="n">init_method</span><span class="o">=</span><span class="s1">&#39;randn&#39;</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="n">mean</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="n">std</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
</pre></div>
</div>
<p>Also, one can use one of the <a class="reference internal" href="initializers.html#initializers"><span class="std std-ref">Initializers</span></a> to simplify:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">node</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<span class="gp">... </span>                <span class="n">param_node</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.ParamNode.grad">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">grad</span></span><a class="headerlink" href="#tensorkrowch.ParamNode.grad" title="Permalink to this definition">#</a></dt>
<dd><p>Returns gradient of the param-node’s tensor.</p>
<p>See also <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.Tensor.grad.html">torch.Tensor.grad()</a></p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.ParamNode.parameterize">
<span class="sig-name descname"><span class="pre">parameterize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">set_param</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#ParamNode.parameterize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.ParamNode.parameterize" title="Permalink to this definition">#</a></dt>
<dd><p>Replaces the param-node with a de-parameterized version of it, that is,
turns a <a class="reference internal" href="#tensorkrowch.ParamNode" title="tensorkrowch.ParamNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParamNode</span></code></a> into a non-trainable, fixed <a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node"><code class="xref py py-class docutils literal notranslate"><span class="pre">Node</span></code></a>.</p>
<p>Since the param-node is <cite>replaced</cite>, it will be completely removed from
the network, and its neighbours will point to the new node.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>set_param</strong> (<em>bool</em>) – Boolean indicating whether the node should stay parameterized
(<code class="docutils literal notranslate"><span class="pre">True</span></code>), thus returning the param-node itself. Otherwise (<code class="docutils literal notranslate"><span class="pre">False</span></code>),
the param-node will be de-parameterized.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The original node or a de-parameterized version of it.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#tensorkrowch.ParamNode" title="tensorkrowch.ParamNode">ParamNode</a> or <a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node">Node</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.ParamNode.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">share_tensor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#ParamNode.copy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.ParamNode.copy" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a copy of the param-node. That is, returns a param-node whose
tensor is a copy of the original, whose edges are directly inherited
(these are not copies, but the exact same edges) and whose name is
extended with the prefix <code class="docutils literal notranslate"><span class="pre">&quot;copy_&quot;</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#tensorkrowch.ParamNode" title="tensorkrowch.ParamNode">ParamNode</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="stacknode">
<h3>StackNode<a class="headerlink" href="#stacknode" title="Permalink to this headline">#</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="tensorkrowch.StackNode">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tensorkrowch.</span></span><span class="sig-name descname"><span class="pre">StackNode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nodes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">network</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">override_node</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">edges</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node1_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#StackNode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.StackNode" title="Permalink to this definition">#</a></dt>
<dd><p>Class for stacked nodes. <code class="docutils literal notranslate"><span class="pre">StackNodes</span></code> are nodes that store the information
of a list of nodes that are stacked via <a class="reference internal" href="operations.html#tensorkrowch.stack" title="tensorkrowch.stack"><code class="xref py py-func docutils literal notranslate"><span class="pre">stack()</span></code></a>, although they can also
be instantiated directly. To do so, there are two options:</p>
<ul class="simple">
<li><p>Provide a sequence of nodes: if <code class="docutils literal notranslate"><span class="pre">nodes</span></code> are provided, their tensors will
be stacked and stored in the <code class="docutils literal notranslate"><span class="pre">StackNode</span></code>. It is necessary that all nodes
are of the same type (<a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node"><code class="xref py py-class docutils literal notranslate"><span class="pre">Node</span></code></a> or <a class="reference internal" href="#tensorkrowch.ParamNode" title="tensorkrowch.ParamNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParamNode</span></code></a>), have the same
rank (although dimension of each leg can be different for different nodes;
in which case smaller tensors are extended with 0’s to match the dimensions
of the largest tensor in the stack), same axes names (to ensure only the
<cite>same kind</cite> of nodes are stacked), belong to the same network and have edges
with the same type in each axis (<a class="reference internal" href="#tensorkrowch.Edge" title="tensorkrowch.Edge"><code class="xref py py-class docutils literal notranslate"><span class="pre">Edge</span></code></a> or <code class="xref py py-class docutils literal notranslate"><span class="pre">ParamEdge</span></code>).</p></li>
<li><p>Provide a stacked tensor: if the stacked <code class="docutils literal notranslate"><span class="pre">tensor</span></code> is provided, it is also
necessary to specify the <code class="docutils literal notranslate"><span class="pre">axes_names</span></code>, <code class="docutils literal notranslate"><span class="pre">network</span></code>, <code class="docutils literal notranslate"><span class="pre">edges</span></code>, <code class="docutils literal notranslate"><span class="pre">node1_list</span></code>.</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">StackNodes</span></code> have an additional axis for the new <cite>stack</cite> dimension, which
is a batch edge. This way, some contractions can be computed in parallel by
first stacking two sequences of nodes (connected pair-wise), performing the
batch contraction and finally unbinding the <code class="docutils literal notranslate"><span class="pre">StackNodes</span></code> to retrieve just
one sequence of nodes.</p>
<p>For the rest of the axes, a list of the edges corresponding to all nodes in
the stack is stored, so that, when <a class="reference internal" href="operations.html#tensorkrowch.unbind" title="tensorkrowch.unbind"><code class="xref py py-func docutils literal notranslate"><span class="pre">unbinding</span></code></a> the stack, it
can be inferred to which nodes the unbinded nodes have to be connected.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nodes</strong> (<em>list</em><em>[</em><a class="reference internal" href="#tensorkrowch.AbstractNode" title="tensorkrowch.AbstractNode"><em>AbstractNode</em></a><em>] or </em><em>tuple</em><em>[</em><a class="reference internal" href="#tensorkrowch.AbstractNode" title="tensorkrowch.AbstractNode"><em>AbstractNode</em></a><em>]</em><em>, </em><em>optional</em>) – Sequence of nodes that are to be stacked.</p></li>
<li><p><strong>axes_names</strong> (<em>list</em><em>[</em><em>str</em><em>]</em><em>, </em><em>tuple</em><em>[</em><em>str</em><em>]</em><em>, </em><em>optional</em>) – Sequence of names for each of the node’s axes. Names are used to access
the edge that is attached to the node in a certain axis. Hence they should
be all distinct. Necessary if <code class="docutils literal notranslate"><span class="pre">nodes</span></code> are not provided.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – Node’s name, used to access the node from de <a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a> where
it belongs. It cannot contain blank spaces.</p></li>
<li><p><strong>network</strong> (<a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><em>TensorNetwork</em></a><em>, </em><em>optional</em>) – Tensor network where the node should belong. Necessary if <code class="docutils literal notranslate"><span class="pre">nodes</span></code> are
not provided.</p></li>
<li><p><strong>override_node</strong> (<em>bool</em><em>, </em><em>optional</em>) – Boolean indicating whether the node should override (<code class="docutils literal notranslate"><span class="pre">True</span></code>) another
node in the network that has the same name (e.g. if a node is parameterized,
it would be required that a new <a class="reference internal" href="#tensorkrowch.ParamNode" title="tensorkrowch.ParamNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParamNode</span></code></a> replaces the non-parameterized
node in the network).</p></li>
<li><p><strong>tensor</strong> (<em>torch.Tensor</em><em>, </em><em>optional</em>) – Tensor that is to be stored in the node. Necessary if <code class="docutils literal notranslate"><span class="pre">nodes</span></code> are not
provided.</p></li>
<li><p><strong>edges</strong> (<em>list</em><em>[</em><a class="reference internal" href="#tensorkrowch.Edge" title="tensorkrowch.Edge"><em>Edge</em></a><em>]</em><em>, </em><em>optional</em>) – List of edges that are to be attached to the node. Necessary if <code class="docutils literal notranslate"><span class="pre">nodes</span></code>
are not provided.</p></li>
<li><p><strong>node1_list</strong> (<em>list</em><em>[</em><em>bool</em><em>]</em><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">edges</span></code> are provided, the list of <code class="docutils literal notranslate"><span class="pre">node1</span></code> attributes of each edge
should also be provided. Necessary if <code class="docutils literal notranslate"><span class="pre">nodes</span></code> are not provided.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">TensorNetwork</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<span class="gp">... </span>                  <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">),</span>
<span class="gp">... </span>                  <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">)</span>
<span class="gp">... </span>         <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,),</span>
<span class="gp">... </span>                 <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;feature&#39;</span><span class="p">,),</span>
<span class="gp">... </span>                 <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">_</span> <span class="o">=</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;input&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;feature&#39;</span><span class="p">]</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stack_nodes</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">nodes</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stack_data</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># It is necessary to re-connect stacks</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">stack_nodes</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">stack_data</span><span class="p">[</span><span class="s1">&#39;feature&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">stack_nodes</span> <span class="o">@</span> <span class="n">stack_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="go">unbind_0</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axes</span><span class="p">)</span>
<span class="go">[Axis( left (0) ), Axis( right (1) )]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">torch.Size([2, 2])</span>
</pre></div>
</div>
<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.StackNode.edges_dict">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">edges_dict</span></span><a class="headerlink" href="#tensorkrowch.StackNode.edges_dict" title="Permalink to this definition">#</a></dt>
<dd><p>Returns dictionary with list of edges of each axis.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.StackNode.node1_lists_dict">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">node1_lists_dict</span></span><a class="headerlink" href="#tensorkrowch.StackNode.node1_lists_dict" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a dictionary with list of <code class="docutils literal notranslate"><span class="pre">node1_list</span></code> attribute of each axis.</p>
</dd></dl>

</dd></dl>

</section>
<section id="paramstacknode">
<h3>ParamStackNode<a class="headerlink" href="#paramstacknode" title="Permalink to this headline">#</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="tensorkrowch.ParamStackNode">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tensorkrowch.</span></span><span class="sig-name descname"><span class="pre">ParamStackNode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nodes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">virtual</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">override_node</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#ParamStackNode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.ParamStackNode" title="Permalink to this definition">#</a></dt>
<dd><p>Class for parametric stacked nodes. They are essentially the same as
<a class="reference internal" href="#tensorkrowch.StackNode" title="tensorkrowch.StackNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">StackNodes</span></code></a> but they are also <a class="reference internal" href="#tensorkrowch.ParamNode" title="tensorkrowch.ParamNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParamNodes</span></code></a>.
They are used to optimize memory usage and save some time when the first
operation that occurs to param-nodes in a contraction (that might be
computed several times during training) is <a class="reference internal" href="operations.html#tensorkrowch.stack" title="tensorkrowch.stack"><code class="xref py py-func docutils literal notranslate"><span class="pre">stack()</span></code></a>. If this is the case,
the param-nodes no longer store their own tensors, but rather they make
reference to a slide of a greater <code class="docutils literal notranslate"><span class="pre">ParamStackNode</span></code> (if <code class="docutils literal notranslate"><span class="pre">auto_stack</span></code> attribute
of the <a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code>). Hence, that first <a class="reference internal" href="operations.html#tensorkrowch.stack" title="tensorkrowch.stack"><code class="xref py py-func docutils literal notranslate"><span class="pre">stack()</span></code></a>
is never computed.</p>
<p><code class="docutils literal notranslate"><span class="pre">ParamStackNodes</span></code> can only be instantiated by providing a sequence of nodes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nodes</strong> (<em>list</em><em>[</em><a class="reference internal" href="#tensorkrowch.AbstractNode" title="tensorkrowch.AbstractNode"><em>AbstractNode</em></a><em>] or </em><em>tuple</em><em>[</em><a class="reference internal" href="#tensorkrowch.AbstractNode" title="tensorkrowch.AbstractNode"><em>AbstractNode</em></a><em>]</em>) – Sequence of nodes that are to be stacked.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – Node’s name, used to access the node from de <a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a> where
it belongs. It cannot contain blank spaces.</p></li>
<li><p><strong>virtual</strong> (<em>bool</em><em>, </em><em>optional</em>) – Boolean indicating if the node is a <code class="docutils literal notranslate"><span class="pre">virtual</span></code> node. Since it will be
used mainly for the case described <a class="reference internal" href="#tensorkrowch.ParamStackNode" title="tensorkrowch.ParamStackNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">here</span></code></a>, the
node will be virtual, since it will not be an <cite>effective</cite> part of the
tensor network, but rather a <cite>virtual</cite> node used just to store tensors.</p></li>
<li><p><strong>override_node</strong> (<em>bool</em><em>, </em><em>optional</em>) – Boolean indicating whether the node should override (<code class="docutils literal notranslate"><span class="pre">True</span></code>) another
node in the network that has the same name (e.g. if a node is parameterized,
it would be required that a new <a class="reference internal" href="#tensorkrowch.ParamNode" title="tensorkrowch.ParamNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParamNode</span></code></a> replaces the non-parameterized
node in the network).</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">TensorNetwork</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="o">.</span><span class="n">auto_stack</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<span class="gp">... </span>                  <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">),</span>
<span class="gp">... </span>                  <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">,</span>
<span class="gp">... </span>                  <span class="n">param_node</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">... </span>         <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,),</span>
<span class="gp">... </span>                 <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;feature&#39;</span><span class="p">,),</span>
<span class="gp">... </span>                 <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">_</span> <span class="o">=</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;input&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;feature&#39;</span><span class="p">]</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stack_nodes</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">nodes</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stack_nodes</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;my_stack&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># ._tensor_info has info regarding where the node&#39;s tensor is stored</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;node_ref&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="go">my_stack</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stack_data</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># It is necessary to re-connect stacks</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">stack_nodes</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">stack_data</span><span class="p">[</span><span class="s1">&#39;feature&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">stack_nodes</span> <span class="o">@</span> <span class="n">stack_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="go">unbind_0</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axes</span><span class="p">)</span>
<span class="go">[Axis( left (0) ), Axis( right (1) )]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">torch.Size([2, 2])</span>
</pre></div>
</div>
<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.ParamStackNode.edges_dict">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">edges_dict</span></span><a class="headerlink" href="#tensorkrowch.ParamStackNode.edges_dict" title="Permalink to this definition">#</a></dt>
<dd><p>Returns dictionary with list of edges of each axis.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.ParamStackNode.node1_lists_dict">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">node1_lists_dict</span></span><a class="headerlink" href="#tensorkrowch.ParamStackNode.node1_lists_dict" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a dictionary with list of <code class="docutils literal notranslate"><span class="pre">node1_list</span></code> attribute of each axis.</p>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="edges">
<h2>Edges<a class="headerlink" href="#edges" title="Permalink to this headline">#</a></h2>
<section id="edge">
<h3>Edge<a class="headerlink" href="#edge" title="Permalink to this headline">#</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="tensorkrowch.Edge">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tensorkrowch.</span></span><span class="sig-name descname"><span class="pre">Edge</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#Edge"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.Edge" title="Permalink to this definition">#</a></dt>
<dd><p>Base class for edges. Should be subclassed by any new class of edges.</p>
<p>An edge is nothing more than an object that wraps references to the nodes it
connects. Thus it stores information like the nodes it connects, the corresponding
nodes’ axes it is attached to, whether it is dangling or batch, its size, etc.</p>
<p>Above all, its importance lies in that edges enable to connect nodes, forming
any possible graph, and to perform easily <a class="reference internal" href="operations.html#tensorkrowch.Operation" title="tensorkrowch.Operation"><code class="xref py py-class docutils literal notranslate"><span class="pre">Operations</span></code></a> like
contracting and splitting nodes.</p>
<p>Furthermore, edges have specific operations like <a class="reference internal" href="operations.html#tensorkrowch.contract_" title="tensorkrowch.contract_"><code class="xref py py-meth docutils literal notranslate"><span class="pre">contract_()</span></code></a> or <a class="reference internal" href="operations.html#tensorkrowch.svd_" title="tensorkrowch.svd_"><code class="xref py py-meth docutils literal notranslate"><span class="pre">svd_()</span></code></a>
(and its variations) that allow in-place modification of the <a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>node1</strong> (<a class="reference internal" href="#tensorkrowch.AbstractNode" title="tensorkrowch.AbstractNode"><em>AbstractNode</em></a>) – First node to which the edge is connected.</p></li>
<li><p><strong>axis1</strong> (<em>int</em><em>, </em><em>str</em><em> or </em><a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><em>Axis</em></a>) – Axis of <code class="docutils literal notranslate"><span class="pre">node1</span></code> where the edge is attached.</p></li>
<li><p><strong>node2</strong> (<a class="reference internal" href="#tensorkrowch.AbstractNode" title="tensorkrowch.AbstractNode"><em>AbstractNode</em></a><em>, </em><em>optional</em>) – Second node to which the edge is connected. If None, the edge will be
dangling.</p></li>
<li><p><strong>axis2</strong> (<em>int</em><em>, </em><em>str</em><em>, </em><a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><em>Axis</em></a><em>, </em><em>optional</em>) – Axis of <code class="docutils literal notranslate"><span class="pre">node2</span></code> where the edge is attached.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.Edge.node1">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">node1</span></span><a class="headerlink" href="#tensorkrowch.Edge.node1" title="Permalink to this definition">#</a></dt>
<dd><p>Returns <cite>node1</cite> of the edge.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.Edge.node2">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">node2</span></span><a class="headerlink" href="#tensorkrowch.Edge.node2" title="Permalink to this definition">#</a></dt>
<dd><p>Returns <cite>node2</cite> of the edge. If the edge is dangling, it is None.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.Edge.nodes">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">nodes</span></span><a class="headerlink" href="#tensorkrowch.Edge.nodes" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a list with <cite>node1</cite> and <cite>node2</cite>.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.Edge.axis1">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">axis1</span></span><a class="headerlink" href="#tensorkrowch.Edge.axis1" title="Permalink to this definition">#</a></dt>
<dd><p>Returns axis where the edge is attached to <cite>node1</cite>.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.Edge.axis2">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">axis2</span></span><a class="headerlink" href="#tensorkrowch.Edge.axis2" title="Permalink to this definition">#</a></dt>
<dd><p>Returns axis where the edge is attached to <cite>node2</cite>. If the edge is dangling,
it is None.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.Edge.axes">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">axes</span></span><a class="headerlink" href="#tensorkrowch.Edge.axes" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a list of axes where the edge is attached to <cite>node1</cite> and <cite>node2</cite>,
respectively.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.Edge.name">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#tensorkrowch.Edge.name" title="Permalink to this definition">#</a></dt>
<dd><p>Returns edge’s name. It is formed with the corresponding nodes’ and axes’
names.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">nodeA</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;nodeA&#39;</span><span class="p">,</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">edge</span> <span class="o">=</span> <span class="n">nodeA</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">edge</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="go">nodeA[right] &lt;-&gt; None</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;nodeB&#39;</span><span class="p">,</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_edge</span> <span class="o">=</span> <span class="n">nodeA</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">nodeB</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">new_edge</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="go">nodeA[right] &lt;-&gt; nodeB[left]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.Edge.is_dangling">
<span class="sig-name descname"><span class="pre">is_dangling</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#Edge.is_dangling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.Edge.is_dangling" title="Permalink to this definition">#</a></dt>
<dd><p>Returns boolean indicating whether the edge is a dangling edge.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.Edge.is_batch">
<span class="sig-name descname"><span class="pre">is_batch</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#Edge.is_batch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.Edge.is_batch" title="Permalink to this definition">#</a></dt>
<dd><p>Returns boolean indicating whether the edge is a batch edge.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.Edge.is_attached_to">
<span class="sig-name descname"><span class="pre">is_attached_to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#Edge.is_attached_to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.Edge.is_attached_to" title="Permalink to this definition">#</a></dt>
<dd><p>Returns boolean indicating whether the edge is attached to <code class="docutils literal notranslate"><span class="pre">node</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.Edge.size">
<span class="sig-name descname"><span class="pre">size</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#Edge.size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.Edge.size" title="Permalink to this definition">#</a></dt>
<dd><p>Returns edge’s size.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.Edge.change_size">
<span class="sig-name descname"><span class="pre">change_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#Edge.change_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.Edge.change_size" title="Permalink to this definition">#</a></dt>
<dd><p>Changes size of the edge, thus changing the size of tensors of <cite>node1</cite>
and <cite>node2</cite> at the corresponding axes. If new size is smaller, the tensor
will be cropped; if larger, the tensor will be expanded with zeros. In
both cases, the process (cropping/expanding) occurs at the “left”, “top”,
“front”, etc. of each dimension.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.Edge.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#Edge.copy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.Edge.copy" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a copy of the edge, that is, a new edge referencing the same
nodes at the same axes.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.Edge.connect">
<span class="sig-name descname"><span class="pre">connect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#Edge.connect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.Edge.connect" title="Permalink to this definition">#</a></dt>
<dd><p>Connects dangling edge to another dangling edge.</p>
<p>It is necessary that both edges have the same dimension so that contractions
along that edge can be computed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>other</strong> (<a class="reference internal" href="#tensorkrowch.Edge" title="tensorkrowch.Edge"><em>Edge</em></a>) – The other edge to which current edge will be connected.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#tensorkrowch.Edge" title="tensorkrowch.Edge">Edge</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<p>To connect two edges, the overloaded operator <code class="docutils literal notranslate"><span class="pre">^</span></code> can also be used.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">nodeA</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;nodeA&#39;</span><span class="p">,</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;nodeB&#39;</span><span class="p">,</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_edge</span> <span class="o">=</span> <span class="n">nodeA</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">nodeB</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span>  <span class="c1"># Same as .connect()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">new_edge</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="go">nodeA[right] &lt;-&gt; nodeB[left]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.Edge.disconnect">
<span class="sig-name descname"><span class="pre">disconnect</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#Edge.disconnect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.Edge.disconnect" title="Permalink to this definition">#</a></dt>
<dd><p>Disconnects connected edge, that is, the connected edge is splitted into
two dangling edges, one for each node.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[<a class="reference internal" href="#tensorkrowch.Edge" title="tensorkrowch.Edge">Edge</a>, <a class="reference internal" href="#tensorkrowch.Edge" title="tensorkrowch.Edge">Edge</a>]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<p>To disconnect an edge, the overloaded operator <code class="docutils literal notranslate"><span class="pre">|</span></code> can also be used.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">nodeA</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;nodeA&#39;</span><span class="p">,</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;nodeB&#39;</span><span class="p">,</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_edge</span> <span class="o">=</span> <span class="n">nodeA</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">nodeB</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_edgeA</span><span class="p">,</span> <span class="n">new_edgeB</span> <span class="o">=</span> <span class="n">new_edge</span> <span class="o">|</span> <span class="n">new_edge</span>  <span class="c1"># Same as .disconnect()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">new_edgeA</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="go">nodeA[right] &lt;-&gt; None</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">new_edgeB</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="go">nodeB[left] &lt;-&gt; None</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.Edge.contract_">
<span class="sig-name descname"><span class="pre">contract_</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorkrowch.Edge.contract_" title="Permalink to this definition">#</a></dt>
<dd><p>Contracts in-place the nodes that are connected through the edge. See
<code class="xref py py-func docutils literal notranslate"><span class="pre">contract()</span></code> for a more complete explanation.</p>
<p>Following the <strong>PyTorch</strong> convention, names of functions ended with an
underscore indicate <strong>in-place</strong> operations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>edge</strong> (<a class="reference internal" href="#tensorkrowch.Edge" title="tensorkrowch.Edge"><em>Edge</em></a>) – Edges that is to be contracted. Batch contraction is automatically
performed when both nodes have batch edges with the same names.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node">Node</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.Edge.qr_">
<span class="sig-name descname"><span class="pre">qr_</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorkrowch.Edge.qr_" title="Permalink to this definition">#</a></dt>
<dd><p>Contracts an edge in-place via <a class="reference internal" href="#tensorkrowch.Edge.contract_" title="tensorkrowch.Edge.contract_"><code class="xref py py-func docutils literal notranslate"><span class="pre">contract_()</span></code></a> and splits
it in-place via <a class="reference internal" href="#tensorkrowch.AbstractNode.split_" title="tensorkrowch.AbstractNode.split_"><code class="xref py py-func docutils literal notranslate"><span class="pre">split_()</span></code></a> using <code class="docutils literal notranslate"><span class="pre">mode</span> <span class="pre">=</span> <span class="pre">&quot;qr&quot;</span></code>. See
<a class="reference internal" href="operations.html#tensorkrowch.split" title="tensorkrowch.split"><code class="xref py py-func docutils literal notranslate"><span class="pre">split()</span></code></a> for a more complete explanation.</p>
<p>Following the <strong>PyTorch</strong> convention, names of functions ended with an
underscore indicate <strong>in-place</strong> operations.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[<a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node">Node</a>, <a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node">Node</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.Edge.rq_">
<span class="sig-name descname"><span class="pre">rq_</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tensorkrowch.Edge.rq_" title="Permalink to this definition">#</a></dt>
<dd><p>Contracts an edge in-place via <a class="reference internal" href="#tensorkrowch.Edge.contract_" title="tensorkrowch.Edge.contract_"><code class="xref py py-func docutils literal notranslate"><span class="pre">contract_()</span></code></a> and splits
it in-place via <a class="reference internal" href="#tensorkrowch.AbstractNode.split_" title="tensorkrowch.AbstractNode.split_"><code class="xref py py-func docutils literal notranslate"><span class="pre">split_()</span></code></a> using <code class="docutils literal notranslate"><span class="pre">mode</span> <span class="pre">=</span> <span class="pre">&quot;qr&quot;</span></code>. See
<a class="reference internal" href="operations.html#tensorkrowch.split" title="tensorkrowch.split"><code class="xref py py-func docutils literal notranslate"><span class="pre">split()</span></code></a> for a more complete explanation.</p>
<p>Following the <strong>PyTorch</strong> convention, names of functions ended with an
underscore indicate <strong>in-place</strong> operations.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple[<a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node">Node</a>, <a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node">Node</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.Edge.svd_">
<span class="sig-name descname"><span class="pre">svd_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">side</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'left'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cum_percentage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cutoff</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tensorkrowch.Edge.svd_" title="Permalink to this definition">#</a></dt>
<dd><p>Contracts an edge in-place via <a class="reference internal" href="#tensorkrowch.Edge.contract_" title="tensorkrowch.Edge.contract_"><code class="xref py py-func docutils literal notranslate"><span class="pre">contract_()</span></code></a> and splits
it in-place via <a class="reference internal" href="#tensorkrowch.AbstractNode.split_" title="tensorkrowch.AbstractNode.split_"><code class="xref py py-func docutils literal notranslate"><span class="pre">split_()</span></code></a> using <code class="docutils literal notranslate"><span class="pre">mode</span> <span class="pre">=</span> <span class="pre">&quot;svd&quot;</span></code>. See
<a class="reference internal" href="operations.html#tensorkrowch.split" title="tensorkrowch.split"><code class="xref py py-func docutils literal notranslate"><span class="pre">split()</span></code></a> for a more complete explanation.</p>
<p>Following the <strong>PyTorch</strong> convention, names of functions ended with an
underscore indicate <strong>in-place</strong> operations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>side</strong> (<em>str</em><em>, </em><em>optional</em>) – Indicates the side to which the diagonal matrix <span class="math notranslate nohighlight">\(S\)</span> should be
contracted. If “left”, the first resultant node’s tensor will be
<span class="math notranslate nohighlight">\(US\)</span>, and the other node’s tensor will be <span class="math notranslate nohighlight">\(V^{\dagger}\)</span>.
If “right”, their tensors will be <span class="math notranslate nohighlight">\(U\)</span> and <span class="math notranslate nohighlight">\(SV^{\dagger}\)</span>,
respectively.</p></li>
<li><p><strong>rank</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of singular values to keep.</p></li>
<li><p><strong>cum_percentage</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>Proportion that should be satisfied between the sum of all singular
values kept and the total sum of all singular values.</p>
<div class="math notranslate nohighlight">
\[\frac{\sum_{i \in \{kept\}}{s_i}}{\sum_{i \in \{all\}}{s_i}} \ge
cum\_percentage\]</div>
</p></li>
<li><p><strong>cutoff</strong> (<em>float</em><em>, </em><em>optional</em>) – Quantity that lower bounds singular values in order to be kept.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>tuple[<a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node">Node</a>, <a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node">Node</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.Edge.svdr_">
<span class="sig-name descname"><span class="pre">svdr_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">side</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'left'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cum_percentage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cutoff</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tensorkrowch.Edge.svdr_" title="Permalink to this definition">#</a></dt>
<dd><p>Contracts an edge in-place via <a class="reference internal" href="#tensorkrowch.Edge.contract_" title="tensorkrowch.Edge.contract_"><code class="xref py py-func docutils literal notranslate"><span class="pre">contract_()</span></code></a> and splits
it in-place via <a class="reference internal" href="#tensorkrowch.AbstractNode.split_" title="tensorkrowch.AbstractNode.split_"><code class="xref py py-func docutils literal notranslate"><span class="pre">split_()</span></code></a> using <code class="docutils literal notranslate"><span class="pre">mode</span> <span class="pre">=</span> <span class="pre">&quot;svdr&quot;</span></code>. See
<a class="reference internal" href="operations.html#tensorkrowch.split" title="tensorkrowch.split"><code class="xref py py-func docutils literal notranslate"><span class="pre">split()</span></code></a> for a more complete explanation.</p>
<p>Following the <strong>PyTorch</strong> convention, names of functions ended with an
underscore indicate <strong>in-place</strong> operations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>side</strong> (<em>str</em><em>, </em><em>optional</em>) – Indicates the side to which the diagonal matrix <span class="math notranslate nohighlight">\(S\)</span> should be
contracted. If “left”, the first resultant node’s tensor will be
<span class="math notranslate nohighlight">\(US\)</span>, and the other node’s tensor will be <span class="math notranslate nohighlight">\(V^{\dagger}\)</span>.
If “right”, their tensors will be <span class="math notranslate nohighlight">\(U\)</span> and <span class="math notranslate nohighlight">\(SV^{\dagger}\)</span>,
respectively.</p></li>
<li><p><strong>rank</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of singular values to keep.</p></li>
<li><p><strong>cum_percentage</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>Proportion that should be satisfied between the sum of all singular
values kept and the total sum of all singular values.</p>
<div class="math notranslate nohighlight">
\[\frac{\sum_{i \in \{kept\}}{s_i}}{\sum_{i \in \{all\}}{s_i}} \ge
cum\_percentage\]</div>
</p></li>
<li><p><strong>cutoff</strong> (<em>float</em><em>, </em><em>optional</em>) – Quantity that lower bounds singular values in order to be kept.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>tuple[<a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node">Node</a>, <a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node">Node</a>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="stackedge">
<h3>StackEdge<a class="headerlink" href="#stackedge" title="Permalink to this headline">#</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="tensorkrowch.StackEdge">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tensorkrowch.</span></span><span class="sig-name descname"><span class="pre">StackEdge</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">edges</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node1_lists</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#StackEdge"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.StackEdge" title="Permalink to this definition">#</a></dt>
<dd><p>Class for stacked edges. They are just like <a class="reference internal" href="#tensorkrowch.Edge" title="tensorkrowch.Edge"><code class="xref py py-class docutils literal notranslate"><span class="pre">Edges</span></code></a> but used
when stacking a collection of nodes into a <a class="reference internal" href="#tensorkrowch.StackNode" title="tensorkrowch.StackNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">StackNode</span></code></a>. When doing
this, all edges of the stacked nodes must be kept, since they have the
information regarding the nodes’ neighbours, which will be used when :func:
<cite>unbinding &lt;unbind&gt;</cite> the stack. Thus, <code class="docutils literal notranslate"><span class="pre">StackEdges</span></code> have two additional
properties, <code class="docutils literal notranslate"><span class="pre">edges</span></code> and <code class="docutils literal notranslate"><span class="pre">node1_lists</span></code>, that is, the edges of all stacked
nodes corresponding to a certain axis, and their <code class="docutils literal notranslate"><span class="pre">node1_list</span></code>’s.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>edges</strong> (<em>list</em><em>[</em><a class="reference internal" href="#tensorkrowch.Edge" title="tensorkrowch.Edge"><em>Edge</em></a><em>]</em>) – List of non-trainable edges that will be stacked.</p></li>
<li><p><strong>node1_lists</strong> (<em>list</em><em>[</em><em>bool</em><em>]</em>) – List of <code class="docutils literal notranslate"><span class="pre">node1_list</span></code>’s corresponding to each edge in <code class="docutils literal notranslate"><span class="pre">edges</span></code>.</p></li>
<li><p><strong>node1</strong> (<a class="reference internal" href="#tensorkrowch.StackNode" title="tensorkrowch.StackNode"><em>StackNode</em></a><em> or </em><a class="reference internal" href="#tensorkrowch.ParamStackNode" title="tensorkrowch.ParamStackNode"><em>ParamStackNode</em></a>) – First node to which the edge is connected.</p></li>
<li><p><strong>axis1</strong> (<em>int</em><em>, </em><em>str</em><em> or </em><a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><em>Axis</em></a>) – Axis of <code class="docutils literal notranslate"><span class="pre">node1</span></code> where the edge is attached.</p></li>
<li><p><strong>node2</strong> (<a class="reference internal" href="#tensorkrowch.StackNode" title="tensorkrowch.StackNode"><em>StackNode</em></a><em> or </em><a class="reference internal" href="#tensorkrowch.ParamStackNode" title="tensorkrowch.ParamStackNode"><em>ParamStackNode</em></a><em>, </em><em>optional</em>) – Second node to which the edge is connected. If None, the edge will be
dangling.</p></li>
<li><p><strong>axis2</strong> (<em>int</em><em>, </em><em>str</em><em>, </em><a class="reference internal" href="#tensorkrowch.Axis" title="tensorkrowch.Axis"><em>Axis</em></a><em>, </em><em>optional</em>) – Axis of <code class="docutils literal notranslate"><span class="pre">node2</span></code> where the edge is attached.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.StackEdge.edges">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">edges</span></span><a class="headerlink" href="#tensorkrowch.StackEdge.edges" title="Permalink to this definition">#</a></dt>
<dd><p>Returns list of stacked edges corresponding to this axis.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.StackEdge.node1_lists">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">node1_lists</span></span><a class="headerlink" href="#tensorkrowch.StackEdge.node1_lists" title="Permalink to this definition">#</a></dt>
<dd><p>Returns list of <code class="docutils literal notranslate"><span class="pre">node1_list</span></code>’s corresponding to this axis.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.StackEdge.connect">
<span class="sig-name descname"><span class="pre">connect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#StackEdge.connect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.StackEdge.connect" title="Permalink to this definition">#</a></dt>
<dd><p>Same as <a class="reference internal" href="#tensorkrowch.Edge.connect" title="tensorkrowch.Edge.connect"><code class="xref py py-meth docutils literal notranslate"><span class="pre">connect()</span></code></a> but it is verified that all stacked edges
corresponding to both <code class="docutils literal notranslate"><span class="pre">StackEdges</span></code> are the same. That is, this is a
redundant operation to re-connect a list of edges that should be already
connected. However, this is mandatory, since when stacking two sequences
of nodes independently it cannot be inferred that the resultant
<code class="docutils literal notranslate"><span class="pre">StackNodes</span></code> had to be connected.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>other</strong> (<a class="reference internal" href="#tensorkrowch.StackEdge" title="tensorkrowch.StackEdge"><em>StackEdge</em></a>) – The other edge to which current edge will be connected.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#tensorkrowch.StackEdge" title="tensorkrowch.StackEdge">StackEdge</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<p>To connect two stack-edges, the overloaded operator <code class="docutils literal notranslate"><span class="pre">^</span></code> can also be used.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">TensorNetwork</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<span class="gp">... </span>                  <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">),</span>
<span class="gp">... </span>                  <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">)</span>
<span class="gp">... </span>         <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,),</span>
<span class="gp">... </span>                 <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;feature&#39;</span><span class="p">,),</span>
<span class="gp">... </span>                 <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">_</span> <span class="o">=</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;input&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;feature&#39;</span><span class="p">]</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stack_nodes</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">nodes</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stack_data</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># It is necessary to re-connect stacks to be able to contract</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">stack_nodes</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">stack_data</span><span class="p">[</span><span class="s1">&#39;feature&#39;</span><span class="p">]</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="successor">
<h2>Successor<a class="headerlink" href="#successor" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tensorkrowch.Successor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tensorkrowch.</span></span><span class="sig-name descname"><span class="pre">Successor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kwargs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">child</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#Successor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.Successor" title="Permalink to this definition">#</a></dt>
<dd><p>Class for successors. This is a sort of cache memory for <a class="reference internal" href="operations.html#tensorkrowch.Operation" title="tensorkrowch.Operation"><code class="xref py py-class docutils literal notranslate"><span class="pre">operations</span></code></a> that have been already computed.</p>
<p>For instance, when contracting two nodes, the result gives a new node that
stores the tensor resultant from contracting both nodes’s tensors. However,
when training a <a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a>, the tensors inside the nodes will
change every epoch, but there is actually no need to create a new resultant
node every time. Instead, it is more efficient to keep track of which node
arose as the result of an operation, and simply change its tensor.</p>
<p>Hence, a <code class="docutils literal notranslate"><span class="pre">Successor</span></code> is instantiated providing the arguments of the operation
that gave rise to a resultant node, a reference to the resultant node itself,
and some hints that might help accelerating the computations the next time
the operation is performed.</p>
<p>These three properties can be accessed via <code class="docutils literal notranslate"><span class="pre">successor.kwargs</span></code>, <code class="docutils literal notranslate"><span class="pre">successor.child</span></code>
and <code class="docutils literal notranslate"><span class="pre">successor.hints</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kwargs</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>any</em><em>]</em>) – Dictionary with keyword arguments used to call an operation.</p></li>
<li><p><strong>child</strong> (<a class="reference internal" href="#tensorkrowch.AbstractNode" title="tensorkrowch.AbstractNode"><em>AbstractNode</em></a><em> or </em><em>list</em><em>[</em><a class="reference internal" href="#tensorkrowch.AbstractNode" title="tensorkrowch.AbstractNode"><em>AbstractNode</em></a><em>]</em>) – The node or list of nodes that result from an operation.</p></li>
<li><p><strong>hints</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>any</em><em>]</em><em>, </em><em>optional</em>) – A dictionary of hints created the first time an operation is computed in
order to save some computation in the next calls of the operation.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<p>When contracting two nodes, a <code class="docutils literal notranslate"><span class="pre">Successor</span></code> is created and added to the list
of successors of the first node (left operand).</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">nodeA</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodeB</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">))</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Connect nodes</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">nodeA</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">nodeB</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Contract nodes</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">nodeA</span> <span class="o">@</span> <span class="n">nodeB</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;my_result&#39;</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">nodeA</span><span class="o">.</span><span class="n">successors</span><span class="p">[</span><span class="s1">&#39;contract_edges&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="go">my_result my_result</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="tensor-network">
<h2>Tensor Network<a class="headerlink" href="#tensor-network" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tensorkrowch.TensorNetwork">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tensorkrowch.</span></span><span class="sig-name descname"><span class="pre">TensorNetwork</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#TensorNetwork"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.TensorNetwork" title="Permalink to this definition">#</a></dt>
<dd><p>Class for arbitrary Tensor Networks. Subclass of <strong>PyTorch</strong> <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code>.</p>
<p>Tensor Networks are the central objects of <strong>TensorKrowch</strong>. Basically,
a tensor network is a graph where vertices are <a class="reference internal" href="#tensorkrowch.AbstractNode" title="tensorkrowch.AbstractNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">Nodes</span></code></a>
and edges are, pun intended, <a class="reference internal" href="#tensorkrowch.Edge" title="tensorkrowch.Edge"><code class="xref py py-class docutils literal notranslate"><span class="pre">Edges</span></code></a>. In these models,
nodes’ tensors will be trained so that the contraction of the whole network
approximates a certain function. Hence, Tensor Networks are the <cite>trainable
objects</cite> of <strong>TensorKrowch</strong>, very much like <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code>’s are the
<cite>trainable objects</cite> of <strong>PyTorch</strong>.</p>
<p>Recall that the common way of defining models out of <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> is by
defining a subclass where the <code class="docutils literal notranslate"><span class="pre">__init__</span></code> and <code class="docutils literal notranslate"><span class="pre">forward</span></code> methods are
overriden:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>: Defines the model itself (its layers, attributes, etc.).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">forward</span></code>: Defines the way the model operates, that is, how the different
parts of the model migh combine to get an output from a particular input.</p></li>
</ul>
<p>With <code class="docutils literal notranslate"><span class="pre">TensorNetwork</span></code>, the workflow is similar, though there are other
methods that should be overriden:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>: Defines the graph of the tensor network and initializes the
tensors of the nodes.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">set_data_nodes</span></code>: Creates the data nodes where the data tensor(s) will
be placed. Usually, it will just select the edges to which the data nodes
should be connected, and call the parent method <code class="docutils literal notranslate"><span class="pre">set_data_nodes</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">contract</span></code>: Defines the contraction algorithm of the whole tensor network,
thus returning a single node. Very much like <code class="docutils literal notranslate"><span class="pre">forward</span></code> this is the main
method that describes how the components of the network are combined.
Hence, in <code class="docutils literal notranslate"><span class="pre">TensorNetwork</span></code> the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method shall not be overriden,
since it will just call <code class="docutils literal notranslate"><span class="pre">contract</span></code>.</p></li>
</ul>
<p>Although one can define how the network is going to be contracted, there a
couple of modes that can change how this contraction behaves at a lower level:</p>
<ul class="simple">
<li><p><strong>auto_stack</strong> (<code class="docutils literal notranslate"><span class="pre">False</span></code> by default): This mode indicates whether node
<a class="reference internal" href="operations.html#tensorkrowch.Operation" title="tensorkrowch.Operation"><code class="xref py py-class docutils literal notranslate"><span class="pre">Operations</span></code></a> have the ability to take control of the
memory management of the network. For instance, if <code class="docutils literal notranslate"><span class="pre">auto_stack</span></code> is set
to <code class="docutils literal notranslate"><span class="pre">True</span></code> and a collection of <a class="reference internal" href="#tensorkrowch.ParamNode" title="tensorkrowch.ParamNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParamNodes</span></code></a> are
<a class="reference internal" href="operations.html#tensorkrowch.stack" title="tensorkrowch.stack"><code class="xref py py-func docutils literal notranslate"><span class="pre">stacked</span></code></a> (as the first operation in the contraction),
then those nodes will no longer store their own tensors, but rather a
<code class="docutils literal notranslate"><span class="pre">virtual</span></code> <a class="reference internal" href="#tensorkrowch.ParamStackNode" title="tensorkrowch.ParamStackNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParamStackNode</span></code></a> will store the stacked tensor, avoiding
the computation of the first <a class="reference internal" href="operations.html#tensorkrowch.stack" title="tensorkrowch.stack"><code class="xref py py-func docutils literal notranslate"><span class="pre">stack()</span></code></a> in every contraction. This
behaviour is not possible if <code class="docutils literal notranslate"><span class="pre">auto_stack</span></code> is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, in which
case all nodes will always store their own tensors.</p></li>
<li><p><strong>auto_unbind</strong> (<code class="docutils literal notranslate"><span class="pre">True</span></code> by default): This mode indicates whether the
operation <a class="reference internal" href="operations.html#tensorkrowch.unbind" title="tensorkrowch.unbind"><code class="xref py py-func docutils literal notranslate"><span class="pre">unbind()</span></code></a> has to actually <cite>unbind</cite> the stacked tensor or
just generate a collection of references. That is, if <code class="docutils literal notranslate"><span class="pre">auto_unbind</span></code> is
set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, <a class="reference internal" href="operations.html#tensorkrowch.unbind" title="tensorkrowch.unbind"><code class="xref py py-func docutils literal notranslate"><span class="pre">unbind()</span></code></a> creates a collection of nodes, each of them
storing the corresponding slice of the stacked tensor. If <code class="docutils literal notranslate"><span class="pre">auto_unbind</span></code>
is set to <code class="docutils literal notranslate"><span class="pre">True</span></code> (called <code class="docutils literal notranslate"><span class="pre">index_mode</span></code>), <a class="reference internal" href="operations.html#tensorkrowch.unbind" title="tensorkrowch.unbind"><code class="xref py py-func docutils literal notranslate"><span class="pre">unbind()</span></code></a> just creates
the nodes and gives each of them an index for the stacked tensor, so that
each node’s tensor would be retrieved by indexing the stack. This avoids
performing the operation, since these indices will be the same in consecutive
iterations. Hence, in a similar way to <code class="docutils literal notranslate"><span class="pre">auto_stack</span></code>, this mode entails
a certain control of the memory management of the network.</p></li>
</ul>
<p>Once the training algorithm starts, these modes should not be changed (very
often at least), since changing them entails first resetting the whole
network (see <a class="reference internal" href="#tensorkrowch.TensorNetwork.reset" title="tensorkrowch.TensorNetwork.reset"><code class="xref py py-meth docutils literal notranslate"><span class="pre">reset()</span></code></a>), which is a costly method. To understand what
reset means, check the different types of nodes a network might have:</p>
<p># TODO: reference to AbstarctNode</p>
<ul class="simple">
<li><p><strong>leaf</strong>: These are the nodes that make up the graph of the Tensor Network,
except for the nodes containing data. These can be either type <a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node"><code class="xref py py-class docutils literal notranslate"><span class="pre">Node</span></code></a>
or <a class="reference internal" href="#tensorkrowch.ParamNode" title="tensorkrowch.ParamNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParamNode</span></code></a> (trainable nodes).</p></li>
<li><p><strong>data</strong>: These are <a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node"><code class="xref py py-class docutils literal notranslate"><span class="pre">Nodes</span></code></a> which store the tensors coming
from input data. These are set via <a class="reference internal" href="#tensorkrowch.TensorNetwork.set_data_nodes" title="tensorkrowch.TensorNetwork.set_data_nodes"><code class="xref py py-meth docutils literal notranslate"><span class="pre">set_data_nodes()</span></code></a>.</p></li>
<li><p><strong>virtual</strong>: These nodes (<a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node"><code class="xref py py-class docutils literal notranslate"><span class="pre">Node</span></code></a> or <a class="reference internal" href="#tensorkrowch.ParamNode" title="tensorkrowch.ParamNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParamNode</span></code></a>) are a sort
of ancillay, hidden nodes that accomplish some useful task (e.g. in uniform
tensor networks a virtual node has the shared tensor, while all the other
nodes in the network just have a reference to it).</p></li>
<li><p><strong>resultant</strong>: These are <a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node"><code class="xref py py-class docutils literal notranslate"><span class="pre">Nodes</span></code></a> that result from an
<a class="reference internal" href="operations.html#tensorkrowch.Operation" title="tensorkrowch.Operation"><code class="xref py py-class docutils literal notranslate"><span class="pre">Operation</span></code></a>. They are intermediate nodes that (almost always)
inherit edges from <code class="docutils literal notranslate"><span class="pre">leaf</span></code>  and <code class="docutils literal notranslate"><span class="pre">data</span></code> nodes, the ones that really
establish the network’s graph. Thus <code class="docutils literal notranslate"><span class="pre">resultant</span></code> nodes can be thought of
like permutations or combinations of <code class="docutils literal notranslate"><span class="pre">leaf</span></code> nodes.</p></li>
</ul>
<p>This way, when the Tensor Network is defined, it has a bunch of <code class="docutils literal notranslate"><span class="pre">leaf</span></code>,
<code class="docutils literal notranslate"><span class="pre">data</span></code> and <code class="docutils literal notranslate"><span class="pre">virtual</span></code> nodes that make up the network structure, each of
them storing its own tensor. However, when the network is contracted, several
<code class="docutils literal notranslate"><span class="pre">resultant</span></code> nodes become new members of the network, even modifying its
memory (depending on the <code class="docutils literal notranslate"><span class="pre">auto_stack</span></code> and <code class="docutils literal notranslate"><span class="pre">auto_unbind</span></code> modes). Therefore,
if one wants to <cite>reset</cite> the network to its initial state after performing
some operations, all the <code class="docutils literal notranslate"><span class="pre">resultant</span></code> nodes should be deleted, and all the
tensors should return to its nodes. This is exactly what <a class="reference internal" href="#tensorkrowch.TensorNetwork.reset" title="tensorkrowch.TensorNetwork.reset"><code class="xref py py-meth docutils literal notranslate"><span class="pre">reset()</span></code></a> does.
Besides, since <code class="docutils literal notranslate"><span class="pre">auto_stack</span></code> and <code class="docutils literal notranslate"><span class="pre">auto_unbind</span></code> can change how the tensors
are stored, if one wants to change these modes, the network should be first
reset (this is already done automatically when changing the modes).</p>
<p class="rubric">Example</p>
<p>This is how one may define an <strong>MPS</strong>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MPS</span><span class="p">(</span><span class="n">tk</span><span class="o">.</span><span class="n">TensorNetwork</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_size</span><span class="p">,</span> <span class="n">uniform</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;MPS&#39;</span><span class="p">)</span>

        <span class="c1"># Create TN</span>
        <span class="n">input_nodes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">node</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">ParamNode</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
                                <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span>
                                            <span class="s1">&#39;input&#39;</span><span class="p">,</span>
                                            <span class="s1">&#39;right&#39;</span><span class="p">),</span>
                                <span class="n">name</span><span class="o">=</span><span class="s1">&#39;input_node&#39;</span><span class="p">,</span>
                                <span class="n">network</span><span class="o">=</span><span class="bp">self</span><span class="p">)</span>
            <span class="n">input_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_nodes</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">input_nodes</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;right&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">input_nodes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">][</span><span class="s1">&#39;left&#39;</span><span class="p">]</span>

        <span class="c1"># Periodic boundary conditions</span>
        <span class="n">output_node</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">ParamNode</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
                                   <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span>
                                               <span class="s1">&#39;output&#39;</span><span class="p">,</span>
                                               <span class="s1">&#39;right&#39;</span><span class="p">),</span>
                                   <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output_node&#39;</span><span class="p">,</span>
                                   <span class="n">network</span><span class="o">=</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">output_node</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">input_nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;left&#39;</span><span class="p">]</span>
        <span class="n">output_node</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">input_nodes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;right&#39;</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_nodes</span> <span class="o">=</span> <span class="n">input_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_node</span> <span class="o">=</span> <span class="n">output_node</span>

        <span class="k">if</span> <span class="n">uniform</span><span class="p">:</span>
            <span class="n">uniform_memory</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">ParamNode</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
                                          <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span>
                                                      <span class="s1">&#39;input&#39;</span><span class="p">,</span>
                                                      <span class="s1">&#39;right&#39;</span><span class="p">),</span>
                                          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;virtual_uniform&#39;</span><span class="p">,</span>
                                          <span class="n">network</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
                                          <span class="n">virtual</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">uniform_memory</span> <span class="o">=</span> <span class="n">uniform_memory</span>

        <span class="c1"># Initialize nodes</span>
        <span class="k">if</span> <span class="n">uniform</span><span class="p">:</span>
            <span class="n">std</span> <span class="o">=</span> <span class="mf">1e-9</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">uniform_memory</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">std</span>
            <span class="n">random_eye</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                     <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> <span class="o">*</span> <span class="n">std</span>
            <span class="n">random_eye</span>  <span class="o">=</span> <span class="n">random_eye</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                                 <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
            <span class="n">tensor</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">random_eye</span>

            <span class="n">uniform_memory</span><span class="o">.</span><span class="n">_unrestricted_set_tensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>

            <span class="c1"># Memory of each node is just a reference</span>
            <span class="c1"># to the uniform_memory tensor</span>
            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">input_nodes</span><span class="p">:</span>
                <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memory_nodes</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]]</span>
                <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;node_ref&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">uniform_memory</span>
                <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;full&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;index&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">std</span> <span class="o">=</span> <span class="mf">1e-9</span>
            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">input_nodes</span><span class="p">:</span>
                <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">std</span>
                <span class="n">random_eye</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                         <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> <span class="o">*</span> <span class="n">std</span>
                <span class="n">random_eye</span>  <span class="o">=</span> <span class="n">random_eye</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                                     <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
                <span class="n">tensor</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">random_eye</span>

                <span class="n">node</span><span class="o">.</span><span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span>

        <span class="n">eye_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span>
            <span class="n">output_node</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">output_node</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="n">output_node</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                        <span class="mi">1</span><span class="p">,</span>
                                        <span class="n">output_node</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]])</span>
        <span class="n">eye_tensor</span> <span class="o">=</span> <span class="n">eye_tensor</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">output_node</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">eye_tensor</span> <span class="o">+</span> <span class="n">std</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">output_node</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="n">output_node</span><span class="o">.</span><span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_nodes</span> <span class="o">=</span> <span class="n">input_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_node</span> <span class="o">=</span> <span class="n">output_node</span>

    <span class="k">def</span> <span class="nf">set_data_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">input_edges</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_nodes</span><span class="p">:</span>
            <span class="n">input_edges</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">])</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">set_data_nodes</span><span class="p">(</span><span class="n">input_edges</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">contract</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">stack_input</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_nodes</span><span class="p">)</span>
        <span class="n">stack_data</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_nodes</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>

        <span class="n">stack_input</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">stack_data</span><span class="p">[</span><span class="s1">&#39;feature&#39;</span><span class="p">]</span>
        <span class="n">stack_result</span> <span class="o">=</span> <span class="n">stack_input</span> <span class="o">@</span> <span class="n">stack_data</span>

        <span class="n">stack_result</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">stack_result</span><span class="p">)</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">stack_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">stack_result</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
            <span class="n">result</span> <span class="o">@=</span> <span class="n">node</span>
        <span class="n">result</span> <span class="o">@=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_node</span>

        <span class="k">return</span> <span class="n">result</span>
</pre></div>
</div>
<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.TensorNetwork.nodes">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">nodes</span></span><a class="headerlink" href="#tensorkrowch.TensorNetwork.nodes" title="Permalink to this definition">#</a></dt>
<dd><p>Returns dictionary with all the nodes belonging to the network (<code class="docutils literal notranslate"><span class="pre">leaf</span></code>,
<code class="docutils literal notranslate"><span class="pre">data</span></code>, <code class="docutils literal notranslate"><span class="pre">virtual</span></code> and <code class="docutils literal notranslate"><span class="pre">resultant</span></code>).</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.TensorNetwork.nodes_names">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">nodes_names</span></span><a class="headerlink" href="#tensorkrowch.TensorNetwork.nodes_names" title="Permalink to this definition">#</a></dt>
<dd><p>Returns list of names of all the nodes belonging to the network (<code class="docutils literal notranslate"><span class="pre">leaf</span></code>,
<code class="docutils literal notranslate"><span class="pre">data</span></code>, <code class="docutils literal notranslate"><span class="pre">virtual</span></code> and <code class="docutils literal notranslate"><span class="pre">resultant</span></code>).</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.TensorNetwork.leaf_nodes">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">leaf_nodes</span></span><a class="headerlink" href="#tensorkrowch.TensorNetwork.leaf_nodes" title="Permalink to this definition">#</a></dt>
<dd><p>Returns <code class="docutils literal notranslate"><span class="pre">leaf</span></code> nodes of the network.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.TensorNetwork.data_nodes">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">data_nodes</span></span><a class="headerlink" href="#tensorkrowch.TensorNetwork.data_nodes" title="Permalink to this definition">#</a></dt>
<dd><p>Returns <code class="docutils literal notranslate"><span class="pre">data</span></code> nodes of the network.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.TensorNetwork.virtual_nodes">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">virtual_nodes</span></span><a class="headerlink" href="#tensorkrowch.TensorNetwork.virtual_nodes" title="Permalink to this definition">#</a></dt>
<dd><p>Returns <code class="docutils literal notranslate"><span class="pre">virtual</span></code> nodes of the network.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.TensorNetwork.resultant_nodes">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">resultant_nodes</span></span><a class="headerlink" href="#tensorkrowch.TensorNetwork.resultant_nodes" title="Permalink to this definition">#</a></dt>
<dd><p>Returns <code class="docutils literal notranslate"><span class="pre">resultant</span></code> nodes of the network.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.TensorNetwork.edges">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">edges</span></span><a class="headerlink" href="#tensorkrowch.TensorNetwork.edges" title="Permalink to this definition">#</a></dt>
<dd><p>Returns list of dangling, non-batch edges of the network.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.TensorNetwork.auto_stack">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">auto_stack</span></span><a class="headerlink" href="#tensorkrowch.TensorNetwork.auto_stack" title="Permalink to this definition">#</a></dt>
<dd><p>Returns boolean indicating whether <code class="docutils literal notranslate"><span class="pre">auto_stack</span></code> is on/off.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="tensorkrowch.TensorNetwork.auto_unbind">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">auto_unbind</span></span><a class="headerlink" href="#tensorkrowch.TensorNetwork.auto_unbind" title="Permalink to this definition">#</a></dt>
<dd><p>Returns boolean indicating whether <code class="docutils literal notranslate"><span class="pre">auto_unbind</span></code> is on/off.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.TensorNetwork.delete_node">
<span class="sig-name descname"><span class="pre">delete_node</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">move_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#TensorNetwork.delete_node"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.TensorNetwork.delete_node" title="Permalink to this definition">#</a></dt>
<dd><p>Disconnects node from all its neighbours and removes it from the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>node</strong> (<a class="reference internal" href="#tensorkrowch.Node" title="tensorkrowch.Node"><em>Node</em></a><em> or </em><a class="reference internal" href="#tensorkrowch.ParamNode" title="tensorkrowch.ParamNode"><em>ParamNode</em></a>) – Node to be deleted.</p></li>
<li><p><strong>move_names</strong> (<em>bool</em>) – Boolean indicating whether names’ enumerations should be decreased
when removing a node (<code class="docutils literal notranslate"><span class="pre">True</span></code>) or kept as they are (<code class="docutils literal notranslate"><span class="pre">False</span></code>).
This is useful when several nodes are being modified at once, and
each resultant node has the same enumeration as the corresponding
original node.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.TensorNetwork.copy">
<span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#TensorNetwork.copy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.TensorNetwork.copy" title="Permalink to this definition">#</a></dt>
<dd><p>Copies the tensor network (via <code class="docutils literal notranslate"><span class="pre">copy.deepcopy</span></code>).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.TensorNetwork.parameterize">
<span class="sig-name descname"><span class="pre">parameterize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">set_param</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">override</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#TensorNetwork.parameterize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.TensorNetwork.parameterize" title="Permalink to this definition">#</a></dt>
<dd><p>Parameterizes all nodes of the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>set_param</strong> (<em>bool</em>) – Boolean indicating whether the tensor network has to be parameterized
(<code class="docutils literal notranslate"><span class="pre">True</span></code>) or de-parameterized (<code class="docutils literal notranslate"><span class="pre">False</span></code>).</p></li>
<li><p><strong>override</strong> (<em>bool</em>) – Boolean indicating whether the tensor network should be parameterized
in-place (<code class="docutils literal notranslate"><span class="pre">True</span></code>) or copied and then parameterized (<code class="docutils literal notranslate"><span class="pre">False</span></code>).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.TensorNetwork.trace">
<span class="sig-name descname"><span class="pre">trace</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">example</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#TensorNetwork.trace"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.TensorNetwork.trace" title="Permalink to this definition">#</a></dt>
<dd><p>Traces the tensor network contraction algorithm with two purposes:</p>
<ul class="simple">
<li><p>Create all the intermediate <code class="docutils literal notranslate"><span class="pre">resultant</span></code> nodes that result from
<a class="reference internal" href="operations.html#tensorkrowch.Operation" title="tensorkrowch.Operation"><code class="xref py py-class docutils literal notranslate"><span class="pre">Operations</span></code></a> so that in the next contractions only
the tensor-like operations have to be computed, thus saving a lot of time.</p></li>
<li><p>Keep track of the tensors that are used to compute operations, so that
intermediate results that are not useful any more can be deleted, thus
saving a lot of memory. This is achieved by constructing an <code class="docutils literal notranslate"><span class="pre">inverse_memory</span></code>
that, given a memory address, stores the nodes that use the tensor located
in that address.</p></li>
</ul>
<p>To trace a tensor network, it is necessary to provide the same arguments
that would be required in the forward call. In case the tensor network
is contracted with some input data, an example tensor with batch dimension
1 and filled with zeros would be enough to trace the contraction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>example</strong> (<em>torch.Tensor</em><em>, </em><em>optional</em>) – Example tensor used to trace the contraction of the tensor network.
In case the tensor network is contracted with some input data, an
example tensor with batch dimension 1 and filled with zeros would
be enough to trace the contraction.</p></li>
<li><p><strong>args</strong> – Arguments that might be used in <a class="reference internal" href="#tensorkrowch.TensorNetwork.contract" title="tensorkrowch.TensorNetwork.contract"><code class="xref py py-meth docutils literal notranslate"><span class="pre">contract()</span></code></a>.</p></li>
<li><p><strong>kwargs</strong> – Keyword arguments that might be used in <a class="reference internal" href="#tensorkrowch.TensorNetwork.contract" title="tensorkrowch.TensorNetwork.contract"><code class="xref py py-meth docutils literal notranslate"><span class="pre">contract()</span></code></a>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.TensorNetwork.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#TensorNetwork.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.TensorNetwork.reset" title="Permalink to this definition">#</a></dt>
<dd><p>Resets the tensor network as it was before tracing, contracting or, in
general, performing any non-in-place <a class="reference internal" href="operations.html#tensorkrowch.Operation" title="tensorkrowch.Operation"><code class="xref py py-class docutils literal notranslate"><span class="pre">Operation</span></code></a>. Hence, it deletes
all <code class="docutils literal notranslate"><span class="pre">resultant</span></code> and <code class="docutils literal notranslate"><span class="pre">virtual</span></code> nodes that are created when performing
an operation, and resets the <code class="docutils literal notranslate"><span class="pre">memory_nodes</span></code> of the network, so that
each node stores its corresponding tensor. Also, the lists of successors
of all <code class="docutils literal notranslate"><span class="pre">leaf</span></code> and <code class="docutils literal notranslate"><span class="pre">data</span></code> nodes are emptied.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.TensorNetwork.set_data_nodes">
<span class="sig-name descname"><span class="pre">set_data_nodes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_edges</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_batch_edges</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#TensorNetwork.set_data_nodes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.TensorNetwork.set_data_nodes" title="Permalink to this definition">#</a></dt>
<dd><p>Creates <code class="docutils literal notranslate"><span class="pre">data</span></code> nodes with as many batch edges as <code class="docutils literal notranslate"><span class="pre">num_batch_edges</span></code>
and one feature edge, and connects each of these feature edges to an
edge from the list <code class="docutils literal notranslate"><span class="pre">input_edges</span></code> (following the provided order).</p>
<p>If all the data nodes have the same shape, a <code class="docutils literal notranslate"><span class="pre">virtual</span></code> node will
contain all the tensors stacked in one, what will save some memory
and time in computations.</p>
<p>This method can be overriden in subclasses so that it is specified in
its implementation to which edges of the network the data nodes should
be connected. In this case, there is no need to call <code class="docutils literal notranslate"><span class="pre">set_data_nodes</span></code>
explicitly during training, since it will be done in the <a class="reference internal" href="#tensorkrowch.TensorNetwork.forward" title="tensorkrowch.TensorNetwork.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a>
call. Otherwise, it should be called before starting training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_edges</strong> (<em>list</em><em>[</em><em>int</em><em>] or </em><em>list</em><em>[</em><a class="reference internal" href="#tensorkrowch.Edge" title="tensorkrowch.Edge"><em>Edge</em></a><em>]</em>) – List of edges (or indices of <a class="reference internal" href="#tensorkrowch.TensorNetwork.edges" title="tensorkrowch.TensorNetwork.edges"><code class="xref py py-meth docutils literal notranslate"><span class="pre">edges()</span></code></a> if given as <code class="docutils literal notranslate"><span class="pre">int</span></code>) to
which the <code class="docutils literal notranslate"><span class="pre">data</span></code> nodes’ feature edges will be connected.</p></li>
<li><p><strong>num_batch_edges</strong> (<em>int</em>) – Number of batch edges in the <code class="docutils literal notranslate"><span class="pre">data</span></code> nodes.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.TensorNetwork.unset_data_nodes">
<span class="sig-name descname"><span class="pre">unset_data_nodes</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#TensorNetwork.unset_data_nodes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.TensorNetwork.unset_data_nodes" title="Permalink to this definition">#</a></dt>
<dd><p>Deletes all <code class="docutils literal notranslate"><span class="pre">data</span></code> nodes (and <code class="docutils literal notranslate"><span class="pre">virtual</span></code> ancillary nodes in case it
is necessary).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.TensorNetwork.add_data">
<span class="sig-name descname"><span class="pre">add_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#TensorNetwork.add_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.TensorNetwork.add_data" title="Permalink to this definition">#</a></dt>
<dd><p>Adds data tensor(s) to <code class="docutils literal notranslate"><span class="pre">data</span></code> nodes, that is, changes their tensors
by new data tensors when a new batch is provided.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<em>torch.Tensor</em><em> or </em><em>list</em><em>[</em><em>torch.Tensor</em><em>]</em>) – If all data nodes have the same shape, thus having its tensor stored
in “stack_data_memory”, <code class="docutils literal notranslate"><span class="pre">data</span></code> should be a tensor of shape
n_features x batch_size_{0} x … x batch_size_{n} x feature_size.
Otherwise, it should be a list with n_features elements, each of them
being a tensor with shape batch_size_{0} x … x batch_size_{n} x feature_size.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.TensorNetwork.contract">
<span class="sig-name descname"><span class="pre">contract</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#TensorNetwork.contract"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.TensorNetwork.contract" title="Permalink to this definition">#</a></dt>
<dd><p>Contracts the whole tensor network returning a single <code class="docutils literal notranslate"><span class="pre">Node</span></code>. This
method is not implemented and should be overriden in subclasses of
<a class="reference internal" href="#tensorkrowch.TensorNetwork" title="tensorkrowch.TensorNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorNetwork</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tensorkrowch.TensorNetwork.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tensorkrowch/components.html#TensorNetwork.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tensorkrowch.TensorNetwork.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Contract Tensor Network with input data with shape batch x n_features x feature.</p>
<p>Overrides the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method of <strong>PyTorch</strong> <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code>. Sets data
nodes automatically whenever <code class="docutils literal notranslate"><span class="pre">set_data_nodes</span></code> is overriden, adds data
tensor(s) to these nodes, and contracts the whole network according to
<a class="reference internal" href="#tensorkrowch.TensorNetwork.contract" title="tensorkrowch.TensorNetwork.contract"><code class="xref py py-meth docutils literal notranslate"><span class="pre">contract()</span></code></a>, returning a single <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>.</p>
<p>It can be called using the <code class="docutils literal notranslate"><span class="pre">__call__</span></code> operator <code class="docutils literal notranslate"><span class="pre">()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>torch.Tensor</em><em> or </em><em>list</em><em>[</em><em>torch.Tensor</em><em>]</em><em>, </em><em>optional</em>) – <p>If all data nodes have the same shape, thus having its tensor stored
in “stack_data_memory”, <code class="docutils literal notranslate"><span class="pre">data</span></code> should be a tensor of shape</p>
<div class="math notranslate nohighlight">
\[n_{features} \times batch\_size_{0} \times ... \times
batch\_size_{n} \times feature\_size.\]</div>
<p>Otherwise, it should be a list with <span class="math notranslate nohighlight">\(n_{features}\)</span> elements,
each of them being a tensor with shape</p>
<div class="math notranslate nohighlight">
\[batch\_size_{0} \times ... \times batch\_size_{n} \times
feature\_size.\]</div>
<p>Also, it is not necessary that the network has <code class="docutils literal notranslate"><span class="pre">data</span></code> nodes, thus
<code class="docutils literal notranslate"><span class="pre">None</span></code> is also valid.</p>
</p></li>
<li><p><strong>args</strong> – Arguments that might be used in <a class="reference internal" href="#tensorkrowch.TensorNetwork.contract" title="tensorkrowch.TensorNetwork.contract"><code class="xref py py-meth docutils literal notranslate"><span class="pre">contract()</span></code></a>.</p></li>
<li><p><strong>kwargs</strong> – Keyword arguments that might be used in <a class="reference internal" href="#tensorkrowch.TensorNetwork.contract" title="tensorkrowch.TensorNetwork.contract"><code class="xref py py-meth docutils literal notranslate"><span class="pre">contract()</span></code></a>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="api.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">API Reference</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="initializers.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Initializers</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By José Ramón Pareja Monturiol<br/>
  
      &copy; Copyright 2023, José Ramón Pareja Monturiol.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>