
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>How to subclass TensorNetwork to build Custom Models &#8212; TensorKrowch 1.1.5 documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="shortcut icon" href="../_static/tensorkrowch_favicon_light.svg"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Creating a Hybrid Neural-Tensor Network Model" href="6_mix_with_pytorch.html" />
    <link rel="prev" title="The different Types of Nodes (ADVANCED)" href="4_types_of_nodes.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/tensorkrowch_logo_light.svg" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Contents:
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../tutorials.html">
   Tutorials
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="0_first_steps.html">
     First Steps with TensorKrowch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="1_creating_tensor_network.html">
     Creating a Tensor Network in TensorKrowch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="2_contracting_tensor_network.html">
     Contracting and Differentiating the Tensor Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3_memory_management.html">
     How to save Memory and Time with TensorKrowch (ADVANCED)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="4_types_of_nodes.html">
     The different Types of Nodes (ADVANCED)
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     How to subclass TensorNetwork to build Custom Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="6_mix_with_pytorch.html">
     Creating a Hybrid Neural-Tensor Network Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../examples.html">
   Examples
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/training_mps.html">
     Training MPS in different ways
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/hybrid_tnn_model.html">
     Hybrid Tensorial Neural Network model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/tensorizing_nn.html">
     Tensorizing Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/mps_dmrg.html">
     DMRG-like training of MPS
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/mps_dmrg_hybrid.html">
     Hybrid DMRG-like training of MPS
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../api.html">
   API Reference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../components.html">
     Components
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../operations.html">
     Operations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../models.html">
     Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../initializers.html">
     Initializers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../embeddings.html">
     Embeddings
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../decompositions.html">
     Decompositions
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/joserapa98/tensorkrowch"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/tutorials/5_subclass_tensor_network.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#steps">
   Steps
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-components-of-a-tensornetwork-subclass">
     1. The Components of a TensorNetwork Subclass
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#putting-everything-together">
     2. Putting Everything Together
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#first-steps-with-our-custom-model">
     3. First Steps with our Custom Model
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>How to subclass TensorNetwork to build Custom Models</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#steps">
   Steps
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-components-of-a-tensornetwork-subclass">
     1. The Components of a TensorNetwork Subclass
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#putting-everything-together">
     2. Putting Everything Together
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#first-steps-with-our-custom-model">
     3. First Steps with our Custom Model
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="how-to-subclass-tensornetwork-to-build-custom-models">
<span id="tutorial-5"></span><h1>How to subclass TensorNetwork to build Custom Models<a class="headerlink" href="#how-to-subclass-tensornetwork-to-build-custom-models" title="Permalink to this headline">#</a></h1>
<p>In order to mimic the <code class="docutils literal notranslate"><span class="pre">PyTorch</span></code> convention, a model in <code class="docutils literal notranslate"><span class="pre">TensorKrowch</span></code>
is always a subclass of <code class="docutils literal notranslate"><span class="pre">TensorNetwork</span></code>, which is itself a subclass of
<code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>. Therefore, to create models properly and be able to
combine them easily with other <code class="docutils literal notranslate"><span class="pre">PyTorch</span></code> layers (like <code class="docutils literal notranslate"><span class="pre">torch.nn.Linear</span></code>)
one should learn what is the convention for creating subclasses of
<code class="docutils literal notranslate"><span class="pre">TensorNetwork</span></code>.</p>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">#</a></h2>
<p>In all the previous tutorials you have learned about the pieces of a
<code class="docutils literal notranslate"><span class="pre">TensorNetwork</span></code> such as <code class="docutils literal notranslate"><span class="pre">Nodes</span></code> and <code class="docutils literal notranslate"><span class="pre">Edges</span></code>. You should have already
built your first <cite>trainable</cite> <code class="docutils literal notranslate"><span class="pre">TensorNetwork</span></code>, even using nodes with
different <strong>roles</strong> (<code class="docutils literal notranslate"><span class="pre">leaf</span></code>, <code class="docutils literal notranslate"><span class="pre">data</span></code>, <code class="docutils literal notranslate"><span class="pre">virtual</span></code>). Not only have you
created a <code class="docutils literal notranslate"><span class="pre">TensorNetwork</span></code>, but contracted it using <code class="docutils literal notranslate"><span class="pre">Operations</span></code>.</p>
<p>In this tutorial we will put everything together to build your first custom
<code class="docutils literal notranslate"><span class="pre">TensorNetwork</span></code> model. You will also learn how to pass data through your
model, <code class="docutils literal notranslate"><span class="pre">trace</span></code> it, and <code class="docutils literal notranslate"><span class="pre">reset</span></code> it.</p>
</section>
<section id="steps">
<h2>Steps<a class="headerlink" href="#steps" title="Permalink to this headline">#</a></h2>
<ol class="arabic simple">
<li><p>The Components of a TensorNetwork Subclass.</p></li>
<li><p>Putting Everything Together.</p></li>
<li><p>First Steps with our Custom Model.</p></li>
</ol>
<section id="the-components-of-a-tensornetwork-subclass">
<h3>1. The Components of a TensorNetwork Subclass<a class="headerlink" href="#the-components-of-a-tensornetwork-subclass" title="Permalink to this headline">#</a></h3>
<p>Recall that the common way of defining models out of <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code> is
by defining a subclass where the <code class="docutils literal notranslate"><span class="pre">__init__</span></code> and <code class="docutils literal notranslate"><span class="pre">forward</span></code> methods are
overriden:</p>
<ul class="simple">
<li><p><strong>__init__</strong>: Defines the model itself (its layers, attributes, etc.).</p></li>
<li><dl class="simple">
<dt><strong>forward</strong>: Defines the way the model operates, that is, how the different</dt><dd><p>parts of the model might combine to get an output from a particular input.</p>
</dd>
</dl>
</li>
</ul>
<p>With <code class="docutils literal notranslate"><span class="pre">TensorNetwork</span></code>, the workflow is similar, though there are other
methods that should be overriden:</p>
<ul class="simple">
<li><p><strong>__init__</strong>: Defines the graph of the tensor network and initializes the
tensors of the nodes.</p></li>
<li><p><strong>set_data_nodes</strong> (optional): Creates the data nodes where the data
tensor(s) will be placed. Usually, it will just select the edges to which
the <code class="docutils literal notranslate"><span class="pre">data</span></code> nodes should be connected, and call the
<a class="reference internal" href="../components.html#tensorkrowch.TensorNetwork.set_data_nodes" title="tensorkrowch.TensorNetwork.set_data_nodes"><code class="xref py py-meth docutils literal notranslate"><span class="pre">parent</span> <span class="pre">method</span></code></a>.</p></li>
<li><p><strong>add_data</strong> (optional): Adds new data tensors that will be stored in <code class="docutils literal notranslate"><span class="pre">data</span></code>
nodes. Usually it will not be necessary to override this method, but if one
wants to customize how data is set into the <code class="docutils literal notranslate"><span class="pre">data</span></code> nodes, <code class="xref py py-meth docutils literal notranslate"><span class="pre">add_data()</span></code>
can be overriden.</p></li>
<li><p><strong>contract</strong>: Defines the contraction algorithm of the whole tensor network,
thus returning a single node. Very much like <code class="docutils literal notranslate"><span class="pre">forward</span></code> this is the main
method that describes how the components of the network are combined. Hence,
in <code class="docutils literal notranslate"><span class="pre">TensorNetwork</span></code> the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method shall not be overriden, since it
will just call <code class="docutils literal notranslate"><span class="pre">set_data_nodes</span></code>, if needed, <code class="docutils literal notranslate"><span class="pre">add_data</span></code> and <code class="docutils literal notranslate"><span class="pre">contract</span></code>,
and then it will return the tensor corresponding to the last <code class="docutils literal notranslate"><span class="pre">resultant</span></code>
node. Hence, the order in which <code class="docutils literal notranslate"><span class="pre">Operations</span></code> are called from <code class="docutils literal notranslate"><span class="pre">contract</span></code>
is important. The last operation must be the one returning the final node.</p></li>
</ul>
</section>
<section id="putting-everything-together">
<h3>2. Putting Everything Together<a class="headerlink" href="#putting-everything-together" title="Permalink to this headline">#</a></h3>
<p>Let’s create a class for Matrix Product States that we will use to classify
images:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">tensorkrowch</span> <span class="k">as</span> <span class="nn">tk</span>

<span class="k">class</span> <span class="nc">MPS</span><span class="p">(</span><span class="n">tk</span><span class="o">.</span><span class="n">TensorNetwork</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_size</span><span class="p">,</span> <span class="n">uniform</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        In the __init__ method we define the tensor network</span>
<span class="sd">        structure and initialize all the nodes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;MPS&#39;</span><span class="p">)</span>

        <span class="c1">#############</span>
        <span class="c1"># Create TN #</span>
        <span class="c1">#############</span>
        <span class="n">input_nodes</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Number of input nodes equal to number of pixels</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">node</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">ParamNode</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
                                <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">),</span>
                                <span class="n">name</span><span class="o">=</span><span class="s1">&#39;input_node&#39;</span><span class="p">,</span>
                                <span class="n">network</span><span class="o">=</span><span class="bp">self</span><span class="p">)</span>
            <span class="n">input_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_nodes</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">input_nodes</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;right&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">input_nodes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">][</span><span class="s1">&#39;left&#39;</span><span class="p">]</span>

        <span class="c1"># Output node is in the last position,</span>
        <span class="c1"># but that could be changed</span>
        <span class="n">output_node</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">ParamNode</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
                                   <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span>
                                       <span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;output&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">),</span>
                                   <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output_node&#39;</span><span class="p">,</span>
                                   <span class="n">network</span><span class="o">=</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">output_node</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">input_nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;left&#39;</span><span class="p">]</span>
        <span class="n">output_node</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">input_nodes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;right&#39;</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_nodes</span> <span class="o">=</span> <span class="n">input_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_node</span> <span class="o">=</span> <span class="n">output_node</span>

        <span class="c1"># If desired, the MPS can be uniform</span>
        <span class="k">if</span> <span class="n">uniform</span><span class="p">:</span>
            <span class="n">uniform_memory</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">ParamNode</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
                                          <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span>
                                              <span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">),</span>
                                          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;virtual_uniform&#39;</span><span class="p">,</span>
                                          <span class="n">network</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
                                          <span class="n">virtual</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">uniform_memory</span> <span class="o">=</span> <span class="n">uniform_memory</span>

        <span class="c1">####################</span>
        <span class="c1"># Initialize Nodes #</span>
        <span class="c1">####################</span>

        <span class="c1"># Input nodes</span>
        <span class="k">if</span> <span class="n">uniform</span><span class="p">:</span>
            <span class="n">std</span> <span class="o">=</span> <span class="mf">1e-9</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">uniform_memory</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">std</span>
            <span class="n">random_eye</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span>
                <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> <span class="o">*</span> <span class="n">std</span>
            <span class="n">random_eye</span> <span class="o">=</span> <span class="n">random_eye</span> <span class="o">+</span> \
                <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
            <span class="n">tensor</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">random_eye</span>

            <span class="n">uniform_memory</span><span class="o">.</span><span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span>

            <span class="c1"># Memory of each node is just a reference</span>
            <span class="c1"># to the uniform_memory tensor</span>
            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">input_nodes</span><span class="p">:</span>
                <span class="n">node</span><span class="o">.</span><span class="n">set_tensor_from</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">uniform_memory</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">std</span> <span class="o">=</span> <span class="mf">1e-9</span>
            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">input_nodes</span><span class="p">:</span>
                <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">std</span>
                <span class="n">random_eye</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span>
                    <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> <span class="o">*</span> <span class="n">std</span>
                <span class="n">random_eye</span> <span class="o">=</span> <span class="n">random_eye</span> <span class="o">+</span> \
                    <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
                <span class="n">tensor</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">random_eye</span>

                <span class="n">node</span><span class="o">.</span><span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span>

        <span class="c1"># Output node</span>
        <span class="n">eye_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">output_node</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">output_node</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>\
            <span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="n">output_node</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">output_node</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]])</span>
        <span class="n">eye_tensor</span> <span class="o">=</span> <span class="n">eye_tensor</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">output_node</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">eye_tensor</span> <span class="o">+</span> <span class="n">std</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">output_node</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="n">output_node</span><span class="o">.</span><span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_nodes</span> <span class="o">=</span> <span class="n">input_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_node</span> <span class="o">=</span> <span class="n">output_node</span>

    <span class="k">def</span> <span class="nf">set_data_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method is optional. If overriden, it should not have</span>
<span class="sd">        arguments other than self. Furthermore, we won&#39;t have to</span>
<span class="sd">        call it explicitly, since it will be called from forward.</span>

<span class="sd">        If not overriden, it should be explicitly called before</span>
<span class="sd">        training.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Select input edges where to put data nodes</span>
        <span class="n">input_edges</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_nodes</span><span class="p">:</span>
            <span class="n">input_edges</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">])</span>

        <span class="c1"># num_batch_edges inicates number of batch edges. Usually</span>
        <span class="c1"># it will be 1, for the batch of input data. But for</span>
        <span class="c1"># convolutional or sequential models it could be 2,</span>
        <span class="c1"># one edge for the batch of input data, and one for the</span>
        <span class="c1"># patches of sequence</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">set_data_nodes</span><span class="p">(</span><span class="n">input_edges</span><span class="p">,</span>
                                <span class="n">num_batch_edges</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">contract</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        In this method we define the contraction algorithm</span>
<span class="sd">        for the tensor network.</span>

<span class="sd">        The last operation computed must be the one returning</span>
<span class="sd">        the final node.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">stack_input</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_nodes</span><span class="p">)</span>
        <span class="n">stack_data</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_nodes</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>

        <span class="n">stack_input</span> <span class="o">^</span> <span class="n">stack_data</span>
        <span class="n">stack_result</span> <span class="o">=</span> <span class="n">stack_input</span> <span class="o">@</span> <span class="n">stack_data</span>

        <span class="n">stack_result</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">stack_result</span><span class="p">)</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">stack_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">stack_result</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
            <span class="n">result</span> <span class="o">@=</span> <span class="n">node</span>
        <span class="n">result</span> <span class="o">@=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_node</span>

        <span class="k">return</span> <span class="n">result</span>
</pre></div>
</div>
</section>
<section id="first-steps-with-our-custom-model">
<h3>3. First Steps with our Custom Model<a class="headerlink" href="#first-steps-with-our-custom-model" title="Permalink to this headline">#</a></h3>
<p>Now we can instantiate our model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">image_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">mps</span> <span class="o">=</span> <span class="n">MPS</span><span class="p">(</span><span class="n">image_size</span><span class="o">=</span><span class="n">image_size</span><span class="p">)</span>
</pre></div>
</div>
<p>Since our model is a subclass of <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>, we can take advantage of
its methods. For instance, we can easily send the model to the GPU:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">mps</span> <span class="o">=</span> <span class="n">mps</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>Note that only the <code class="docutils literal notranslate"><span class="pre">ParamNodes</span></code> are parameters of the model. Thus if your
model has other non-parametric <code class="docutils literal notranslate"><span class="pre">Nodes</span></code>, these won’t be sento to the GPU.
Instead, you should fill them with tensors that are already in the GPU.</p>
<p>Let’s get some images to use as our data:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">images</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>Images are tensors with shape <code class="docutils literal notranslate"><span class="pre">batch</span> <span class="pre">x</span> <span class="pre">height</span> <span class="pre">x</span> <span class="pre">width</span></code>. That is, for each
pixel, for each image in the batch we have just one value. Yet the nodes in
our tensor network are all tensors (vectors, matrices, etc.), so we need to
embed our pixel values into a greater vector space. That is, for each pixel,
for each image in the batch, we should have a vector (of dimension 3 in this
case, the size of <code class="docutils literal notranslate"><span class="pre">input</span></code> edges of the nodes in our <code class="docutils literal notranslate"><span class="pre">MPS</span></code> class).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">images</span> <span class="o">=</span> <span class="n">tk</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">poly</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>The input data for <code class="docutils literal notranslate"><span class="pre">TensorNetwork</span></code> subclasses, when <a class="reference internal" href="../components.html#tensorkrowch.TensorNetwork.add_data" title="tensorkrowch.TensorNetwork.add_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">add_data()</span></code></a>
has not been overriden, should have shape <code class="docutils literal notranslate"><span class="pre">batch_1</span> <span class="pre">x</span> <span class="pre">...</span> <span class="pre">x</span> <span class="pre">batch_n</span> <span class="pre">x</span>
<span class="pre">n_features</span> <span class="pre">x</span> <span class="pre">feature_dim</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
    <span class="mi">500</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>Before starting training, there are <strong>2 important steps</strong> you have to do
manually. First, set the memory management modes as you wish. Usually, for
training it will be faster to set <code class="docutils literal notranslate"><span class="pre">auto_stack</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code> and <code class="docutils literal notranslate"><span class="pre">auto_unbind</span></code>
to <code class="docutils literal notranslate"><span class="pre">False</span></code>. For inference, it will be faster to set both nodes to <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mps</span><span class="o">.</span><span class="n">auto_stack</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">mps</span><span class="o">.</span><span class="n">auto_unbind</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
<p>Secondly, you should <a class="reference internal" href="../components.html#tensorkrowch.TensorNetwork.trace" title="tensorkrowch.TensorNetwork.trace"><code class="xref py py-meth docutils literal notranslate"><span class="pre">trace()</span></code></a> the <code class="docutils literal notranslate"><span class="pre">TensorNetwork</span></code>. To
trace the network you need to pass an example input data through your model
in order to perform all the heavy computations (compute all <code class="docutils literal notranslate"><span class="pre">Operations</span></code> for
the first time, create all the intermediate <code class="docutils literal notranslate"><span class="pre">resultant</span></code> nodes, etc..). The
example can be simply a tensor of zeros with the appropiate shape. In fact,
the batch size can be set to 1:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">example</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">example</span> <span class="o">=</span> <span class="n">example</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">mps</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>
</pre></div>
</div>
<p>Finally everything is ready to train our model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Training loop</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
    <span class="o">...</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">mps</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>When the training has finished, and you want to save the model, you will need
to <a class="reference internal" href="../components.html#tensorkrowch.TensorNetwork.reset" title="tensorkrowch.TensorNetwork.reset"><code class="xref py py-meth docutils literal notranslate"><span class="pre">reset()</span></code></a> it. Note that when the model was traced, a
bunch of <code class="docutils literal notranslate"><span class="pre">resultant</span></code> nodes were added to the network. If now you instantiate
<code class="docutils literal notranslate"><span class="pre">MPS</span></code> again, all those nodes won’t be in the new instance. The networks
will have different nodes. Therefore, you need to <code class="docutils literal notranslate"><span class="pre">reset</span></code> the network to its
initial state, how it was before tracing:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mps</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</pre></div>
</div>
<p>With this, you can save your model and load it later:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Save</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">mps</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;mps.pt&#39;</span><span class="p">)</span>

<span class="c1"># Load</span>
<span class="n">new_mps</span> <span class="o">=</span> <span class="n">MPS</span><span class="p">(</span><span class="n">image_size</span><span class="p">)</span>
<span class="n">new_mps</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;mps.pt&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p>Of course, although you can create any tensor network you like, <code class="docutils literal notranslate"><span class="pre">TensorKrowch</span></code>
already comes with a handful of widely-known models that you can use:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../models.html#tensorkrowch.models.MPS" title="tensorkrowch.models.MPS"><code class="xref py py-class docutils literal notranslate"><span class="pre">MPS</span></code></a></p></li>
<li><p><a class="reference internal" href="../models.html#tensorkrowch.models.MPSLayer" title="tensorkrowch.models.MPSLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">MPSLayer</span></code></a></p></li>
<li><p><a class="reference internal" href="../models.html#tensorkrowch.models.MPO" title="tensorkrowch.models.MPO"><code class="xref py py-class docutils literal notranslate"><span class="pre">MPO</span></code></a></p></li>
<li><p><a class="reference internal" href="../models.html#tensorkrowch.models.PEPS" title="tensorkrowch.models.PEPS"><code class="xref py py-class docutils literal notranslate"><span class="pre">PEPS</span></code></a></p></li>
<li><p><a class="reference internal" href="../models.html#tensorkrowch.models.Tree" title="tensorkrowch.models.Tree"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tree</span></code></a></p></li>
</ul>
<p>There are also uniform and convolutional variants of the four models mentioned
above.</p>
</section>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="4_types_of_nodes.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">The different Types of Nodes (ADVANCED)</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="6_mix_with_pytorch.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Creating a Hybrid Neural-Tensor Network Model</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By José Ramón Pareja Monturiol<br/>
  
      &copy; Copyright 2023, José Ramón Pareja Monturiol.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>