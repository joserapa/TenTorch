
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>tensorkrowch.operations &#8212; TensorKrowch 00.00.01 documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="shortcut icon" href="../../_static/tensorkrowch_favicon_light.svg"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/tensorkrowch_logo_light.svg" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Contents:
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials.html">
   Tutorials
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/1_creating_tensor_network.html">
     Creating a Tensor Network in TensorKrowch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/2_contracting_tensor_network.html">
     Contracting and Differentiating the Tensor Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/3_memory_management.html">
     How to save Memory and Time with TensorKrowch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/4_types_of_nodes.html">
     The different Types of Nodes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/5_subclass_tensor_network.html">
     How to subclass TensorNetwork to build Custom Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/6_mix_with_pytorch.html">
     Creating a Hybrid Neural-Tensor Network Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../api.html">
   API Reference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../components.html">
     Components
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../operations.html">
     Operations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../models.html">
     Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../initializers.html">
     Initializers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../embeddings.html">
     Embeddings
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/joserapa98/tensorkrowch"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <h1>Source code for tensorkrowch.operations</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This script contains:</span>

<span class="sd">    Operation Class:</span>
<span class="sd">        * Operation</span>
<span class="sd">        </span>
<span class="sd">    Tensor-like operations:</span>
<span class="sd">        * permute</span>
<span class="sd">        * permute_           (in-place)</span>
<span class="sd">        * tprod</span>
<span class="sd">        * mul</span>
<span class="sd">        * add</span>
<span class="sd">        * sub</span>
<span class="sd">        </span>
<span class="sd">    Node-like operations:</span>
<span class="sd">        * split</span>
<span class="sd">        * split_             (in-place)</span>
<span class="sd">        * svd_               (in-place) (edge operation)</span>
<span class="sd">        * svdr_              (in-place) (edge operation)</span>
<span class="sd">        * qr_                (in-place) (edge operation)</span>
<span class="sd">        * rq_                (in-place) (edge operation)</span>
<span class="sd">        * contract_edges</span>
<span class="sd">        * contract_          (in-place) (edge operation)</span>
<span class="sd">        * get_shared_edges</span>
<span class="sd">        * contract_between</span>
<span class="sd">        * contract_between_  (in-place)</span>
<span class="sd">        * stack</span>
<span class="sd">        * unbind</span>
<span class="sd">        * einsum</span>
<span class="sd">        * stacked_einsum</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Text</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>
<span class="kn">import</span> <span class="nn">types</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">opt_einsum</span>

<span class="kn">from</span> <span class="nn">tensorkrowch.components</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">tensorkrowch.utils</span> <span class="kn">import</span> <span class="p">(</span><span class="n">inverse_permutation</span><span class="p">,</span> <span class="n">is_permutation</span><span class="p">,</span>
                                <span class="n">list2slice</span><span class="p">,</span> <span class="n">permute_list</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">tensorkrowch</span> <span class="kn">import</span> <span class="n">_C</span>


<span class="n">Ax</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Text</span><span class="p">,</span> <span class="n">Axis</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">copy_func</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns a function with the same code, defaults, closure and name.&quot;&quot;&quot;</span>
    <span class="n">fn</span> <span class="o">=</span> <span class="n">types</span><span class="o">.</span><span class="n">FunctionType</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="vm">__code__</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="vm">__globals__</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                            <span class="n">f</span><span class="o">.</span><span class="vm">__defaults__</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="vm">__closure__</span><span class="p">)</span>

    <span class="c1"># In case f was given attrs (note this dict is a shallow copy)</span>
    <span class="n">fn</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fn</span>

<span class="c1">###############################################################################</span>
<span class="c1">#                               OPERATION CLASS                               #</span>
<span class="c1">###############################################################################</span>


<div class="viewcode-block" id="Operation"><a class="viewcode-back" href="../../operations.html#tensorkrowch.Operation">[docs]</a><span class="k">class</span> <span class="nc">Operation</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class for node operations.</span>
<span class="sd">    </span>
<span class="sd">    A node operation is made up of two functions, the one that is executed the</span>
<span class="sd">    first time the operation is called and the one that is executed in every</span>
<span class="sd">    other call (with the same arguments). Both functions are usually similar,</span>
<span class="sd">    though the former computes extra things regarding the creation of the</span>
<span class="sd">    ``resultant`` nodes and some auxilliary operations whose result will be the</span>
<span class="sd">    same in every call (e.g. when contracting two nodes, maybe a permutation of</span>
<span class="sd">    the tensors should be first performed; how this permutation is carried out</span>
<span class="sd">    is always the same, though the tensors themselves are different).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    name : str</span>
<span class="sd">        Name of the operation. It cannot coincide with another operation&#39;s name.</span>
<span class="sd">        Operation names can be checked via ``net.operations``.</span>
<span class="sd">    check_first : callable</span>
<span class="sd">        Function that checks if the operation has been called at least one time.</span>
<span class="sd">    func1 : callable</span>
<span class="sd">        Function that is called the first time the operation is performed.</span>
<span class="sd">    func2 : callable</span>
<span class="sd">        Function that is called the next times the operation is performed.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n">Text</span><span class="p">,</span> <span class="n">check_first</span><span class="p">,</span> <span class="n">func1</span><span class="p">,</span> <span class="n">func2</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">check_first</span><span class="p">,</span> <span class="n">Callable</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">func1</span><span class="p">,</span> <span class="n">Callable</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">func2</span><span class="p">,</span> <span class="n">Callable</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">func1</span> <span class="o">=</span> <span class="n">func1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">func2</span> <span class="o">=</span> <span class="n">func2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">check_first</span> <span class="o">=</span> <span class="n">check_first</span>

        <span class="c1"># Operations could be overriden</span>
        <span class="n">TensorNetwork</span><span class="o">.</span><span class="n">operations</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">successor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">check_first</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">successor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">func1</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">args</span> <span class="o">=</span> <span class="p">[</span><span class="n">successor</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">func2</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<span class="c1">###############################################################################</span>
<span class="c1">#                           TENSOR-LIKE OPERATIONS                            #</span>
<span class="c1">###############################################################################</span>

<span class="c1">#################################   PERMUTE    ################################</span>
<span class="k">def</span> <span class="nf">_check_first_permute</span><span class="p">(</span><span class="n">node</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
                         <span class="n">axes</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Ax</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Successor</span><span class="p">]:</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;node&#39;</span><span class="p">:</span> <span class="n">node</span><span class="p">,</span>
              <span class="s1">&#39;axes&#39;</span><span class="p">:</span> <span class="n">axes</span><span class="p">}</span>
    <span class="k">if</span> <span class="s1">&#39;permute&#39;</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">_successors</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">succ</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;permute&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">succ</span><span class="o">.</span><span class="n">kwargs</span> <span class="o">==</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">succ</span>
    <span class="k">return</span> <span class="kc">None</span>


<span class="k">def</span> <span class="nf">_permute_first</span><span class="p">(</span><span class="n">node</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span> <span class="n">axes</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Ax</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
    <span class="n">axes_nums</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">:</span>
        <span class="n">axes_nums</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">get_axis_num</span><span class="p">(</span><span class="n">axis</span><span class="p">))</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_permutation</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">axes_nums</span><span class="p">))),</span> <span class="n">axes_nums</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The provided list of axis is not a permutation of the&#39;</span>
                         <span class="s1">&#39; axes of the node&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">new_node</span> <span class="o">=</span> <span class="n">Node</span><span class="o">.</span><span class="n">_create_resultant</span><span class="p">(</span>
            <span class="n">axes_names</span><span class="o">=</span><span class="n">permute_list</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">axes_names</span><span class="p">,</span> <span class="n">axes_nums</span><span class="p">),</span>
            <span class="n">name</span><span class="o">=</span><span class="s1">&#39;permute&#39;</span><span class="p">,</span>
            <span class="n">network</span><span class="o">=</span><span class="n">node</span><span class="o">.</span><span class="n">_network</span><span class="p">,</span>
            <span class="n">tensor</span><span class="o">=</span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span>
                <span class="n">axes_nums</span><span class="p">),</span>
            <span class="n">edges</span><span class="o">=</span><span class="n">permute_list</span><span class="p">(</span>
                <span class="n">node</span><span class="o">.</span><span class="n">_edges</span><span class="p">,</span> <span class="n">axes_nums</span><span class="p">),</span>
            <span class="n">node1_list</span><span class="o">=</span><span class="n">permute_list</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">is_node1</span><span class="p">(),</span> <span class="n">axes_nums</span><span class="p">))</span>

    <span class="c1"># Create successor</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">_network</span>
    <span class="n">successor</span> <span class="o">=</span> <span class="n">Successor</span><span class="p">(</span><span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;node&#39;</span><span class="p">:</span> <span class="n">node</span><span class="p">,</span>
                                  <span class="s1">&#39;axes&#39;</span><span class="p">:</span> <span class="n">axes</span><span class="p">},</span>
                          <span class="n">child</span><span class="o">=</span><span class="n">new_node</span><span class="p">,</span>
                          <span class="n">hints</span><span class="o">=</span><span class="n">axes_nums</span><span class="p">)</span>

    <span class="c1"># Add successor to parent</span>
    <span class="k">if</span> <span class="s1">&#39;permute&#39;</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">_successors</span><span class="p">:</span>
        <span class="n">node</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;permute&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">successor</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">node</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;permute&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">successor</span><span class="p">]</span>

    <span class="c1"># Add operation to list of performed operations of TN</span>
    <span class="n">net</span><span class="o">.</span><span class="n">_seq_ops</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;permute&#39;</span><span class="p">,</span> <span class="n">successor</span><span class="o">.</span><span class="n">kwargs</span><span class="p">))</span>

    <span class="c1"># Record in inverse_memory while tracing</span>
    <span class="n">node</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">new_node</span>


<span class="k">def</span> <span class="nf">_permute_next</span><span class="p">(</span><span class="n">successor</span><span class="p">:</span> <span class="n">Successor</span><span class="p">,</span>
                  <span class="n">node</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
                  <span class="n">axes</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Ax</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
    <span class="c1"># All arguments are mandatory though some might not be used</span>
    <span class="n">new_tensor</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">successor</span><span class="o">.</span><span class="n">hints</span><span class="p">)</span>
    <span class="n">child</span> <span class="o">=</span> <span class="n">successor</span><span class="o">.</span><span class="n">child</span>
    <span class="n">child</span><span class="o">.</span><span class="n">_direct_set_tensor</span><span class="p">(</span><span class="n">new_tensor</span><span class="p">)</span>

    <span class="c1"># Record in inverse_memory while contracting</span>
    <span class="c1"># (to delete memory if possible)</span>
    <span class="n">node</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">child</span>


<span class="n">permute_op</span> <span class="o">=</span> <span class="n">Operation</span><span class="p">(</span><span class="s1">&#39;permute&#39;</span><span class="p">,</span>
                       <span class="n">_check_first_permute</span><span class="p">,</span>
                       <span class="n">_permute_first</span><span class="p">,</span>
                       <span class="n">_permute_next</span><span class="p">)</span>


<div class="viewcode-block" id="permute"><a class="viewcode-back" href="../../operations.html#tensorkrowch.permute">[docs]</a><span class="k">def</span> <span class="nf">permute</span><span class="p">(</span><span class="n">node</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span> <span class="n">axes</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Ax</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Permutes the nodes&#39; tensor, as well as its axes and edges to match the new</span>
<span class="sd">    shape.</span>

<span class="sd">    See `permute &lt;https://pytorch.org/docs/stable/generated/torch.permute.html&gt;`_.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation are called ``&quot;permute&quot;``. The node</span>
<span class="sd">    that keeps information about the :class:`Successor` is ``node``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    node: Node or ParamNode</span>
<span class="sd">        Node whose tensor is to be permuted.</span>
<span class="sd">    axes: list[int, str or Axis]</span>
<span class="sd">        List of axes in the permuted order.</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Node</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; node = tk.randn((2, 5, 7))</span>
<span class="sd">    &gt;&gt;&gt; result = tk.permute(node, (2, 0, 1))</span>
<span class="sd">    &gt;&gt;&gt; result.shape</span>
<span class="sd">    torch.Size([7, 2, 5])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">permute_op</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">axes</span><span class="p">)</span></div>


<span class="n">permute_node</span> <span class="o">=</span> <span class="n">copy_func</span><span class="p">(</span><span class="n">permute</span><span class="p">)</span>
<span class="n">permute_node</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> \
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Permutes the nodes&#39; tensor, as well as its axes and edges to match the new</span>
<span class="sd">    shape.</span>
<span class="sd">    </span>
<span class="sd">    See `permute &lt;https://pytorch.org/docs/stable/generated/torch.permute.html&gt;`_.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation are called ``&quot;permute&quot;``. The node</span>
<span class="sd">    that keeps information about the :class:`Successor` is ``self``.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    axes: list[int, str or Axis]</span>
<span class="sd">        List of axes in the permuted order.</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Node</span>
<span class="sd">        </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; node = tk.randn((2, 5, 7))</span>
<span class="sd">    &gt;&gt;&gt; result = node.permute((2, 0, 1))</span>
<span class="sd">    &gt;&gt;&gt; result.shape</span>
<span class="sd">    torch.Size([7, 2, 5])</span>
<span class="sd">    &quot;&quot;&quot;</span>

<span class="n">AbstractNode</span><span class="o">.</span><span class="n">permute</span> <span class="o">=</span> <span class="n">permute_node</span>


<div class="viewcode-block" id="permute_"><a class="viewcode-back" href="../../operations.html#tensorkrowch.permute_">[docs]</a><span class="k">def</span> <span class="nf">permute_</span><span class="p">(</span><span class="n">node</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span> <span class="n">axes</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Ax</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Permutes the nodes&#39; tensor, as well as its axes and edges to match the new</span>
<span class="sd">    shape (in-place).</span>

<span class="sd">    Following the **PyTorch** convention, names of functions ended with an</span>
<span class="sd">    underscore indicate **in-place** operations.</span>

<span class="sd">    See `permute &lt;https://pytorch.org/docs/stable/generated/torch.permute.html&gt;`_.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation use the same name as ``node``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    node: Node or ParamNode</span>
<span class="sd">        Node whose tensor is to be permuted.</span>
<span class="sd">    axes: list[int, str or Axis]</span>
<span class="sd">        List of axes in the permuted order.</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Node</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; node = tk.randn((2, 5, 7))</span>
<span class="sd">    &gt;&gt;&gt; node = tk.permute_(node, (2, 0, 1))</span>
<span class="sd">    &gt;&gt;&gt; node.shape</span>
<span class="sd">    torch.Size([7, 2, 5])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">axes_nums</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">:</span>
        <span class="n">axes_nums</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">get_axis_num</span><span class="p">(</span><span class="n">axis</span><span class="p">))</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_permutation</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">axes_nums</span><span class="p">))),</span> <span class="n">axes_nums</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The provided list of axis is not a permutation of the&#39;</span>
                         <span class="s1">&#39; axes of the node&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">new_node</span> <span class="o">=</span> <span class="n">Node</span><span class="p">(</span><span class="n">axes_names</span><span class="o">=</span><span class="n">permute_list</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">axes_names</span><span class="p">,</span> <span class="n">axes_nums</span><span class="p">),</span>
                        <span class="n">name</span><span class="o">=</span><span class="n">node</span><span class="o">.</span><span class="n">_name</span><span class="p">,</span>
                        <span class="n">override_node</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">network</span><span class="o">=</span><span class="n">node</span><span class="o">.</span><span class="n">_network</span><span class="p">,</span>
                        <span class="n">override_edges</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">tensor</span><span class="o">=</span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span>
                            <span class="n">axes_nums</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
                        <span class="n">edges</span><span class="o">=</span><span class="n">permute_list</span><span class="p">(</span>
                            <span class="n">node</span><span class="o">.</span><span class="n">_edges</span><span class="p">,</span> <span class="n">axes_nums</span><span class="p">),</span>
                        <span class="n">node1_list</span><span class="o">=</span><span class="n">permute_list</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">is_node1</span><span class="p">(),</span> <span class="n">axes_nums</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">new_node</span></div>


<span class="n">permute_node_</span> <span class="o">=</span> <span class="n">copy_func</span><span class="p">(</span><span class="n">permute_</span><span class="p">)</span>
<span class="n">permute_node_</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> \
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Permutes the nodes&#39; tensor, as well as its axes and edges to match the new</span>
<span class="sd">    shape (in-place).</span>

<span class="sd">    Following the **PyTorch** convention, names of functions ended with an</span>
<span class="sd">    underscore indicate **in-place** operations.</span>

<span class="sd">    See `permute &lt;https://pytorch.org/docs/stable/generated/torch.permute.html&gt;`_.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation use the same name as ``node``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    axes: list[int, str or Axis]</span>
<span class="sd">        List of axes in the permuted order.</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Node</span>
<span class="sd">        </span>
<span class="sd">    &gt;&gt;&gt; node = tk.randn((2, 5, 7))</span>
<span class="sd">    &gt;&gt;&gt; node = node.permute_((2, 0, 1))</span>
<span class="sd">    &gt;&gt;&gt; node.shape</span>
<span class="sd">    torch.Size([7, 2, 5])</span>
<span class="sd">    &quot;&quot;&quot;</span>

<span class="n">AbstractNode</span><span class="o">.</span><span class="n">permute_</span> <span class="o">=</span> <span class="n">permute_node_</span>


<span class="c1">##################################   TPROD    #################################</span>
<span class="k">def</span> <span class="nf">_check_first_tprod</span><span class="p">(</span><span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
                       <span class="n">node2</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Successor</span><span class="p">]:</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;node1&#39;</span><span class="p">:</span> <span class="n">node1</span><span class="p">,</span>
              <span class="s1">&#39;node2&#39;</span><span class="p">:</span> <span class="n">node2</span><span class="p">}</span>
    <span class="k">if</span> <span class="s1">&#39;tprod&#39;</span> <span class="ow">in</span> <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">succ</span> <span class="ow">in</span> <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;tprod&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">succ</span><span class="o">.</span><span class="n">kwargs</span> <span class="o">==</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">succ</span>
    <span class="k">return</span> <span class="kc">None</span>


<span class="k">def</span> <span class="nf">_tprod_first</span><span class="p">(</span><span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span> <span class="n">node2</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">node1</span><span class="o">.</span><span class="n">_network</span> <span class="o">!=</span> <span class="n">node2</span><span class="o">.</span><span class="n">_network</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Nodes must be in the same network&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">node2</span> <span class="ow">in</span> <span class="n">node1</span><span class="o">.</span><span class="n">neighbours</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Tensor product cannot be performed between connected&#39;</span>
                         <span class="s1">&#39; nodes&#39;</span><span class="p">)</span>

    <span class="n">new_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">node1</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
                             <span class="n">node2</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">node1</span><span class="o">.</span><span class="n">_shape</span><span class="p">)</span> <span class="o">+</span>
                                                            <span class="nb">list</span><span class="p">(</span><span class="n">node2</span><span class="o">.</span><span class="n">_shape</span><span class="p">)))</span>
    <span class="n">new_node</span> <span class="o">=</span> <span class="n">Node</span><span class="o">.</span><span class="n">_create_resultant</span><span class="p">(</span>
        <span class="n">axes_names</span><span class="o">=</span><span class="n">node1</span><span class="o">.</span><span class="n">axes_names</span> <span class="o">+</span> <span class="n">node2</span><span class="o">.</span><span class="n">axes_names</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;tprod&#39;</span><span class="p">,</span>
        <span class="n">network</span><span class="o">=</span><span class="n">node1</span><span class="o">.</span><span class="n">_network</span><span class="p">,</span>
        <span class="n">tensor</span><span class="o">=</span><span class="n">new_tensor</span><span class="p">,</span>
        <span class="n">edges</span><span class="o">=</span><span class="n">node1</span><span class="o">.</span><span class="n">_edges</span> <span class="o">+</span> <span class="n">node2</span><span class="o">.</span><span class="n">_edges</span><span class="p">,</span>
        <span class="n">node1_list</span><span class="o">=</span><span class="n">node1</span><span class="o">.</span><span class="n">is_node1</span><span class="p">()</span> <span class="o">+</span> <span class="n">node2</span><span class="o">.</span><span class="n">is_node1</span><span class="p">())</span>

    <span class="c1"># Create successor</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">node1</span><span class="o">.</span><span class="n">_network</span>
    <span class="n">successor</span> <span class="o">=</span> <span class="n">Successor</span><span class="p">(</span><span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;node1&#39;</span><span class="p">:</span> <span class="n">node1</span><span class="p">,</span>
                                  <span class="s1">&#39;node2&#39;</span><span class="p">:</span> <span class="n">node2</span><span class="p">},</span>
                          <span class="n">child</span><span class="o">=</span><span class="n">new_node</span><span class="p">)</span>

    <span class="c1"># Add successor to parent</span>
    <span class="k">if</span> <span class="s1">&#39;tprod&#39;</span> <span class="ow">in</span> <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">:</span>
        <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;tprod&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">successor</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;tprod&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">successor</span><span class="p">]</span>

    <span class="c1"># Add operation to list of performed operations of TN</span>
    <span class="n">net</span><span class="o">.</span><span class="n">_seq_ops</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;tprod&#39;</span><span class="p">,</span> <span class="n">successor</span><span class="o">.</span><span class="n">kwargs</span><span class="p">))</span>

    <span class="c1"># Record in inverse_memory while tracing</span>
    <span class="n">node1</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>
    <span class="n">node2</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">new_node</span>


<span class="k">def</span> <span class="nf">_tprod_next</span><span class="p">(</span><span class="n">successor</span><span class="p">:</span> <span class="n">Successor</span><span class="p">,</span>
                <span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
                <span class="n">node2</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
    <span class="n">new_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">node1</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
                             <span class="n">node2</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">node1</span><span class="o">.</span><span class="n">_shape</span><span class="p">)</span> <span class="o">+</span>
                                                            <span class="nb">list</span><span class="p">(</span><span class="n">node2</span><span class="o">.</span><span class="n">_shape</span><span class="p">)))</span>
    <span class="n">child</span> <span class="o">=</span> <span class="n">successor</span><span class="o">.</span><span class="n">child</span>
    <span class="n">child</span><span class="o">.</span><span class="n">_direct_set_tensor</span><span class="p">(</span><span class="n">new_tensor</span><span class="p">)</span>

    <span class="c1"># Record in inverse_memory while contracting</span>
    <span class="c1"># (to delete memory if possible)</span>
    <span class="n">node1</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>
    <span class="n">node2</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">child</span>


<span class="n">tprod_op</span> <span class="o">=</span> <span class="n">Operation</span><span class="p">(</span><span class="s1">&#39;tprod&#39;</span><span class="p">,</span> <span class="n">_check_first_tprod</span><span class="p">,</span> <span class="n">_tprod_first</span><span class="p">,</span> <span class="n">_tprod_next</span><span class="p">)</span>


<div class="viewcode-block" id="tprod"><a class="viewcode-back" href="../../operations.html#tensorkrowch.tprod">[docs]</a><span class="k">def</span> <span class="nf">tprod</span><span class="p">(</span><span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span> <span class="n">node2</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Tensor product between two nodes. It can also be performed using the</span>
<span class="sd">    operator ``%``.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation are called ``&quot;tprod&quot;``. The node</span>
<span class="sd">    that keeps information about the :class:`Successor` is ``node1``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    node1 : Node or ParamNode</span>
<span class="sd">        First node to be multiplied. Its edges will appear first in the</span>
<span class="sd">        resultant node.</span>
<span class="sd">    node2 : Node or ParamNode</span>
<span class="sd">        Second node to be multiplied. Its edges will appear second in the</span>
<span class="sd">        resultant node.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Node</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; net = tk.TensorNetwork()</span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.randn((2, 3), network=net)</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.randn((4, 5), network=net)</span>
<span class="sd">    &gt;&gt;&gt; result = nodeA % nodeB</span>
<span class="sd">    &gt;&gt;&gt; result.shape</span>
<span class="sd">    torch.Size([2, 3, 4, 5])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">tprod_op</span><span class="p">(</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">)</span></div>


<span class="n">tprod_node</span> <span class="o">=</span> <span class="n">copy_func</span><span class="p">(</span><span class="n">tprod</span><span class="p">)</span>
<span class="n">tprod_node</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> \
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Tensor product between two nodes. It can also be performed using the</span>
<span class="sd">    operator ``%``.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation are called ``&quot;tprod&quot;``. The node</span>
<span class="sd">    that keeps information about the :class:`Successor` is ``self``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    node2 : Node or ParamNode</span>
<span class="sd">        Second node to be multiplied. Its edges will appear second in the</span>
<span class="sd">        resultant node.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Node</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; net = tk.TensorNetwork()</span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.randn((2, 3), network=net)</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.randn((4, 5), network=net)</span>
<span class="sd">    &gt;&gt;&gt; result = nodeA.tprod(nodeB)</span>
<span class="sd">    &gt;&gt;&gt; result.shape</span>
<span class="sd">    torch.Size([2, 3, 4, 5])</span>
<span class="sd">    &quot;&quot;&quot;</span>

<span class="n">AbstractNode</span><span class="o">.</span><span class="fm">__mod__</span> <span class="o">=</span> <span class="n">tprod_node</span>


<span class="c1">###################################   MUL    ##################################</span>
<span class="k">def</span> <span class="nf">_check_first_mul</span><span class="p">(</span><span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
                     <span class="n">node2</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Successor</span><span class="p">]:</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;node1&#39;</span><span class="p">:</span> <span class="n">node1</span><span class="p">,</span>
              <span class="s1">&#39;node2&#39;</span><span class="p">:</span> <span class="n">node2</span><span class="p">}</span>
    <span class="k">if</span> <span class="s1">&#39;mul&#39;</span> <span class="ow">in</span> <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">succ</span> <span class="ow">in</span> <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;mul&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">succ</span><span class="o">.</span><span class="n">kwargs</span> <span class="o">==</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">succ</span>
    <span class="k">return</span> <span class="kc">None</span>


<span class="k">def</span> <span class="nf">_mul_first</span><span class="p">(</span><span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span> <span class="n">node2</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">node1</span><span class="o">.</span><span class="n">_network</span> <span class="o">!=</span> <span class="n">node2</span><span class="o">.</span><span class="n">_network</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Nodes must be in the same network&#39;</span><span class="p">)</span>

    <span class="n">new_tensor</span> <span class="o">=</span> <span class="n">node1</span><span class="o">.</span><span class="n">tensor</span> <span class="o">*</span> <span class="n">node2</span><span class="o">.</span><span class="n">tensor</span>
    <span class="n">new_node</span> <span class="o">=</span> <span class="n">Node</span><span class="o">.</span><span class="n">_create_resultant</span><span class="p">(</span><span class="n">axes_names</span><span class="o">=</span><span class="n">node1</span><span class="o">.</span><span class="n">axes_names</span><span class="p">,</span>
                                      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;mul&#39;</span><span class="p">,</span>
                                      <span class="n">network</span><span class="o">=</span><span class="n">node1</span><span class="o">.</span><span class="n">_network</span><span class="p">,</span>
                                      <span class="n">tensor</span><span class="o">=</span><span class="n">new_tensor</span><span class="p">,</span>
                                      <span class="n">edges</span><span class="o">=</span><span class="n">node1</span><span class="o">.</span><span class="n">_edges</span><span class="p">,</span>
                                      <span class="n">node1_list</span><span class="o">=</span><span class="n">node1</span><span class="o">.</span><span class="n">is_node1</span><span class="p">())</span>

    <span class="c1"># Create successor</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">node1</span><span class="o">.</span><span class="n">_network</span>
    <span class="n">successor</span> <span class="o">=</span> <span class="n">Successor</span><span class="p">(</span><span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;node1&#39;</span><span class="p">:</span> <span class="n">node1</span><span class="p">,</span>
                                  <span class="s1">&#39;node2&#39;</span><span class="p">:</span> <span class="n">node2</span><span class="p">},</span>
                          <span class="n">child</span><span class="o">=</span><span class="n">new_node</span><span class="p">)</span>

    <span class="c1"># Add successor to parent</span>
    <span class="k">if</span> <span class="s1">&#39;mul&#39;</span> <span class="ow">in</span> <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">:</span>
        <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;mul&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">successor</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;mul&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">successor</span><span class="p">]</span>

    <span class="c1"># Add operation to list of performed operations of TN</span>
    <span class="n">net</span><span class="o">.</span><span class="n">_seq_ops</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;mul&#39;</span><span class="p">,</span> <span class="n">successor</span><span class="o">.</span><span class="n">kwargs</span><span class="p">))</span>

    <span class="c1"># Record in inverse_memory while tracing</span>
    <span class="n">node1</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>
    <span class="n">node2</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">new_node</span>


<span class="k">def</span> <span class="nf">_mul_next</span><span class="p">(</span><span class="n">successor</span><span class="p">:</span> <span class="n">Successor</span><span class="p">,</span>
              <span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
              <span class="n">node2</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
    <span class="n">new_tensor</span> <span class="o">=</span> <span class="n">node1</span><span class="o">.</span><span class="n">tensor</span> <span class="o">*</span> <span class="n">node2</span><span class="o">.</span><span class="n">tensor</span>
    <span class="n">child</span> <span class="o">=</span> <span class="n">successor</span><span class="o">.</span><span class="n">child</span>
    <span class="n">child</span><span class="o">.</span><span class="n">_direct_set_tensor</span><span class="p">(</span><span class="n">new_tensor</span><span class="p">)</span>

    <span class="c1"># Record in inverse_memory while contracting</span>
    <span class="c1"># (to delete memory if possible)</span>
    <span class="n">node1</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>
    <span class="n">node2</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">child</span>


<span class="n">mul_op</span> <span class="o">=</span> <span class="n">Operation</span><span class="p">(</span><span class="s1">&#39;mul&#39;</span><span class="p">,</span> <span class="n">_check_first_mul</span><span class="p">,</span> <span class="n">_mul_first</span><span class="p">,</span> <span class="n">_mul_next</span><span class="p">)</span>


<div class="viewcode-block" id="mul"><a class="viewcode-back" href="../../operations.html#tensorkrowch.mul">[docs]</a><span class="k">def</span> <span class="nf">mul</span><span class="p">(</span><span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span> <span class="n">node2</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Element-wise product between two nodes. It can also be performed using the</span>
<span class="sd">    operator ``*``.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation are called ``&quot;mul&quot;``. The node</span>
<span class="sd">    that keeps information about the :class:`Successor` is ``node1``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    node1 : Node or ParamNode</span>
<span class="sd">        First node to be multiplied. Its edges will appear in the resultant node.</span>
<span class="sd">    node2 : Node or ParamNode</span>
<span class="sd">        Second node to be multiplied.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Node</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; net = tk.TensorNetwork()</span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.randn((2, 3), network=net)</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.randn((2, 3), network=net)</span>
<span class="sd">    &gt;&gt;&gt; result = nodeA * nodeB</span>
<span class="sd">    &gt;&gt;&gt; result.shape</span>
<span class="sd">    torch.Size([2, 3])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">mul_op</span><span class="p">(</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">)</span></div>


<span class="n">mul_node</span> <span class="o">=</span> <span class="n">copy_func</span><span class="p">(</span><span class="n">mul</span><span class="p">)</span>
<span class="n">mul_node</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> \
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Element-wise product between two nodes. It can also be performed using the</span>
<span class="sd">    operator ``*``.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation are called ``&quot;mul&quot;``. The node</span>
<span class="sd">    that keeps information about the :class:`Successor` is ``self``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    node2 : Node or ParamNode</span>
<span class="sd">        Second node to be multiplied.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Node</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; net = tk.TensorNetwork()</span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.randn((2, 3), network=net)</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.randn((2, 3), network=net)</span>
<span class="sd">    &gt;&gt;&gt; result = nodeA.mul(nodeB)</span>
<span class="sd">    &gt;&gt;&gt; result.shape</span>
<span class="sd">    torch.Size([2, 3])</span>
<span class="sd">    &quot;&quot;&quot;</span>

<span class="n">AbstractNode</span><span class="o">.</span><span class="fm">__mul__</span> <span class="o">=</span> <span class="n">mul_node</span>


<span class="c1">###################################   ADD    ##################################</span>
<span class="k">def</span> <span class="nf">_check_first_add</span><span class="p">(</span><span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
                     <span class="n">node2</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Successor</span><span class="p">]:</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;node1&#39;</span><span class="p">:</span> <span class="n">node1</span><span class="p">,</span>
              <span class="s1">&#39;node2&#39;</span><span class="p">:</span> <span class="n">node2</span><span class="p">}</span>
    <span class="k">if</span> <span class="s1">&#39;add&#39;</span> <span class="ow">in</span> <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">succ</span> <span class="ow">in</span> <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;add&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">succ</span><span class="o">.</span><span class="n">kwargs</span> <span class="o">==</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">succ</span>
    <span class="k">return</span> <span class="kc">None</span>


<span class="k">def</span> <span class="nf">_add_first</span><span class="p">(</span><span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span> <span class="n">node2</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">node1</span><span class="o">.</span><span class="n">_network</span> <span class="o">!=</span> <span class="n">node2</span><span class="o">.</span><span class="n">_network</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Nodes must be in the same network&#39;</span><span class="p">)</span>

    <span class="n">new_tensor</span> <span class="o">=</span> <span class="n">node1</span><span class="o">.</span><span class="n">tensor</span> <span class="o">+</span> <span class="n">node2</span><span class="o">.</span><span class="n">tensor</span>
    <span class="n">new_node</span> <span class="o">=</span> <span class="n">Node</span><span class="o">.</span><span class="n">_create_resultant</span><span class="p">(</span><span class="n">axes_names</span><span class="o">=</span><span class="n">node1</span><span class="o">.</span><span class="n">axes_names</span><span class="p">,</span>
                                      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;add&#39;</span><span class="p">,</span>
                                      <span class="n">network</span><span class="o">=</span><span class="n">node1</span><span class="o">.</span><span class="n">_network</span><span class="p">,</span>
                                      <span class="n">tensor</span><span class="o">=</span><span class="n">new_tensor</span><span class="p">,</span>
                                      <span class="n">edges</span><span class="o">=</span><span class="n">node1</span><span class="o">.</span><span class="n">_edges</span><span class="p">,</span>
                                      <span class="n">node1_list</span><span class="o">=</span><span class="n">node1</span><span class="o">.</span><span class="n">is_node1</span><span class="p">())</span>

    <span class="c1"># Create successor</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">node1</span><span class="o">.</span><span class="n">_network</span>
    <span class="n">successor</span> <span class="o">=</span> <span class="n">Successor</span><span class="p">(</span><span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;node1&#39;</span><span class="p">:</span> <span class="n">node1</span><span class="p">,</span>
                                  <span class="s1">&#39;node2&#39;</span><span class="p">:</span> <span class="n">node2</span><span class="p">},</span>
                          <span class="n">child</span><span class="o">=</span><span class="n">new_node</span><span class="p">)</span>

    <span class="c1"># Add successor to parent</span>
    <span class="k">if</span> <span class="s1">&#39;add&#39;</span> <span class="ow">in</span> <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">:</span>
        <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;add&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">successor</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;add&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">successor</span><span class="p">]</span>

    <span class="c1"># Add operation to list of performed operations of TN</span>
    <span class="n">net</span><span class="o">.</span><span class="n">_seq_ops</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;add&#39;</span><span class="p">,</span> <span class="n">successor</span><span class="o">.</span><span class="n">kwargs</span><span class="p">))</span>

    <span class="c1"># Record in inverse_memory while tracing</span>
    <span class="n">node1</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>
    <span class="n">node2</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">new_node</span>


<span class="k">def</span> <span class="nf">_add_next</span><span class="p">(</span><span class="n">successor</span><span class="p">:</span> <span class="n">Successor</span><span class="p">,</span>
              <span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
              <span class="n">node2</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
    <span class="n">new_tensor</span> <span class="o">=</span> <span class="n">node1</span><span class="o">.</span><span class="n">tensor</span> <span class="o">+</span> <span class="n">node2</span><span class="o">.</span><span class="n">tensor</span>
    <span class="n">child</span> <span class="o">=</span> <span class="n">successor</span><span class="o">.</span><span class="n">child</span>
    <span class="n">child</span><span class="o">.</span><span class="n">_direct_set_tensor</span><span class="p">(</span><span class="n">new_tensor</span><span class="p">)</span>

    <span class="c1"># Record in inverse_memory while contracting</span>
    <span class="c1"># (to delete memory if possible)</span>
    <span class="n">node1</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>
    <span class="n">node2</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">child</span>


<span class="n">add_op</span> <span class="o">=</span> <span class="n">Operation</span><span class="p">(</span><span class="s1">&#39;add&#39;</span><span class="p">,</span> <span class="n">_check_first_add</span><span class="p">,</span> <span class="n">_add_first</span><span class="p">,</span> <span class="n">_add_next</span><span class="p">)</span>


<div class="viewcode-block" id="add"><a class="viewcode-back" href="../../operations.html#tensorkrowch.add">[docs]</a><span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span> <span class="n">node2</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Element-wise addition between two nodes. It can also be performed using the</span>
<span class="sd">    operator ``+``.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation are called ``&quot;add&quot;``. The node</span>
<span class="sd">    that keeps information about the :class:`Successor` is ``node1``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    node1 : Node or ParamNode</span>
<span class="sd">        First node to be added. Its edges will appear in the resultant node.</span>
<span class="sd">    node2 : Node or ParamNode</span>
<span class="sd">        Second node to be added.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Node</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; net = tk.TensorNetwork()</span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.randn((2, 3), network=net)</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.randn((2, 3), network=net)</span>
<span class="sd">    &gt;&gt;&gt; result = nodeA + nodeB</span>
<span class="sd">    &gt;&gt;&gt; result.shape</span>
<span class="sd">    torch.Size([2, 3])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">add_op</span><span class="p">(</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">)</span></div>


<span class="n">add_node</span> <span class="o">=</span> <span class="n">copy_func</span><span class="p">(</span><span class="n">add</span><span class="p">)</span>
<span class="n">add_node</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> \
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Element-wise addition between two nodes. It can also be performed using the</span>
<span class="sd">    operator ``+``.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation are called ``&quot;add&quot;``. The node</span>
<span class="sd">    that keeps information about the :class:`Successor` is ``self``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    node2 : Node or ParamNode</span>
<span class="sd">        Second node to be multiplied.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Node</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; net = tk.TensorNetwork()</span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.randn((2, 3), network=net)</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.randn((2, 3), network=net)</span>
<span class="sd">    &gt;&gt;&gt; result = nodeA.add(nodeB)</span>
<span class="sd">    &gt;&gt;&gt; result.shape</span>
<span class="sd">    torch.Size([2, 3])</span>
<span class="sd">    &quot;&quot;&quot;</span>

<span class="n">AbstractNode</span><span class="o">.</span><span class="fm">__add__</span> <span class="o">=</span> <span class="n">add_node</span>


<span class="c1">###################################   SUB    ##################################</span>
<span class="k">def</span> <span class="nf">_check_first_sub</span><span class="p">(</span><span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
                     <span class="n">node2</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Successor</span><span class="p">]:</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;node1&#39;</span><span class="p">:</span> <span class="n">node1</span><span class="p">,</span>
              <span class="s1">&#39;node2&#39;</span><span class="p">:</span> <span class="n">node2</span><span class="p">}</span>
    <span class="k">if</span> <span class="s1">&#39;sub&#39;</span> <span class="ow">in</span> <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">succ</span> <span class="ow">in</span> <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;sub&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">succ</span><span class="o">.</span><span class="n">kwargs</span> <span class="o">==</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">succ</span>
    <span class="k">return</span> <span class="kc">None</span>


<span class="k">def</span> <span class="nf">_sub_first</span><span class="p">(</span><span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span> <span class="n">node2</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">node1</span><span class="o">.</span><span class="n">_network</span> <span class="o">!=</span> <span class="n">node2</span><span class="o">.</span><span class="n">_network</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Nodes must be in the same network&#39;</span><span class="p">)</span>

    <span class="n">new_tensor</span> <span class="o">=</span> <span class="n">node1</span><span class="o">.</span><span class="n">tensor</span> <span class="o">-</span> <span class="n">node2</span><span class="o">.</span><span class="n">tensor</span>
    <span class="n">new_node</span> <span class="o">=</span> <span class="n">Node</span><span class="o">.</span><span class="n">_create_resultant</span><span class="p">(</span><span class="n">axes_names</span><span class="o">=</span><span class="n">node1</span><span class="o">.</span><span class="n">axes_names</span><span class="p">,</span>
                                      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;sub&#39;</span><span class="p">,</span>
                                      <span class="n">network</span><span class="o">=</span><span class="n">node1</span><span class="o">.</span><span class="n">_network</span><span class="p">,</span>
                                      <span class="n">tensor</span><span class="o">=</span><span class="n">new_tensor</span><span class="p">,</span>
                                      <span class="n">edges</span><span class="o">=</span><span class="n">node1</span><span class="o">.</span><span class="n">_edges</span><span class="p">,</span>
                                      <span class="n">node1_list</span><span class="o">=</span><span class="n">node1</span><span class="o">.</span><span class="n">is_node1</span><span class="p">())</span>

    <span class="c1"># Create successor</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">node1</span><span class="o">.</span><span class="n">_network</span>
    <span class="n">successor</span> <span class="o">=</span> <span class="n">Successor</span><span class="p">(</span><span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;node1&#39;</span><span class="p">:</span> <span class="n">node1</span><span class="p">,</span>
                                  <span class="s1">&#39;node2&#39;</span><span class="p">:</span> <span class="n">node2</span><span class="p">},</span>
                          <span class="n">child</span><span class="o">=</span><span class="n">new_node</span><span class="p">)</span>

    <span class="c1"># Add successor to parent</span>
    <span class="k">if</span> <span class="s1">&#39;sub&#39;</span> <span class="ow">in</span> <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">:</span>
        <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;sub&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">successor</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;sub&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">successor</span><span class="p">]</span>

    <span class="c1"># Add operation to list of performed operations of TN</span>
    <span class="n">net</span><span class="o">.</span><span class="n">_seq_ops</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;sub&#39;</span><span class="p">,</span> <span class="n">successor</span><span class="o">.</span><span class="n">kwargs</span><span class="p">))</span>

    <span class="c1"># Record in inverse_memory while tracing</span>
    <span class="n">node1</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>
    <span class="n">node2</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">new_node</span>


<span class="k">def</span> <span class="nf">_sub_next</span><span class="p">(</span><span class="n">successor</span><span class="p">:</span> <span class="n">Successor</span><span class="p">,</span>
              <span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
              <span class="n">node2</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
    <span class="n">new_tensor</span> <span class="o">=</span> <span class="n">node1</span><span class="o">.</span><span class="n">tensor</span> <span class="o">-</span> <span class="n">node2</span><span class="o">.</span><span class="n">tensor</span>
    <span class="n">child</span> <span class="o">=</span> <span class="n">successor</span><span class="o">.</span><span class="n">child</span>
    <span class="n">child</span><span class="o">.</span><span class="n">_direct_set_tensor</span><span class="p">(</span><span class="n">new_tensor</span><span class="p">)</span>

    <span class="c1"># Record in inverse_memory while contracting</span>
    <span class="c1"># (to delete memory if possible)</span>
    <span class="n">node1</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>
    <span class="n">node2</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">child</span>


<span class="n">sub_op</span> <span class="o">=</span> <span class="n">Operation</span><span class="p">(</span><span class="s1">&#39;sub&#39;</span><span class="p">,</span> <span class="n">_check_first_sub</span><span class="p">,</span> <span class="n">_sub_first</span><span class="p">,</span> <span class="n">_sub_next</span><span class="p">)</span>


<div class="viewcode-block" id="sub"><a class="viewcode-back" href="../../operations.html#tensorkrowch.sub">[docs]</a><span class="k">def</span> <span class="nf">sub</span><span class="p">(</span><span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span> <span class="n">node2</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Element-wise subtraction between two nodes. It can also be performed using</span>
<span class="sd">    the operator ``-``.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation are called ``&quot;sub&quot;``. The node</span>
<span class="sd">    that keeps information about the :class:`Successor` is ``node1``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    node1 : Node or ParamNode</span>
<span class="sd">        First node, minuend . Its edges will appear in the resultant node.</span>
<span class="sd">    node2 : Node or ParamNode</span>
<span class="sd">        Second node, subtrahend.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Node</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; net = tk.TensorNetwork()</span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.randn((2, 3), network=net)</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.randn((2, 3), network=net)</span>
<span class="sd">    &gt;&gt;&gt; result = nodeA - nodeB</span>
<span class="sd">    &gt;&gt;&gt; result.shape</span>
<span class="sd">    torch.Size([2, 3])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">sub_op</span><span class="p">(</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">)</span></div>


<span class="n">sub_node</span> <span class="o">=</span> <span class="n">copy_func</span><span class="p">(</span><span class="n">sub</span><span class="p">)</span>
<span class="n">sub_node</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> \
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Element-wise subtraction between two nodes. It can also be performed using</span>
<span class="sd">    the operator ``-``.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation are called ``&quot;sub&quot;``. The node</span>
<span class="sd">    that keeps information about the :class:`Successor` is ``self``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    node2 : Node or ParamNode</span>
<span class="sd">        Second node, subtrahend.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Node</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; net = tk.TensorNetwork()</span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.randn((2, 3), network=net)</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.randn((2, 3), network=net)</span>
<span class="sd">    &gt;&gt;&gt; result = nodeA.sub(nodeB)</span>
<span class="sd">    &gt;&gt;&gt; result.shape</span>
<span class="sd">    torch.Size([2, 3])</span>
<span class="sd">    &quot;&quot;&quot;</span>

<span class="n">AbstractNode</span><span class="o">.</span><span class="fm">__sub__</span> <span class="o">=</span> <span class="n">sub_node</span>


<span class="c1">###############################################################################</span>
<span class="c1">#                            NODE-LIKE OPERATIONS                             #</span>
<span class="c1">###############################################################################</span>

<span class="c1">##################################   SPLIT    #################################</span>
<span class="k">def</span> <span class="nf">_check_first_split</span><span class="p">(</span><span class="n">node</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
                       <span class="n">node1_axes</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Ax</span><span class="p">],</span>
                       <span class="n">node2_axes</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Ax</span><span class="p">],</span>
                       <span class="n">mode</span><span class="p">:</span> <span class="n">Text</span> <span class="o">=</span> <span class="s1">&#39;svd&#39;</span><span class="p">,</span>
                       <span class="n">side</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Text</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;left&#39;</span><span class="p">,</span>
                       <span class="n">rank</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                       <span class="n">cum_percentage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                       <span class="n">cutoff</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Successor</span><span class="p">]:</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;node&#39;</span><span class="p">:</span> <span class="n">node</span><span class="p">,</span>
              <span class="s1">&#39;node1_axes&#39;</span><span class="p">:</span> <span class="n">node1_axes</span><span class="p">,</span>
              <span class="s1">&#39;node2_axes&#39;</span><span class="p">:</span> <span class="n">node2_axes</span><span class="p">,</span>
              <span class="s1">&#39;mode&#39;</span><span class="p">:</span> <span class="n">mode</span><span class="p">,</span>
              <span class="s1">&#39;side&#39;</span><span class="p">:</span> <span class="n">side</span><span class="p">,</span>
              <span class="s1">&#39;rank&#39;</span><span class="p">:</span> <span class="n">rank</span><span class="p">,</span>
              <span class="s1">&#39;cum_percentage&#39;</span><span class="p">:</span> <span class="n">cum_percentage</span><span class="p">,</span>
              <span class="s1">&#39;cutoff&#39;</span><span class="p">:</span> <span class="n">cutoff</span><span class="p">}</span>
    <span class="k">if</span> <span class="s1">&#39;split&#39;</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">_successors</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">succ</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;split&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">succ</span><span class="o">.</span><span class="n">kwargs</span> <span class="o">==</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">succ</span>
    <span class="k">return</span> <span class="kc">None</span>


<span class="k">def</span> <span class="nf">_split_first</span><span class="p">(</span><span class="n">node</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
                 <span class="n">node1_axes</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Ax</span><span class="p">],</span>
                 <span class="n">node2_axes</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Ax</span><span class="p">],</span>
                 <span class="n">mode</span><span class="p">:</span> <span class="n">Text</span> <span class="o">=</span> <span class="s1">&#39;svd&#39;</span><span class="p">,</span>
                 <span class="n">side</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Text</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;left&#39;</span><span class="p">,</span>
                 <span class="n">rank</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">cum_percentage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">cutoff</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Node</span><span class="p">,</span> <span class="n">Node</span><span class="p">]:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node1_axes</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`node1_edges` should be list or tuple type&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node2_axes</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`node2_edges` should be list or tuple type&#39;</span><span class="p">)</span>

    <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;node&#39;</span><span class="p">:</span> <span class="n">node</span><span class="p">,</span>
              <span class="s1">&#39;node1_axes&#39;</span><span class="p">:</span> <span class="n">node1_axes</span><span class="p">,</span>
              <span class="s1">&#39;node2_axes&#39;</span><span class="p">:</span> <span class="n">node2_axes</span><span class="p">,</span>
              <span class="s1">&#39;mode&#39;</span><span class="p">:</span> <span class="n">mode</span><span class="p">,</span>
              <span class="s1">&#39;side&#39;</span><span class="p">:</span> <span class="n">side</span><span class="p">,</span>
              <span class="s1">&#39;rank&#39;</span><span class="p">:</span> <span class="n">rank</span><span class="p">,</span>
              <span class="s1">&#39;cum_percentage&#39;</span><span class="p">:</span> <span class="n">cum_percentage</span><span class="p">,</span>
              <span class="s1">&#39;cutoff&#39;</span><span class="p">:</span> <span class="n">cutoff</span><span class="p">}</span>

    <span class="n">node1_axes</span> <span class="o">=</span> <span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">get_axis_num</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span> <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">node1_axes</span><span class="p">]</span>
    <span class="n">node2_axes</span> <span class="o">=</span> <span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">get_axis_num</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span> <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">node2_axes</span><span class="p">]</span>

    <span class="n">batch_axes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">all_axes</span> <span class="o">=</span> <span class="n">node1_axes</span> <span class="o">+</span> <span class="n">node2_axes</span>
    <span class="n">all_axes</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">all_axes</span><span class="p">:</span>
        <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">all_axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">rank</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">rank</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">k</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">node</span><span class="o">.</span><span class="n">_edges</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">is_batch</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Edge </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">_edges</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1"> is not a batch &#39;</span>
                                 <span class="s1">&#39;edge but it</span><span class="se">\&#39;</span><span class="s1">s not included in `node1_axes` &#39;</span>
                                 <span class="s1">&#39;neither in `node2_axes`&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">batch_axes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_axes</span><span class="p">):</span>
                <span class="n">k</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">rank</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">j</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">k</span> <span class="o">=</span> <span class="n">all_axes</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>

    <span class="n">batch_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">shape</span><span class="p">)[</span><span class="n">batch_axes</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">node1_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">shape</span><span class="p">)[</span><span class="n">node1_axes</span><span class="p">]</span>
    <span class="n">node2_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">shape</span><span class="p">)[</span><span class="n">node2_axes</span><span class="p">]</span>

    <span class="n">permutation_dims</span> <span class="o">=</span> <span class="n">batch_axes</span> <span class="o">+</span> <span class="n">node1_axes</span> <span class="o">+</span> <span class="n">node2_axes</span>
    <span class="k">if</span> <span class="n">permutation_dims</span> <span class="o">==</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">rank</span><span class="p">)):</span>
        <span class="n">permutation_dims</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="n">permutation_dims</span><span class="p">:</span>
        <span class="n">node_tensor</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">tensor</span>\
            <span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="n">batch_axes</span> <span class="o">+</span> <span class="n">node1_axes</span> <span class="o">+</span> <span class="n">node2_axes</span><span class="p">))</span>\
            <span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="n">batch_shape</span> <span class="o">+</span>
                       <span class="p">[</span><span class="n">node1_shape</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span> <span class="o">+</span>
                       <span class="p">[</span><span class="n">node2_shape</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()]))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">node_tensor</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">tensor</span>\
            <span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="n">batch_shape</span> <span class="o">+</span>
                       <span class="p">[</span><span class="n">node1_shape</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span> <span class="o">+</span>
                       <span class="p">[</span><span class="n">node2_shape</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()]))</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;svd&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;svdr&#39;</span><span class="p">):</span>
        <span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">vh</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">node_tensor</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">cum_percentage</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">rank</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">cutoff</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Only one of `rank`, `cum_percentage` and &#39;</span>
                                 <span class="s1">&#39;`cutoff` should be provided&#39;</span><span class="p">)</span>

            <span class="n">percentages</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">s</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>\
                <span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="n">cum_percentage_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">cum_percentage</span><span class="p">)</span>\
                <span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">percentages</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">rank</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">percentages</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
                <span class="n">p</span> <span class="o">=</span> <span class="n">percentages</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
                <span class="n">rank</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="c1"># Cut when ``cum_percentage`` is exceeded in all batches</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">ge</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">cum_percentage_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
                    <span class="k">break</span>

        <span class="k">elif</span> <span class="n">cutoff</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">rank</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Only one of `rank`, `cum_percentage` and &#39;</span>
                                 <span class="s1">&#39;`cutoff` should be provided&#39;</span><span class="p">)</span>

            <span class="n">cutoff_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">cutoff</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">rank</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
                <span class="c1"># Cut when ``cutoff`` is exceeded in all batches</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">le</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span> <span class="n">cutoff_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
                    <span class="k">break</span>
                <span class="n">rank</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">rank</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">rank</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">rank</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">rank</span> <span class="o">&lt;</span> <span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                <span class="n">u</span> <span class="o">=</span> <span class="n">u</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">rank</span><span class="p">]</span>
                <span class="n">s</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">rank</span><span class="p">]</span>
                <span class="n">vh</span> <span class="o">=</span> <span class="n">vh</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">rank</span><span class="p">,</span> <span class="p">:]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">rank</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;svdr&#39;</span><span class="p">:</span>
            <span class="n">phase</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
            <span class="n">phase</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag_embed</span><span class="p">(</span><span class="n">phase</span><span class="p">)</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">u</span> <span class="o">@</span> <span class="n">phase</span>
            <span class="n">vh</span> <span class="o">=</span> <span class="n">phase</span> <span class="o">@</span> <span class="n">vh</span>

        <span class="k">if</span> <span class="n">side</span> <span class="o">==</span> <span class="s1">&#39;left&#39;</span><span class="p">:</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">u</span> <span class="o">@</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag_embed</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">side</span> <span class="o">==</span> <span class="s1">&#39;right&#39;</span><span class="p">:</span>
            <span class="n">vh</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag_embed</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">@</span> <span class="n">vh</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`side` can only be &quot;left&quot; or &quot;right&quot;&#39;</span><span class="p">)</span>

        <span class="n">node1_tensor</span> <span class="o">=</span> <span class="n">u</span>
        <span class="n">node2_tensor</span> <span class="o">=</span> <span class="n">vh</span>

    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;qr&#39;</span><span class="p">:</span>
        <span class="n">q</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">node_tensor</span><span class="p">)</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">node1_tensor</span> <span class="o">=</span> <span class="n">q</span>
        <span class="n">node2_tensor</span> <span class="o">=</span> <span class="n">r</span>

    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;rq&#39;</span><span class="p">:</span>
        <span class="n">q</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">node_tensor</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">node1_tensor</span> <span class="o">=</span> <span class="n">r</span>
        <span class="n">node2_tensor</span> <span class="o">=</span> <span class="n">q</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`mode` can only be &quot;svd&quot;, &quot;svdr&quot;, &quot;qr&quot; or &quot;rq&quot;&#39;</span><span class="p">)</span>

    <span class="n">node1_tensor</span> <span class="o">=</span> <span class="n">node1_tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="o">*</span><span class="p">(</span><span class="n">batch_shape</span> <span class="o">+</span> <span class="n">node1_shape</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="p">[</span><span class="n">rank</span><span class="p">]))</span>
    <span class="n">node2_tensor</span> <span class="o">=</span> <span class="n">node2_tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="o">*</span><span class="p">(</span><span class="n">batch_shape</span> <span class="o">+</span> <span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">+</span> <span class="n">node2_shape</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span>

    <span class="n">net</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">_network</span>

    <span class="n">node1_axes_names</span> <span class="o">=</span> <span class="n">permute_list</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">axes_names</span><span class="p">,</span>
                                    <span class="n">batch_axes</span> <span class="o">+</span> <span class="n">node1_axes</span><span class="p">)</span> <span class="o">+</span> \
        <span class="p">[</span><span class="s1">&#39;splitted&#39;</span><span class="p">]</span>
    <span class="n">node1</span> <span class="o">=</span> <span class="n">Node</span><span class="o">.</span><span class="n">_create_resultant</span><span class="p">(</span><span class="n">axes_names</span><span class="o">=</span><span class="n">node1_axes_names</span><span class="p">,</span>
                                   <span class="n">name</span><span class="o">=</span><span class="s1">&#39;split&#39;</span><span class="p">,</span>
                                   <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">,</span>
                                   <span class="n">tensor</span><span class="o">=</span><span class="n">node1_tensor</span><span class="p">)</span>

    <span class="n">node2_axes_names</span> <span class="o">=</span> <span class="n">permute_list</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">axes_names</span><span class="p">,</span> <span class="n">batch_axes</span><span class="p">)</span> <span class="o">+</span> \
        <span class="p">[</span><span class="s1">&#39;splitted&#39;</span><span class="p">]</span> <span class="o">+</span> \
        <span class="n">permute_list</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">axes_names</span><span class="p">,</span> <span class="n">node2_axes</span><span class="p">)</span>
    <span class="n">node2</span> <span class="o">=</span> <span class="n">Node</span><span class="o">.</span><span class="n">_create_resultant</span><span class="p">(</span><span class="n">axes_names</span><span class="o">=</span><span class="n">node2_axes_names</span><span class="p">,</span>
                                   <span class="n">name</span><span class="o">=</span><span class="s1">&#39;split&#39;</span><span class="p">,</span>
                                   <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">,</span>
                                   <span class="n">tensor</span><span class="o">=</span><span class="n">node2_tensor</span><span class="p">)</span>

    <span class="n">n_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_axes</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">node1</span><span class="o">.</span><span class="n">_edges</span><span class="p">[</span><span class="n">n_batches</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">net</span><span class="o">.</span><span class="n">_remove_edge</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">node2</span><span class="o">.</span><span class="n">_edges</span><span class="p">[(</span><span class="n">n_batches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):]:</span>
        <span class="n">net</span><span class="o">.</span><span class="n">_remove_edge</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span>

    <span class="n">trace_node2_axes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">axis1</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">node1_axes</span><span class="p">):</span>
        <span class="n">edge1</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">_edges</span><span class="p">[</span><span class="n">axis1</span><span class="p">]</span>

        <span class="n">in_node2</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">axis2</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">node2_axes</span><span class="p">):</span>
            <span class="n">edge2</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">_edges</span><span class="p">[</span><span class="n">axis2</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">edge1</span> <span class="o">==</span> <span class="n">edge2</span><span class="p">:</span>
                <span class="n">in_node2</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">trace_node2_axes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">axis2</span><span class="p">)</span>

                <span class="n">node1_is_node1</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">is_node1</span><span class="p">(</span><span class="n">axis1</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">node1_is_node1</span><span class="p">:</span>
                    <span class="n">new_edge</span> <span class="o">=</span> <span class="n">edge1</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="n">node1</span><span class="o">=</span><span class="n">node1</span><span class="p">,</span>
                                               <span class="n">axis1</span><span class="o">=</span><span class="n">n_batches</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span>
                                               <span class="n">node2</span><span class="o">=</span><span class="n">node2</span><span class="p">,</span>
                                               <span class="n">axis2</span><span class="o">=</span><span class="n">n_batches</span> <span class="o">+</span> <span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">new_edge</span> <span class="o">=</span> <span class="n">edge1</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="n">node1</span><span class="o">=</span><span class="n">node2</span><span class="p">,</span>
                                               <span class="n">axis1</span><span class="o">=</span><span class="n">n_batches</span> <span class="o">+</span> <span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                                               <span class="n">node2</span><span class="o">=</span><span class="n">node1</span><span class="p">,</span>
                                               <span class="n">axis2</span><span class="o">=</span><span class="n">n_batches</span> <span class="o">+</span> <span class="n">i</span><span class="p">)</span>

                <span class="n">node1</span><span class="o">.</span><span class="n">_add_edge</span><span class="p">(</span><span class="n">edge</span><span class="o">=</span><span class="n">new_edge</span><span class="p">,</span>
                                <span class="n">axis</span><span class="o">=</span><span class="n">n_batches</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span>
                                <span class="n">node1</span><span class="o">=</span><span class="n">node1_is_node1</span><span class="p">)</span>
                <span class="n">node2</span><span class="o">.</span><span class="n">_add_edge</span><span class="p">(</span><span class="n">edge</span><span class="o">=</span><span class="n">new_edge</span><span class="p">,</span>
                                <span class="n">axis</span><span class="o">=</span><span class="n">n_batches</span> <span class="o">+</span> <span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                                <span class="n">node1</span><span class="o">=</span><span class="ow">not</span> <span class="n">node1_is_node1</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">in_node2</span><span class="p">:</span>
            <span class="n">node1</span><span class="o">.</span><span class="n">_add_edge</span><span class="p">(</span><span class="n">edge</span><span class="o">=</span><span class="n">edge1</span><span class="p">,</span>
                            <span class="n">axis</span><span class="o">=</span><span class="n">n_batches</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span>
                            <span class="n">node1</span><span class="o">=</span><span class="n">node</span><span class="o">.</span><span class="n">is_node1</span><span class="p">(</span><span class="n">axis1</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">axis2</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">node2_axes</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">axis2</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">trace_node2_axes</span><span class="p">:</span>
            <span class="n">node2</span><span class="o">.</span><span class="n">_add_edge</span><span class="p">(</span><span class="n">edge</span><span class="o">=</span><span class="n">node</span><span class="o">.</span><span class="n">_edges</span><span class="p">[</span><span class="n">axis2</span><span class="p">],</span>
                            <span class="n">axis</span><span class="o">=</span><span class="n">n_batches</span> <span class="o">+</span> <span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                            <span class="n">node1</span><span class="o">=</span><span class="n">node</span><span class="o">.</span><span class="n">is_node1</span><span class="p">(</span><span class="n">axis2</span><span class="p">))</span>

    <span class="n">splitted_edge</span> <span class="o">=</span> <span class="n">node1</span><span class="p">[</span><span class="s1">&#39;splitted&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">node2</span><span class="p">[</span><span class="s1">&#39;splitted&#39;</span><span class="p">]</span>
    <span class="n">net</span><span class="o">.</span><span class="n">_remove_edge</span><span class="p">(</span><span class="n">splitted_edge</span><span class="p">)</span>

    <span class="c1"># Create successor</span>
    <span class="n">successor</span> <span class="o">=</span> <span class="n">Successor</span><span class="p">(</span><span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="p">,</span>
                          <span class="n">child</span><span class="o">=</span><span class="p">[</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">],</span>
                          <span class="n">hints</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;batch_axes&#39;</span><span class="p">:</span> <span class="n">batch_axes</span><span class="p">,</span>
                                 <span class="s1">&#39;node1_axes&#39;</span><span class="p">:</span> <span class="n">node1_axes</span><span class="p">,</span>
                                 <span class="s1">&#39;node2_axes&#39;</span><span class="p">:</span> <span class="n">node2_axes</span><span class="p">,</span>
                                 <span class="s1">&#39;permutation_dims&#39;</span><span class="p">:</span> <span class="n">permutation_dims</span><span class="p">})</span>

    <span class="c1"># Add successor to parent</span>
    <span class="k">if</span> <span class="s1">&#39;split&#39;</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">_successors</span><span class="p">:</span>
        <span class="n">node</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;split&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">successor</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">node</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;split&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">successor</span><span class="p">]</span>

    <span class="c1"># Add operation to list of performed operations of TN</span>
    <span class="n">net</span><span class="o">.</span><span class="n">_seq_ops</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;split&#39;</span><span class="p">,</span> <span class="n">successor</span><span class="o">.</span><span class="n">kwargs</span><span class="p">))</span>

    <span class="c1"># Record in inverse_memory while tracing</span>
    <span class="n">node</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">node1</span><span class="p">,</span> <span class="n">node2</span>


<span class="k">def</span> <span class="nf">_split_next</span><span class="p">(</span><span class="n">successor</span><span class="p">:</span> <span class="n">Successor</span><span class="p">,</span>
                <span class="n">node</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
                <span class="n">node1_axes</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Ax</span><span class="p">],</span>
                <span class="n">node2_axes</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Ax</span><span class="p">],</span>
                <span class="n">mode</span><span class="p">:</span> <span class="n">Text</span> <span class="o">=</span> <span class="s1">&#39;svd&#39;</span><span class="p">,</span>
                <span class="n">side</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Text</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;left&#39;</span><span class="p">,</span>
                <span class="n">rank</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">cum_percentage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">cutoff</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Node</span><span class="p">,</span> <span class="n">Node</span><span class="p">]:</span>

    <span class="n">batch_axes</span> <span class="o">=</span> <span class="n">successor</span><span class="o">.</span><span class="n">hints</span><span class="p">[</span><span class="s1">&#39;batch_axes&#39;</span><span class="p">]</span>
    <span class="n">node1_axes</span> <span class="o">=</span> <span class="n">successor</span><span class="o">.</span><span class="n">hints</span><span class="p">[</span><span class="s1">&#39;node1_axes&#39;</span><span class="p">]</span>
    <span class="n">node2_axes</span> <span class="o">=</span> <span class="n">successor</span><span class="o">.</span><span class="n">hints</span><span class="p">[</span><span class="s1">&#39;node2_axes&#39;</span><span class="p">]</span>
    <span class="n">permutation_dims</span> <span class="o">=</span> <span class="n">successor</span><span class="o">.</span><span class="n">hints</span><span class="p">[</span><span class="s1">&#39;permutation_dims&#39;</span><span class="p">]</span>

    <span class="n">batch_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">shape</span><span class="p">)[</span><span class="n">batch_axes</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">node1_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">shape</span><span class="p">)[</span><span class="n">node1_axes</span><span class="p">]</span>
    <span class="n">node2_shape</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">shape</span><span class="p">)[</span><span class="n">node2_axes</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">permutation_dims</span><span class="p">:</span>
        <span class="n">node_tensor</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">tensor</span>\
            <span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="n">batch_axes</span> <span class="o">+</span> <span class="n">node1_axes</span> <span class="o">+</span> <span class="n">node2_axes</span><span class="p">))</span>\
            <span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="n">batch_shape</span> <span class="o">+</span>
                       <span class="p">[</span><span class="n">node1_shape</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span> <span class="o">+</span>
                       <span class="p">[</span><span class="n">node2_shape</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()]))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">node_tensor</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">tensor</span>\
            <span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="n">batch_shape</span> <span class="o">+</span>
                       <span class="p">[</span><span class="n">node1_shape</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span> <span class="o">+</span>
                       <span class="p">[</span><span class="n">node2_shape</span><span class="o">.</span><span class="n">prod</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()]))</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;svd&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;svdr&#39;</span><span class="p">):</span>
        <span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">vh</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">node_tensor</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">cum_percentage</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">rank</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">cutoff</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Only one of `rank`, `cum_percentage` and &#39;</span>
                                 <span class="s1">&#39;`cutoff` should be provided&#39;</span><span class="p">)</span>

            <span class="n">percentages</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">s</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>\
                <span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="n">cum_percentage_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="n">cum_percentage</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">percentages</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">rank</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">percentages</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
                <span class="n">p</span> <span class="o">=</span> <span class="n">percentages</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
                <span class="n">rank</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="c1"># Cut when ``cum_percentage`` is exceeded in all batches</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">ge</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">cum_percentage_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
                    <span class="k">break</span>

        <span class="k">elif</span> <span class="n">cutoff</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">rank</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Only one of `rank`, `cum_percentage` and &#39;</span>
                                 <span class="s1">&#39;`cutoff` should be provided&#39;</span><span class="p">)</span>

            <span class="n">cutoff_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">cutoff</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">rank</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
                <span class="c1"># Cut when ``cutoff`` is exceeded in all batches</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">le</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span> <span class="n">cutoff_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
                    <span class="k">break</span>
                <span class="n">rank</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">rank</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">rank</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">rank</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">rank</span> <span class="o">&lt;</span> <span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                <span class="n">u</span> <span class="o">=</span> <span class="n">u</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">rank</span><span class="p">]</span>
                <span class="n">s</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">rank</span><span class="p">]</span>
                <span class="n">vh</span> <span class="o">=</span> <span class="n">vh</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">rank</span><span class="p">,</span> <span class="p">:]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">rank</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;svdr&#39;</span><span class="p">:</span>
            <span class="n">phase</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
            <span class="n">phase</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag_embed</span><span class="p">(</span><span class="n">phase</span><span class="p">)</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">u</span> <span class="o">@</span> <span class="n">phase</span>
            <span class="n">vh</span> <span class="o">=</span> <span class="n">phase</span> <span class="o">@</span> <span class="n">vh</span>

        <span class="k">if</span> <span class="n">side</span> <span class="o">==</span> <span class="s1">&#39;left&#39;</span><span class="p">:</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">u</span> <span class="o">@</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag_embed</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">side</span> <span class="o">==</span> <span class="s1">&#39;right&#39;</span><span class="p">:</span>
            <span class="n">vh</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag_embed</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">@</span> <span class="n">vh</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`side` can only be &quot;left&quot; or &quot;right&quot;&#39;</span><span class="p">)</span>

        <span class="n">node1_tensor</span> <span class="o">=</span> <span class="n">u</span>
        <span class="n">node2_tensor</span> <span class="o">=</span> <span class="n">vh</span>

    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;qr&#39;</span><span class="p">:</span>
        <span class="n">q</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">node_tensor</span><span class="p">)</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">node1_tensor</span> <span class="o">=</span> <span class="n">q</span>
        <span class="n">node2_tensor</span> <span class="o">=</span> <span class="n">r</span>

    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;rq&#39;</span><span class="p">:</span>
        <span class="n">q</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">node_tensor</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">node1_tensor</span> <span class="o">=</span> <span class="n">r</span>
        <span class="n">node2_tensor</span> <span class="o">=</span> <span class="n">q</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`mode` can only be &quot;svd&quot;, &quot;svdr&quot;, &quot;qr&quot; or &quot;rq&quot;&#39;</span><span class="p">)</span>

    <span class="n">node1_tensor</span> <span class="o">=</span> <span class="n">node1_tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="o">*</span><span class="p">(</span><span class="n">batch_shape</span> <span class="o">+</span> <span class="n">node1_shape</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="p">[</span><span class="n">rank</span><span class="p">]))</span>
    <span class="n">node2_tensor</span> <span class="o">=</span> <span class="n">node2_tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="o">*</span><span class="p">(</span><span class="n">batch_shape</span> <span class="o">+</span> <span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">+</span> <span class="n">node2_shape</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span>

    <span class="n">children</span> <span class="o">=</span> <span class="n">successor</span><span class="o">.</span><span class="n">child</span>
    <span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_direct_set_tensor</span><span class="p">(</span><span class="n">node1_tensor</span><span class="p">)</span>
    <span class="n">children</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">_direct_set_tensor</span><span class="p">(</span><span class="n">node2_tensor</span><span class="p">)</span>

    <span class="c1"># Record in inverse_memory while contracting</span>
    <span class="c1"># (to delete memory if possible)</span>
    <span class="n">node</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">children</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>


<span class="n">split_op</span> <span class="o">=</span> <span class="n">Operation</span><span class="p">(</span><span class="s1">&#39;split&#39;</span><span class="p">,</span> <span class="n">_check_first_split</span><span class="p">,</span> <span class="n">_split_first</span><span class="p">,</span> <span class="n">_split_next</span><span class="p">)</span>


<div class="viewcode-block" id="split"><a class="viewcode-back" href="../../operations.html#tensorkrowch.split">[docs]</a><span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="n">node</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
          <span class="n">node1_axes</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Ax</span><span class="p">],</span>
          <span class="n">node2_axes</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Ax</span><span class="p">],</span>
          <span class="n">mode</span><span class="p">:</span> <span class="n">Text</span> <span class="o">=</span> <span class="s1">&#39;svd&#39;</span><span class="p">,</span>
          <span class="n">side</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Text</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;left&#39;</span><span class="p">,</span>
          <span class="n">rank</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
          <span class="n">cum_percentage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
          <span class="n">cutoff</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Node</span><span class="p">,</span> <span class="n">Node</span><span class="p">]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Splits one node in two via the decomposition specified in ``mode``. To</span>
<span class="sd">    perform this operation the set of edges has to be split in two sets,</span>
<span class="sd">    corresponding to the edges of the first and second ``resultant nodes``.</span>
<span class="sd">    Batch edges that don&#39;t appear in any of the lists will be repeated in both</span>
<span class="sd">    nodes, and will appear as the first edges of the ``resultant`` nodes, in</span>
<span class="sd">    the order they appeared in ``node``.</span>

<span class="sd">    Having specified the two sets of edges, the node&#39;s tensor is reshaped as a</span>
<span class="sd">    batch matrix, with batch dimensions first, a single input dimension</span>
<span class="sd">    (adding up all edges in the first set) and a single output dimension</span>
<span class="sd">    (adding up all edges in the second set). With this shape, each matrix in</span>
<span class="sd">    the batch is decomposed according to ``mode``.</span>

<span class="sd">    * **&quot;svd&quot;**: Singular Value Decomposition</span>

<span class="sd">      .. math::</span>

<span class="sd">        M = USV^{\dagger}</span>

<span class="sd">      where :math:`U` and :math:`V` are unitary, and :math:`S` is diagonal.</span>

<span class="sd">    * **&quot;svdr&quot;**: Singular Value Decomposition adding Random phases (square</span>
<span class="sd">      diagonal matrices with random 1&#39;s and -1&#39;s)</span>

<span class="sd">      .. math::</span>

<span class="sd">        M = UR_1SR_2V^{\dagger}</span>

<span class="sd">      where :math:`U` and :math:`V` are unitary, :math:`S` is diagonal, and</span>
<span class="sd">      :math:`R_1` and :math:`R_2` are square diagonal matrices with random 1&#39;s</span>
<span class="sd">      and -1&#39;s.</span>

<span class="sd">    * **&quot;qr&quot;**: QR decomposition</span>

<span class="sd">      .. math::</span>

<span class="sd">        M = QR</span>

<span class="sd">      where Q is unitary and R is an upper triangular matrix.</span>

<span class="sd">    * **&quot;rq&quot;**: RQ decomposition</span>

<span class="sd">      .. math::</span>

<span class="sd">        M = RQ</span>

<span class="sd">      where R is a lower triangular matrix and Q is unitary.</span>

<span class="sd">    If ``mode`` is &quot;svd&quot; or &quot;svdr&quot;, ``side`` must be provided. Besides, one</span>
<span class="sd">    (and only one) of ``rank``, ``cum_percentage`` and ``cutoff`` is required.</span>
<span class="sd">    </span>
<span class="sd">    Since the node is `splitted` in two, a new edge appears connecting both</span>
<span class="sd">    nodes. The axis that corresponds to this edge has the name ``&quot;splitted&quot;``.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation are called ``&quot;split&quot;``. The node</span>
<span class="sd">    that keeps information about the :class:`Successor` is ``node``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    node : AbstractNode</span>
<span class="sd">        Node that is to be splitted.</span>
<span class="sd">    node1_axes : list[int, str or Axis]</span>
<span class="sd">        First set of edges, will appear as the edges of the first (left)</span>
<span class="sd">        resultant node.</span>
<span class="sd">    node2_axes : list[int, str or Axis]</span>
<span class="sd">        Second set of edges, will appear as the edges of the second (right)</span>
<span class="sd">        resultant node.</span>
<span class="sd">    mode : {&quot;svd&quot;, &quot;svdr&quot;, &quot;qr&quot;, &quot;rq&quot;}</span>
<span class="sd">        Decomposition to be used.</span>
<span class="sd">    side : str, optional</span>
<span class="sd">        If ``mode`` is &quot;svd&quot; or &quot;svdr&quot;, indicates the side to which the diagonal</span>
<span class="sd">        matrix :math:`S` should be contracted. If &quot;left&quot;, the first resultant</span>
<span class="sd">        node&#39;s tensor will be :math:`US`, and the other node&#39;s tensor will be</span>
<span class="sd">        :math:`V^{\dagger}`. If &quot;right&quot;, their tensors will be :math:`U` and</span>
<span class="sd">        :math:`SV^{\dagger}`, respectively.</span>
<span class="sd">    rank : int, optional</span>
<span class="sd">        Number of singular values to keep.</span>
<span class="sd">    cum_percentage : float, optional</span>
<span class="sd">        Proportion that should be satisfied between the sum of all singular</span>
<span class="sd">        values kept and the total sum of all singular values.</span>

<span class="sd">        .. math::</span>

<span class="sd">            \frac{\sum_{i \in \{kept\}}{s_i}}{\sum_{i \in \{all\}}{s_i}} \ge</span>
<span class="sd">            cum\_percentage</span>
<span class="sd">    cutoff : float, optional</span>
<span class="sd">        Quantity that lower bounds singular values in order to be kept.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tuple[Node, Node]</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; node = tk.randn(shape=(10, 15, 100),</span>
<span class="sd">    ...                 axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;))</span>
<span class="sd">    &gt;&gt;&gt; node_left, node_right = tk.split(node,</span>
<span class="sd">    ...                                  [&#39;left&#39;], [&#39;right&#39;],</span>
<span class="sd">    ...                                  mode=&#39;svd&#39;,</span>
<span class="sd">    ...                                  rank=5)</span>
<span class="sd">    &gt;&gt;&gt; node_left.shape</span>
<span class="sd">    torch.Size([100, 10, 5])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; node_right.shape</span>
<span class="sd">    torch.Size([100, 5, 15])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; node_left[&#39;splitted&#39;]</span>
<span class="sd">    Edge( split_0[splitted] &lt;-&gt; split_1[splitted] )</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">split_op</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">node1_axes</span><span class="p">,</span> <span class="n">node2_axes</span><span class="p">,</span>
                    <span class="n">mode</span><span class="p">,</span> <span class="n">side</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">cum_percentage</span><span class="p">,</span> <span class="n">cutoff</span><span class="p">)</span></div>


<span class="n">split_node</span> <span class="o">=</span> <span class="n">copy_func</span><span class="p">(</span><span class="n">split</span><span class="p">)</span>
<span class="n">split_node</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> \
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Splits one node in two via the decomposition specified in ``mode``. See</span>
<span class="sd">    :func:`split` for a more complete explanation.</span>
<span class="sd">    </span>
<span class="sd">    Since the node is `splitted` in two, a new edge appears connecting both</span>
<span class="sd">    nodes. The axis that corresponds to this edge has the name ``&quot;splitted&quot;``.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation are called ``&quot;split&quot;``. The node</span>
<span class="sd">    that keeps information about the :class:`Successor` is ``self``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    node1_axes : list[int, str or Axis]</span>
<span class="sd">        First set of edges, will appear as the edges of the first (left)</span>
<span class="sd">        resultant node.</span>
<span class="sd">    node2_axes : list[int, str or Axis]</span>
<span class="sd">        Second set of edges, will appear as the edges of the second (right)</span>
<span class="sd">        resultant node.</span>
<span class="sd">    mode : {&quot;svd&quot;, &quot;svdr&quot;, &quot;qr&quot;, &quot;rq&quot;}</span>
<span class="sd">        Decomposition to be used.</span>
<span class="sd">    side : str, optional</span>
<span class="sd">        If ``mode`` is &quot;svd&quot; or &quot;svdr&quot;, indicates the side to which the diagonal</span>
<span class="sd">        matrix :math:`S` should be contracted. If &quot;left&quot;, the first resultant</span>
<span class="sd">        node&#39;s tensor will be :math:`US`, and the other node&#39;s tensor will be</span>
<span class="sd">        :math:`V^{\dagger}`. If &quot;right&quot;, their tensors will be :math:`U` and</span>
<span class="sd">        :math:`SV^{\dagger}`, respectively.</span>
<span class="sd">    rank : int, optional</span>
<span class="sd">        Number of singular values to keep.</span>
<span class="sd">    cum_percentage : float, optional</span>
<span class="sd">        Proportion that should be satisfied between the sum of all singular</span>
<span class="sd">        values kept and the total sum of all singular values.</span>
<span class="sd">        </span>
<span class="sd">        .. math::</span>
<span class="sd">        </span>
<span class="sd">            \frac{\sum_{i \in \{kept\}}{s_i}}{\sum_{i \in \{all\}}{s_i}} \ge</span>
<span class="sd">            cum\_percentage</span>
<span class="sd">    cutoff : float, optional</span>
<span class="sd">        Quantity that lower bounds singular values in order to be kept.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tuple[Node, Node]</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; node = tk.randn(shape=(10, 15, 100),</span>
<span class="sd">    ...                 axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;))</span>
<span class="sd">    &gt;&gt;&gt; node_left, node_right = node.split([&#39;left&#39;], [&#39;right&#39;],</span>
<span class="sd">    ...                                    mode=&#39;svd&#39;,</span>
<span class="sd">    ...                                    rank=5)</span>
<span class="sd">    &gt;&gt;&gt; node_left.shape</span>
<span class="sd">    torch.Size([100, 10, 5])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; node_right.shape</span>
<span class="sd">    torch.Size([100, 5, 15])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; node_left[&#39;splitted&#39;]</span>
<span class="sd">    Edge( split_0[splitted] &lt;-&gt; split_1[splitted] )</span>
<span class="sd">    &quot;&quot;&quot;</span>

<span class="n">AbstractNode</span><span class="o">.</span><span class="n">split</span> <span class="o">=</span> <span class="n">split_node</span>


<div class="viewcode-block" id="split_"><a class="viewcode-back" href="../../operations.html#tensorkrowch.split_">[docs]</a><span class="k">def</span> <span class="nf">split_</span><span class="p">(</span><span class="n">node</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
           <span class="n">node1_axes</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Ax</span><span class="p">],</span>
           <span class="n">node2_axes</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Ax</span><span class="p">],</span>
           <span class="n">mode</span><span class="p">:</span> <span class="n">Text</span> <span class="o">=</span> <span class="s1">&#39;svd&#39;</span><span class="p">,</span>
           <span class="n">side</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Text</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;left&#39;</span><span class="p">,</span>
           <span class="n">rank</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
           <span class="n">cum_percentage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
           <span class="n">cutoff</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Node</span><span class="p">,</span> <span class="n">Node</span><span class="p">]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    In-place version of :func:`split`.</span>

<span class="sd">    Following the **PyTorch** convention, names of functions ended with an</span>
<span class="sd">    underscore indicate **in-place** operations.</span>
<span class="sd">    </span>
<span class="sd">    Since the node is `splitted` in two, a new edge appears connecting both</span>
<span class="sd">    nodes. The axis that corresponds to this edge has the name ``&quot;splitted&quot;``.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation are called ``&quot;split_ip&quot;``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    node : AbstractNode</span>
<span class="sd">        Node that is to be splitted.</span>
<span class="sd">    node1_axes : list[int, str or Axis]</span>
<span class="sd">        First set of edges, will appear as the edges of the first (left)</span>
<span class="sd">        resultant node.</span>
<span class="sd">    node2_axes : list[int, str or Axis]</span>
<span class="sd">        Second set of edges, will appear as the edges of the second (right)</span>
<span class="sd">        resultant node.</span>
<span class="sd">    mode : {&quot;svd&quot;, &quot;svdr&quot;, &quot;qr&quot;, &quot;rq&quot;}</span>
<span class="sd">        Decomposition to be used.</span>
<span class="sd">    side : str, optional</span>
<span class="sd">        If ``mode`` is &quot;svd&quot; or &quot;svdr&quot;, indicates the side to which the diagonal</span>
<span class="sd">        matrix :math:`S` should be contracted. If &quot;left&quot;, the first resultant</span>
<span class="sd">        node&#39;s tensor will be :math:`US`, and the other node&#39;s tensor will be</span>
<span class="sd">        :math:`V^{\dagger}`. If &quot;right&quot;, their tensors will be :math:`U` and</span>
<span class="sd">        :math:`SV^{\dagger}`, respectively.</span>
<span class="sd">    rank : int, optional</span>
<span class="sd">        Number of singular values to keep.</span>
<span class="sd">    cum_percentage : float, optional</span>
<span class="sd">        Proportion that should be satisfied between the sum of all singular</span>
<span class="sd">        values kept and the total sum of all singular values.</span>

<span class="sd">        .. math::</span>

<span class="sd">            \frac{\sum_{i \in \{kept\}}{s_i}}{\sum_{i \in \{all\}}{s_i}} \ge</span>
<span class="sd">            cum\_percentage</span>
<span class="sd">    cutoff : float, optional</span>
<span class="sd">        Quantity that lower bounds singular values in order to be kept.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tuple[Node, Node]</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; node = tk.randn(shape=(10, 15, 100),</span>
<span class="sd">    ...                 axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;))</span>
<span class="sd">    &gt;&gt;&gt; node_left, node_right = tk.split_(node,</span>
<span class="sd">    ...                                   [&#39;left&#39;], [&#39;right&#39;],</span>
<span class="sd">    ...                                   mode=&#39;svd&#39;,</span>
<span class="sd">    ...                                   rank=5)</span>
<span class="sd">    &gt;&gt;&gt; node_left.shape</span>
<span class="sd">    torch.Size([100, 10, 5])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; node_right.shape</span>
<span class="sd">    torch.Size([100, 5, 15])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; node_left[&#39;splitted&#39;]</span>
<span class="sd">    Edge( split_ip_0[splitted] &lt;-&gt; split_ip_1[splitted] )</span>
<span class="sd">    </span>
<span class="sd">    ``node`` has been deleted (removed from the network), but it still exists</span>
<span class="sd">    until is deleted.</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; node.network is None</span>
<span class="sd">    True</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; del node</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">node1</span><span class="p">,</span> <span class="n">node2</span> <span class="o">=</span> <span class="n">split</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">node1_axes</span><span class="p">,</span> <span class="n">node2_axes</span><span class="p">,</span>
                         <span class="n">mode</span><span class="p">,</span> <span class="n">side</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">cum_percentage</span><span class="p">,</span> <span class="n">cutoff</span><span class="p">)</span>
    <span class="n">node1</span><span class="o">.</span><span class="n">reattach_edges</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">node2</span><span class="o">.</span><span class="n">reattach_edges</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">node1</span><span class="o">.</span><span class="n">_unrestricted_set_tensor</span><span class="p">(</span><span class="n">node1</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
    <span class="n">node2</span><span class="o">.</span><span class="n">_unrestricted_set_tensor</span><span class="p">(</span><span class="n">node2</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

    <span class="c1"># Delete node (and its edges) from the TN</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">_network</span>
    <span class="n">net</span><span class="o">.</span><span class="n">delete_node</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

    <span class="c1"># Add edges of result to the TN</span>
    <span class="k">for</span> <span class="n">res_edge</span> <span class="ow">in</span> <span class="n">node1</span><span class="o">.</span><span class="n">_edges</span> <span class="o">+</span> <span class="n">node2</span><span class="o">.</span><span class="n">_edges</span><span class="p">:</span>
        <span class="n">net</span><span class="o">.</span><span class="n">_add_edge</span><span class="p">(</span><span class="n">res_edge</span><span class="p">)</span>

    <span class="c1"># Transform resultant to leaf nodes</span>
    <span class="n">node1</span><span class="o">.</span><span class="n">_leaf</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">del</span> <span class="n">net</span><span class="o">.</span><span class="n">_resultant_nodes</span><span class="p">[</span><span class="n">node1</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span>
    <span class="n">net</span><span class="o">.</span><span class="n">_leaf_nodes</span><span class="p">[</span><span class="n">node1</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">node1</span>

    <span class="n">node2</span><span class="o">.</span><span class="n">_leaf</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">del</span> <span class="n">net</span><span class="o">.</span><span class="n">_resultant_nodes</span><span class="p">[</span><span class="n">node2</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span>
    <span class="n">net</span><span class="o">.</span><span class="n">_leaf_nodes</span><span class="p">[</span><span class="n">node2</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">node2</span>

    <span class="n">node</span><span class="o">.</span><span class="n">_successors</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">net</span><span class="o">.</span><span class="n">_seq_ops</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Remove resultant names</span>
    <span class="n">node1</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;split_ip&#39;</span>
    <span class="n">node2</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;split_ip&#39;</span>

    <span class="k">return</span> <span class="n">node1</span><span class="p">,</span> <span class="n">node2</span></div>


<span class="n">split_node_</span> <span class="o">=</span> <span class="n">copy_func</span><span class="p">(</span><span class="n">split_</span><span class="p">)</span>
<span class="n">split_node_</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> \
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    In-place version of :func:`~AbstractNode.split`.</span>
<span class="sd">    </span>
<span class="sd">    Following the **PyTorch** convention, names of functions ended with an</span>
<span class="sd">    underscore indicate **in-place** operations.</span>
<span class="sd">    </span>
<span class="sd">    Since the node is `splitted` in two, a new edge appears connecting both</span>
<span class="sd">    nodes. The axis that corresponds to this edge has the name ``&quot;splitted&quot;``.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation are called ``&quot;split_ip&quot;``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    node1_axes : list[int, str or Axis]</span>
<span class="sd">        First set of edges, will appear as the edges of the first (left)</span>
<span class="sd">        resultant node.</span>
<span class="sd">    node2_axes : list[int, str or Axis]</span>
<span class="sd">        Second set of edges, will appear as the edges of the second (right)</span>
<span class="sd">        resultant node.</span>
<span class="sd">    mode : {&quot;svd&quot;, &quot;svdr&quot;, &quot;qr&quot;, &quot;rq&quot;}</span>
<span class="sd">        Decomposition to be used.</span>
<span class="sd">    side : str, optional</span>
<span class="sd">        If ``mode`` is &quot;svd&quot; or &quot;svdr&quot;, indicates the side to which the diagonal</span>
<span class="sd">        matrix :math:`S` should be contracted. If &quot;left&quot;, the first resultant</span>
<span class="sd">        node&#39;s tensor will be :math:`US`, and the other node&#39;s tensor will be</span>
<span class="sd">        :math:`V^{\dagger}`. If &quot;right&quot;, their tensors will be :math:`U` and</span>
<span class="sd">        :math:`SV^{\dagger}`, respectively.</span>
<span class="sd">    rank : int, optional</span>
<span class="sd">        Number of singular values to keep.</span>
<span class="sd">    cum_percentage : float, optional</span>
<span class="sd">        Proportion that should be satisfied between the sum of all singular</span>
<span class="sd">        values kept and the total sum of all singular values.</span>
<span class="sd">        </span>
<span class="sd">        .. math::</span>
<span class="sd">        </span>
<span class="sd">            \frac{\sum_{i \in \{kept\}}{s_i}}{\sum_{i \in \{all\}}{s_i}} \ge</span>
<span class="sd">            cum\_percentage</span>
<span class="sd">    cutoff : float, optional</span>
<span class="sd">        Quantity that lower bounds singular values in order to be kept.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tuple[Node, Node]</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; node = tk.randn(shape=(10, 15, 100),</span>
<span class="sd">    ...                 axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;))</span>
<span class="sd">    &gt;&gt;&gt; node_left, node_right = tk.split_(node,</span>
<span class="sd">    ...                                   [&#39;left&#39;], [&#39;right&#39;],</span>
<span class="sd">    ...                                   mode=&#39;svd&#39;,</span>
<span class="sd">    ...                                   rank=5)</span>
<span class="sd">    &gt;&gt;&gt; node_left.shape</span>
<span class="sd">    torch.Size([100, 10, 5])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; node_right.shape</span>
<span class="sd">    torch.Size([100, 5, 15])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; node_left[&#39;splitted&#39;]</span>
<span class="sd">    Edge( split_ip_0[splitted] &lt;-&gt; split_ip_1[splitted] )</span>
<span class="sd">    </span>
<span class="sd">    ``node`` has been deleted (removed from the network), but it still exists</span>
<span class="sd">    until is deleted.</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; node.network is None</span>
<span class="sd">    True</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; del node</span>
<span class="sd">    &quot;&quot;&quot;</span>

<span class="n">AbstractNode</span><span class="o">.</span><span class="n">split_</span> <span class="o">=</span> <span class="n">split_node_</span>


<div class="viewcode-block" id="svd_"><a class="viewcode-back" href="../../operations.html#tensorkrowch.svd_">[docs]</a><span class="k">def</span> <span class="nf">svd_</span><span class="p">(</span><span class="n">edge</span><span class="p">:</span> <span class="n">Edge</span><span class="p">,</span>
         <span class="n">side</span><span class="p">:</span> <span class="n">Text</span> <span class="o">=</span> <span class="s1">&#39;left&#39;</span><span class="p">,</span>
         <span class="n">rank</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
         <span class="n">cum_percentage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
         <span class="n">cutoff</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Node</span><span class="p">,</span> <span class="n">Node</span><span class="p">]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Contracts an edge in-place via :func:`contract_` and splits it in-place via</span>
<span class="sd">    :func:`split_` using ``mode = &quot;svd&quot;``. See :func:`split` for a more complete</span>
<span class="sd">    explanation.</span>

<span class="sd">    Following the **PyTorch** convention, names of functions ended with an</span>
<span class="sd">    underscore indicate **in-place** operations.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation use the same names as the original</span>
<span class="sd">    nodes connected by ``edge``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    edge : Edge</span>
<span class="sd">        Edge whose nodes are to be contracted and splitted.</span>
<span class="sd">    side : str, optional</span>
<span class="sd">        Indicates the side to which the diagonal matrix :math:`S` should be</span>
<span class="sd">        contracted. If &quot;left&quot;, the first resultant node&#39;s tensor will be</span>
<span class="sd">        :math:`US`, and the other node&#39;s tensor will be :math:`V^{\dagger}`.</span>
<span class="sd">        If &quot;right&quot;, their tensors will be :math:`U` and :math:`SV^{\dagger}`,</span>
<span class="sd">        respectively.</span>
<span class="sd">    rank : int, optional</span>
<span class="sd">        Number of singular values to keep.</span>
<span class="sd">    cum_percentage : float, optional</span>
<span class="sd">        Proportion that should be satisfied between the sum of all singular</span>
<span class="sd">        values kept and the total sum of all singular values.</span>

<span class="sd">        .. math::</span>

<span class="sd">            \frac{\sum_{i \in \{kept\}}{s_i}}{\sum_{i \in \{all\}}{s_i}} \ge</span>
<span class="sd">            cum\_percentage</span>
<span class="sd">    cutoff : float, optional</span>
<span class="sd">        Quantity that lower bounds singular values in order to be kept.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tuple[Node, Node]</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.randn(shape=(10, 15, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeA&#39;)</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.randn(shape=(15, 20, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeB&#39;)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; new_edge = nodeA[&#39;right&#39;] ^ nodeB[&#39;left&#39;]</span>
<span class="sd">    &gt;&gt;&gt; nodeA, nodeB = tk.svd_(new_edge, rank=7)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; nodeA.shape</span>
<span class="sd">    torch.Size([10, 7, 100])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; nodeB.shape</span>
<span class="sd">    torch.Size([7, 20, 100])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; print(nodeA.axes_names)</span>
<span class="sd">    [&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;]</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; print(nodeB.axes_names)</span>
<span class="sd">    [&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">edge</span><span class="o">.</span><span class="n">is_dangling</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Edge should be connected to perform SVD&#39;</span><span class="p">)</span>

    <span class="n">node1</span><span class="p">,</span> <span class="n">node2</span> <span class="o">=</span> <span class="n">edge</span><span class="o">.</span><span class="n">node1</span><span class="p">,</span> <span class="n">edge</span><span class="o">.</span><span class="n">node2</span>
    <span class="n">node1_name</span><span class="p">,</span> <span class="n">node2_name</span> <span class="o">=</span> <span class="n">node1</span><span class="o">.</span><span class="n">_name</span><span class="p">,</span> <span class="n">node2</span><span class="o">.</span><span class="n">_name</span>
    <span class="n">axis1</span><span class="p">,</span> <span class="n">axis2</span> <span class="o">=</span> <span class="n">edge</span><span class="o">.</span><span class="n">axis1</span><span class="p">,</span> <span class="n">edge</span><span class="o">.</span><span class="n">axis2</span>

    <span class="n">batch_axes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">node1</span><span class="o">.</span><span class="n">_axes</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">axis</span><span class="o">.</span><span class="n">is_batch</span><span class="p">()</span> <span class="ow">and</span> <span class="p">(</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span> <span class="ow">in</span> <span class="n">node2</span><span class="o">.</span><span class="n">axes_names</span><span class="p">):</span>
            <span class="n">batch_axes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span>

    <span class="n">n_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_axes</span><span class="p">)</span>
    <span class="n">n_axes1</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">node1</span><span class="o">.</span><span class="n">_axes</span><span class="p">)</span> <span class="o">-</span> <span class="n">n_batches</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">n_axes2</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">node2</span><span class="o">.</span><span class="n">_axes</span><span class="p">)</span> <span class="o">-</span> <span class="n">n_batches</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="n">contracted</span> <span class="o">=</span> <span class="n">edge</span><span class="o">.</span><span class="n">contract_</span><span class="p">()</span>
    <span class="n">new_node1</span><span class="p">,</span> <span class="n">new_node2</span> <span class="o">=</span> <span class="n">split_</span><span class="p">(</span><span class="n">node</span><span class="o">=</span><span class="n">contracted</span><span class="p">,</span>
                                  <span class="n">node1_axes</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span>
                                      <span class="nb">range</span><span class="p">(</span><span class="n">n_batches</span><span class="p">,</span>
                                            <span class="n">n_batches</span> <span class="o">+</span> <span class="n">n_axes1</span><span class="p">)),</span>
                                  <span class="n">node2_axes</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span>
                                      <span class="nb">range</span><span class="p">(</span><span class="n">n_batches</span> <span class="o">+</span> <span class="n">n_axes1</span><span class="p">,</span>
                                            <span class="n">n_batches</span> <span class="o">+</span> <span class="n">n_axes1</span> <span class="o">+</span> <span class="n">n_axes2</span><span class="p">)),</span>
                                  <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;svd&#39;</span><span class="p">,</span>
                                  <span class="n">side</span><span class="o">=</span><span class="n">side</span><span class="p">,</span>
                                  <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
                                  <span class="n">cum_percentage</span><span class="o">=</span><span class="n">cum_percentage</span><span class="p">,</span>
                                  <span class="n">cutoff</span><span class="o">=</span><span class="n">cutoff</span><span class="p">)</span>

    <span class="c1"># new_node1</span>
    <span class="n">prev_nums</span> <span class="o">=</span> <span class="p">[</span><span class="n">ax</span><span class="o">.</span><span class="n">num</span> <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">batch_axes</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_node1</span><span class="o">.</span><span class="n">rank</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">prev_nums</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">i</span> <span class="o">!=</span> <span class="n">axis1</span><span class="o">.</span><span class="n">_num</span><span class="p">):</span>
            <span class="n">prev_nums</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="n">prev_nums</span> <span class="o">+=</span> <span class="p">[</span><span class="n">axis1</span><span class="o">.</span><span class="n">_num</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">prev_nums</span> <span class="o">!=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">new_node1</span><span class="o">.</span><span class="n">rank</span><span class="p">)):</span>
        <span class="n">permutation</span> <span class="o">=</span> <span class="n">inverse_permutation</span><span class="p">(</span><span class="n">prev_nums</span><span class="p">)</span>
        <span class="n">new_node1</span> <span class="o">=</span> <span class="n">new_node1</span><span class="o">.</span><span class="n">permute_</span><span class="p">(</span><span class="n">permutation</span><span class="p">)</span>

    <span class="c1"># new_node2</span>
    <span class="n">prev_nums</span> <span class="o">=</span> <span class="p">[</span><span class="n">node2</span><span class="o">.</span><span class="n">get_axis_num</span><span class="p">(</span><span class="n">node1</span><span class="o">.</span><span class="n">get_axis</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span><span class="o">.</span><span class="n">_name</span><span class="p">)</span>
                 <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">batch_axes</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">axis2</span><span class="o">.</span><span class="n">_num</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_node2</span><span class="o">.</span><span class="n">rank</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">prev_nums</span><span class="p">:</span>
            <span class="n">prev_nums</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">prev_nums</span> <span class="o">!=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">new_node2</span><span class="o">.</span><span class="n">rank</span><span class="p">)):</span>
        <span class="n">permutation</span> <span class="o">=</span> <span class="n">inverse_permutation</span><span class="p">(</span><span class="n">prev_nums</span><span class="p">)</span>
        <span class="n">new_node2</span> <span class="o">=</span> <span class="n">new_node2</span><span class="o">.</span><span class="n">permute_</span><span class="p">(</span><span class="n">permutation</span><span class="p">)</span>

    <span class="n">new_node1</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">node1_name</span>
    <span class="n">new_node1</span><span class="o">.</span><span class="n">get_axis</span><span class="p">(</span><span class="n">axis1</span><span class="o">.</span><span class="n">_num</span><span class="p">)</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">axis1</span><span class="o">.</span><span class="n">_name</span>

    <span class="n">new_node2</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">node2_name</span>
    <span class="n">new_node2</span><span class="o">.</span><span class="n">get_axis</span><span class="p">(</span><span class="n">axis2</span><span class="o">.</span><span class="n">_num</span><span class="p">)</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">axis2</span><span class="o">.</span><span class="n">_name</span>

    <span class="k">return</span> <span class="n">new_node1</span><span class="p">,</span> <span class="n">new_node2</span></div>


<span class="n">svd_edge_</span> <span class="o">=</span> <span class="n">copy_func</span><span class="p">(</span><span class="n">svd_</span><span class="p">)</span>
<span class="n">svd_edge_</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> \
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Contracts an edge in-place via :func:`~Edge.contract_` and splits</span>
<span class="sd">    it in-place via :func:`~AbstractNode.split_` using ``mode = &quot;svd&quot;``. See</span>
<span class="sd">    :func:`split` for a more complete explanation.</span>
<span class="sd">    </span>
<span class="sd">    Following the **PyTorch** convention, names of functions ended with an</span>
<span class="sd">    underscore indicate **in-place** operations.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation use the same names as the original</span>
<span class="sd">    nodes connected by ``self``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    side : str, optional</span>
<span class="sd">        Indicates the side to which the diagonal matrix :math:`S` should be</span>
<span class="sd">        contracted. If &quot;left&quot;, the first resultant node&#39;s tensor will be</span>
<span class="sd">        :math:`US`, and the other node&#39;s tensor will be :math:`V^{\dagger}`.</span>
<span class="sd">        If &quot;right&quot;, their tensors will be :math:`U` and :math:`SV^{\dagger}`,</span>
<span class="sd">        respectively.</span>
<span class="sd">    rank : int, optional</span>
<span class="sd">        Number of singular values to keep.</span>
<span class="sd">    cum_percentage : float, optional</span>
<span class="sd">        Proportion that should be satisfied between the sum of all singular</span>
<span class="sd">        values kept and the total sum of all singular values.</span>
<span class="sd">        </span>
<span class="sd">        .. math::</span>
<span class="sd">        </span>
<span class="sd">            \frac{\sum_{i \in \{kept\}}{s_i}}{\sum_{i \in \{all\}}{s_i}} \ge</span>
<span class="sd">            cum\_percentage</span>
<span class="sd">    cutoff : float, optional</span>
<span class="sd">        Quantity that lower bounds singular values in order to be kept.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tuple[Node, Node]</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.randn(shape=(10, 15, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeA&#39;)</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.randn(shape=(15, 20, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeB&#39;)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; new_edge = nodeA[&#39;right&#39;] ^ nodeB[&#39;left&#39;]</span>
<span class="sd">    &gt;&gt;&gt; nodeA, nodeB = new_edge.svd_(rank=7)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; nodeA.shape</span>
<span class="sd">    torch.Size([10, 7, 100])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; nodeB.shape</span>
<span class="sd">    torch.Size([7, 20, 100])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; print(nodeA.axes_names)</span>
<span class="sd">    [&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;]</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; print(nodeB.axes_names)</span>
<span class="sd">    [&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;]</span>
<span class="sd">    &quot;&quot;&quot;</span>

<span class="n">Edge</span><span class="o">.</span><span class="n">svd_</span> <span class="o">=</span> <span class="n">svd_edge_</span>


<div class="viewcode-block" id="svdr_"><a class="viewcode-back" href="../../operations.html#tensorkrowch.svdr_">[docs]</a><span class="k">def</span> <span class="nf">svdr_</span><span class="p">(</span><span class="n">edge</span><span class="p">:</span> <span class="n">Edge</span><span class="p">,</span>
          <span class="n">side</span><span class="p">:</span> <span class="n">Text</span> <span class="o">=</span> <span class="s1">&#39;left&#39;</span><span class="p">,</span>
          <span class="n">rank</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
          <span class="n">cum_percentage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
          <span class="n">cutoff</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Node</span><span class="p">,</span> <span class="n">Node</span><span class="p">]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Contracts an edge in-place via :func:`contract_` and splits it in-place via</span>
<span class="sd">    :func:`split_` using ``mode = &quot;svdr&quot;``. See :func:`split` for a more complete</span>
<span class="sd">    explanation.</span>

<span class="sd">    Following the **PyTorch** convention, names of functions ended with an</span>
<span class="sd">    underscore indicate **in-place** operations.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation use the same names as the original</span>
<span class="sd">    nodes connected by ``edge``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    edge : Edge</span>
<span class="sd">        Edge whose nodes are to be contracted and splitted.</span>
<span class="sd">    side : str, optional</span>
<span class="sd">        Indicates the side to which the diagonal matrix :math:`S` should be</span>
<span class="sd">        contracted. If &quot;left&quot;, the first resultant node&#39;s tensor will be</span>
<span class="sd">        :math:`US`, and the other node&#39;s tensor will be :math:`V^{\dagger}`.</span>
<span class="sd">        If &quot;right&quot;, their tensors will be :math:`U` and :math:`SV^{\dagger}`,</span>
<span class="sd">        respectively.</span>
<span class="sd">    rank : int, optional</span>
<span class="sd">        Number of singular values to keep.</span>
<span class="sd">    cum_percentage : float, optional</span>
<span class="sd">        Proportion that should be satisfied between the sum of all singular</span>
<span class="sd">        values kept and the total sum of all singular values.</span>

<span class="sd">        .. math::</span>

<span class="sd">            \frac{\sum_{i \in \{kept\}}{s_i}}{\sum_{i \in \{all\}}{s_i}} \ge</span>
<span class="sd">            cum\_percentage</span>
<span class="sd">    cutoff : float, optional</span>
<span class="sd">        Quantity that lower bounds singular values in order to be kept.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tuple[Node, Node]</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.randn(shape=(10, 15, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeA&#39;)</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.randn(shape=(15, 20, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeB&#39;)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; new_edge = nodeA[&#39;right&#39;] ^ nodeB[&#39;left&#39;]</span>
<span class="sd">    &gt;&gt;&gt; nodeA, nodeB = tk.svdr_(new_edge, rank=7)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; nodeA.shape</span>
<span class="sd">    torch.Size([10, 7, 100])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; nodeB.shape</span>
<span class="sd">    torch.Size([7, 20, 100])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; print(nodeA.axes_names)</span>
<span class="sd">    [&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;]</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; print(nodeB.axes_names)</span>
<span class="sd">    [&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">edge</span><span class="o">.</span><span class="n">is_dangling</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Edge should be connected to perform SVD&#39;</span><span class="p">)</span>

    <span class="n">node1</span><span class="p">,</span> <span class="n">node2</span> <span class="o">=</span> <span class="n">edge</span><span class="o">.</span><span class="n">node1</span><span class="p">,</span> <span class="n">edge</span><span class="o">.</span><span class="n">node2</span>
    <span class="n">node1_name</span><span class="p">,</span> <span class="n">node2_name</span> <span class="o">=</span> <span class="n">node1</span><span class="o">.</span><span class="n">_name</span><span class="p">,</span> <span class="n">node2</span><span class="o">.</span><span class="n">_name</span>
    <span class="n">axis1</span><span class="p">,</span> <span class="n">axis2</span> <span class="o">=</span> <span class="n">edge</span><span class="o">.</span><span class="n">axis1</span><span class="p">,</span> <span class="n">edge</span><span class="o">.</span><span class="n">axis2</span>

    <span class="n">batch_axes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">node1</span><span class="o">.</span><span class="n">_axes</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">axis</span><span class="o">.</span><span class="n">is_batch</span><span class="p">()</span> <span class="ow">and</span> <span class="p">(</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span> <span class="ow">in</span> <span class="n">node2</span><span class="o">.</span><span class="n">axes_names</span><span class="p">):</span>
            <span class="n">batch_axes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span>

    <span class="n">n_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_axes</span><span class="p">)</span>
    <span class="n">n_axes1</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">node1</span><span class="o">.</span><span class="n">_axes</span><span class="p">)</span> <span class="o">-</span> <span class="n">n_batches</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">n_axes2</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">node2</span><span class="o">.</span><span class="n">_axes</span><span class="p">)</span> <span class="o">-</span> <span class="n">n_batches</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="n">contracted</span> <span class="o">=</span> <span class="n">edge</span><span class="o">.</span><span class="n">contract_</span><span class="p">()</span>
    <span class="n">new_node1</span><span class="p">,</span> <span class="n">new_node2</span> <span class="o">=</span> <span class="n">split_</span><span class="p">(</span><span class="n">node</span><span class="o">=</span><span class="n">contracted</span><span class="p">,</span>
                                  <span class="n">node1_axes</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span>
                                      <span class="nb">range</span><span class="p">(</span><span class="n">n_batches</span><span class="p">,</span>
                                            <span class="n">n_batches</span> <span class="o">+</span> <span class="n">n_axes1</span><span class="p">)),</span>
                                  <span class="n">node2_axes</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span>
                                      <span class="nb">range</span><span class="p">(</span><span class="n">n_batches</span> <span class="o">+</span> <span class="n">n_axes1</span><span class="p">,</span>
                                            <span class="n">n_batches</span> <span class="o">+</span> <span class="n">n_axes1</span> <span class="o">+</span> <span class="n">n_axes2</span><span class="p">)),</span>
                                  <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;svdr&#39;</span><span class="p">,</span>
                                  <span class="n">side</span><span class="o">=</span><span class="n">side</span><span class="p">,</span>
                                  <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
                                  <span class="n">cum_percentage</span><span class="o">=</span><span class="n">cum_percentage</span><span class="p">,</span>
                                  <span class="n">cutoff</span><span class="o">=</span><span class="n">cutoff</span><span class="p">)</span>

    <span class="c1"># new_node1</span>
    <span class="n">prev_nums</span> <span class="o">=</span> <span class="p">[</span><span class="n">ax</span><span class="o">.</span><span class="n">_num</span> <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">batch_axes</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_node1</span><span class="o">.</span><span class="n">rank</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">prev_nums</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">i</span> <span class="o">!=</span> <span class="n">axis1</span><span class="o">.</span><span class="n">_num</span><span class="p">):</span>
            <span class="n">prev_nums</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="n">prev_nums</span> <span class="o">+=</span> <span class="p">[</span><span class="n">axis1</span><span class="o">.</span><span class="n">_num</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">prev_nums</span> <span class="o">!=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">new_node1</span><span class="o">.</span><span class="n">rank</span><span class="p">)):</span>
        <span class="n">permutation</span> <span class="o">=</span> <span class="n">inverse_permutation</span><span class="p">(</span><span class="n">prev_nums</span><span class="p">)</span>
        <span class="n">new_node1</span> <span class="o">=</span> <span class="n">new_node1</span><span class="o">.</span><span class="n">permute_</span><span class="p">(</span><span class="n">permutation</span><span class="p">)</span>

    <span class="c1"># new_node2</span>
    <span class="n">prev_nums</span> <span class="o">=</span> <span class="p">[</span><span class="n">node2</span><span class="o">.</span><span class="n">get_axis_num</span><span class="p">(</span><span class="n">node1</span><span class="o">.</span><span class="n">get_axis</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span><span class="o">.</span><span class="n">_name</span><span class="p">)</span>
                 <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">batch_axes</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">axis2</span><span class="o">.</span><span class="n">_num</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_node2</span><span class="o">.</span><span class="n">rank</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">prev_nums</span><span class="p">:</span>
            <span class="n">prev_nums</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">prev_nums</span> <span class="o">!=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">new_node2</span><span class="o">.</span><span class="n">rank</span><span class="p">)):</span>
        <span class="n">permutation</span> <span class="o">=</span> <span class="n">inverse_permutation</span><span class="p">(</span><span class="n">prev_nums</span><span class="p">)</span>
        <span class="n">new_node2</span> <span class="o">=</span> <span class="n">new_node2</span><span class="o">.</span><span class="n">permute_</span><span class="p">(</span><span class="n">permutation</span><span class="p">)</span>

    <span class="n">new_node1</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">node1_name</span>
    <span class="n">new_node1</span><span class="o">.</span><span class="n">get_axis</span><span class="p">(</span><span class="n">axis1</span><span class="o">.</span><span class="n">_num</span><span class="p">)</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">axis1</span><span class="o">.</span><span class="n">_name</span>

    <span class="n">new_node2</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">node2_name</span>
    <span class="n">new_node2</span><span class="o">.</span><span class="n">get_axis</span><span class="p">(</span><span class="n">axis2</span><span class="o">.</span><span class="n">_num</span><span class="p">)</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">axis2</span><span class="o">.</span><span class="n">_name</span>

    <span class="k">return</span> <span class="n">new_node1</span><span class="p">,</span> <span class="n">new_node2</span></div>


<span class="n">svdr_edge_</span> <span class="o">=</span> <span class="n">copy_func</span><span class="p">(</span><span class="n">svdr_</span><span class="p">)</span>
<span class="n">svdr_edge_</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> \
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Contracts an edge in-place via :func:`~Edge.contract_` and splits</span>
<span class="sd">    it in-place via :func:`~AbstractNode.split_` using ``mode = &quot;svdr&quot;``. See</span>
<span class="sd">    :func:`split` for a more complete explanation.</span>
<span class="sd">    </span>
<span class="sd">    Following the **PyTorch** convention, names of functions ended with an</span>
<span class="sd">    underscore indicate **in-place** operations.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation use the same names as the original</span>
<span class="sd">    nodes connected by ``self``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    side : str, optional</span>
<span class="sd">        Indicates the side to which the diagonal matrix :math:`S` should be</span>
<span class="sd">        contracted. If &quot;left&quot;, the first resultant node&#39;s tensor will be</span>
<span class="sd">        :math:`US`, and the other node&#39;s tensor will be :math:`V^{\dagger}`.</span>
<span class="sd">        If &quot;right&quot;, their tensors will be :math:`U` and :math:`SV^{\dagger}`,</span>
<span class="sd">        respectively.</span>
<span class="sd">    rank : int, optional</span>
<span class="sd">        Number of singular values to keep.</span>
<span class="sd">    cum_percentage : float, optional</span>
<span class="sd">        Proportion that should be satisfied between the sum of all singular</span>
<span class="sd">        values kept and the total sum of all singular values.</span>
<span class="sd">        </span>
<span class="sd">        .. math::</span>
<span class="sd">        </span>
<span class="sd">            \frac{\sum_{i \in \{kept\}}{s_i}}{\sum_{i \in \{all\}}{s_i}} \ge</span>
<span class="sd">            cum\_percentage</span>
<span class="sd">    cutoff : float, optional</span>
<span class="sd">        Quantity that lower bounds singular values in order to be kept.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tuple[Node, Node]</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.randn(shape=(10, 15, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeA&#39;)</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.randn(shape=(15, 20, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeB&#39;)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; new_edge = nodeA[&#39;right&#39;] ^ nodeB[&#39;left&#39;]</span>
<span class="sd">    &gt;&gt;&gt; nodeA, nodeB = new_edge.svdr_(rank=7)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; nodeA.shape</span>
<span class="sd">    torch.Size([10, 7, 100])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; nodeB.shape</span>
<span class="sd">    torch.Size([7, 20, 100])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; print(nodeA.axes_names)</span>
<span class="sd">    [&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;]</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; print(nodeB.axes_names)</span>
<span class="sd">    [&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;]</span>
<span class="sd">    &quot;&quot;&quot;</span>

<span class="n">Edge</span><span class="o">.</span><span class="n">svdr_</span> <span class="o">=</span> <span class="n">svdr_edge_</span>


<div class="viewcode-block" id="qr_"><a class="viewcode-back" href="../../operations.html#tensorkrowch.qr_">[docs]</a><span class="k">def</span> <span class="nf">qr_</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Node</span><span class="p">,</span> <span class="n">Node</span><span class="p">]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Contracts an edge in-place via :func:`contract_` and splits it in-place via</span>
<span class="sd">    :func:`split_` using ``mode = &quot;qr&quot;``. See :func:`split` for a more complete</span>
<span class="sd">    explanation.</span>

<span class="sd">    Following the **PyTorch** convention, names of functions ended with an</span>
<span class="sd">    underscore indicate **in-place** operations.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation use the same names as the original</span>
<span class="sd">    nodes connected by ``edge``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    edge : Edge</span>
<span class="sd">        Edge whose nodes are to be contracted and splitted.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tuple[Node, Node]</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.randn(shape=(10, 15, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeA&#39;)</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.randn(shape=(15, 20, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeB&#39;)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; new_edge = nodeA[&#39;right&#39;] ^ nodeB[&#39;left&#39;]</span>
<span class="sd">    &gt;&gt;&gt; nodeA, nodeB = tk.qr_(new_edge)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; nodeA.shape</span>
<span class="sd">    torch.Size([10, 10, 100])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; nodeB.shape</span>
<span class="sd">    torch.Size([10, 20, 100])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; print(nodeA.axes_names)</span>
<span class="sd">    [&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;]</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; print(nodeB.axes_names)</span>
<span class="sd">    [&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">edge</span><span class="o">.</span><span class="n">is_dangling</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Edge should be connected to perform SVD&#39;</span><span class="p">)</span>

    <span class="n">node1</span><span class="p">,</span> <span class="n">node2</span> <span class="o">=</span> <span class="n">edge</span><span class="o">.</span><span class="n">node1</span><span class="p">,</span> <span class="n">edge</span><span class="o">.</span><span class="n">node2</span>
    <span class="n">node1_name</span><span class="p">,</span> <span class="n">node2_name</span> <span class="o">=</span> <span class="n">node1</span><span class="o">.</span><span class="n">_name</span><span class="p">,</span> <span class="n">node2</span><span class="o">.</span><span class="n">_name</span>
    <span class="n">axis1</span><span class="p">,</span> <span class="n">axis2</span> <span class="o">=</span> <span class="n">edge</span><span class="o">.</span><span class="n">axis1</span><span class="p">,</span> <span class="n">edge</span><span class="o">.</span><span class="n">axis2</span>

    <span class="n">batch_axes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">node1</span><span class="o">.</span><span class="n">_axes</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">axis</span><span class="o">.</span><span class="n">is_batch</span><span class="p">()</span> <span class="ow">and</span> <span class="p">(</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span> <span class="ow">in</span> <span class="n">node2</span><span class="o">.</span><span class="n">axes_names</span><span class="p">):</span>
            <span class="n">batch_axes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span>

    <span class="n">n_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_axes</span><span class="p">)</span>
    <span class="n">n_axes1</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">node1</span><span class="o">.</span><span class="n">_axes</span><span class="p">)</span> <span class="o">-</span> <span class="n">n_batches</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">n_axes2</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">node2</span><span class="o">.</span><span class="n">_axes</span><span class="p">)</span> <span class="o">-</span> <span class="n">n_batches</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="n">contracted</span> <span class="o">=</span> <span class="n">edge</span><span class="o">.</span><span class="n">contract_</span><span class="p">()</span>
    <span class="n">new_node1</span><span class="p">,</span> <span class="n">new_node2</span> <span class="o">=</span> <span class="n">split_</span><span class="p">(</span><span class="n">node</span><span class="o">=</span><span class="n">contracted</span><span class="p">,</span>
                                  <span class="n">node1_axes</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span>
                                      <span class="nb">range</span><span class="p">(</span><span class="n">n_batches</span><span class="p">,</span>
                                            <span class="n">n_batches</span> <span class="o">+</span> <span class="n">n_axes1</span><span class="p">)),</span>
                                  <span class="n">node2_axes</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span>
                                      <span class="nb">range</span><span class="p">(</span><span class="n">n_batches</span> <span class="o">+</span> <span class="n">n_axes1</span><span class="p">,</span>
                                            <span class="n">n_batches</span> <span class="o">+</span> <span class="n">n_axes1</span> <span class="o">+</span> <span class="n">n_axes2</span><span class="p">)),</span>
                                  <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;qr&#39;</span><span class="p">)</span>

    <span class="c1"># new_node1</span>
    <span class="n">prev_nums</span> <span class="o">=</span> <span class="p">[</span><span class="n">ax</span><span class="o">.</span><span class="n">_num</span> <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">batch_axes</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_node1</span><span class="o">.</span><span class="n">rank</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">prev_nums</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">i</span> <span class="o">!=</span> <span class="n">axis1</span><span class="o">.</span><span class="n">_num</span><span class="p">):</span>
            <span class="n">prev_nums</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="n">prev_nums</span> <span class="o">+=</span> <span class="p">[</span><span class="n">axis1</span><span class="o">.</span><span class="n">_num</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">prev_nums</span> <span class="o">!=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">new_node1</span><span class="o">.</span><span class="n">rank</span><span class="p">)):</span>
        <span class="n">permutation</span> <span class="o">=</span> <span class="n">inverse_permutation</span><span class="p">(</span><span class="n">prev_nums</span><span class="p">)</span>
        <span class="n">new_node1</span> <span class="o">=</span> <span class="n">new_node1</span><span class="o">.</span><span class="n">permute_</span><span class="p">(</span><span class="n">permutation</span><span class="p">)</span>

    <span class="c1"># new_node2</span>
    <span class="n">prev_nums</span> <span class="o">=</span> <span class="p">[</span><span class="n">node2</span><span class="o">.</span><span class="n">get_axis_num</span><span class="p">(</span><span class="n">node1</span><span class="o">.</span><span class="n">get_axis</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span><span class="o">.</span><span class="n">_name</span><span class="p">)</span>
                 <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">batch_axes</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">axis2</span><span class="o">.</span><span class="n">_num</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_node2</span><span class="o">.</span><span class="n">rank</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">prev_nums</span><span class="p">:</span>
            <span class="n">prev_nums</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">prev_nums</span> <span class="o">!=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">new_node2</span><span class="o">.</span><span class="n">rank</span><span class="p">)):</span>
        <span class="n">permutation</span> <span class="o">=</span> <span class="n">inverse_permutation</span><span class="p">(</span><span class="n">prev_nums</span><span class="p">)</span>
        <span class="n">new_node2</span> <span class="o">=</span> <span class="n">new_node2</span><span class="o">.</span><span class="n">permute_</span><span class="p">(</span><span class="n">permutation</span><span class="p">)</span>

    <span class="n">new_node1</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">node1_name</span>
    <span class="n">new_node1</span><span class="o">.</span><span class="n">get_axis</span><span class="p">(</span><span class="n">axis1</span><span class="o">.</span><span class="n">_num</span><span class="p">)</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">axis1</span><span class="o">.</span><span class="n">_name</span>

    <span class="n">new_node2</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">node2_name</span>
    <span class="n">new_node2</span><span class="o">.</span><span class="n">get_axis</span><span class="p">(</span><span class="n">axis2</span><span class="o">.</span><span class="n">_num</span><span class="p">)</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">axis2</span><span class="o">.</span><span class="n">_name</span>

    <span class="k">return</span> <span class="n">new_node1</span><span class="p">,</span> <span class="n">new_node2</span></div>


<span class="n">qr_edge_</span> <span class="o">=</span> <span class="n">copy_func</span><span class="p">(</span><span class="n">qr_</span><span class="p">)</span>
<span class="n">qr_edge_</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> \
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Contracts an edge in-place via :func:`~Edge.contract_` and splits</span>
<span class="sd">    it in-place via :func:`~AbstractNode.split_` using ``mode = &quot;qr&quot;``. See</span>
<span class="sd">    :func:`split` for a more complete explanation.</span>
<span class="sd">    </span>
<span class="sd">    Following the **PyTorch** convention, names of functions ended with an</span>
<span class="sd">    underscore indicate **in-place** operations.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation use the same names as the original</span>
<span class="sd">    nodes connected by ``self``.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tuple[Node, Node]</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.randn(shape=(10, 15, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeA&#39;)</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.randn(shape=(15, 20, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeB&#39;)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; new_edge = nodeA[&#39;right&#39;] ^ nodeB[&#39;left&#39;]</span>
<span class="sd">    &gt;&gt;&gt; nodeA, nodeB = new_edge.qr_()</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; nodeA.shape</span>
<span class="sd">    torch.Size([10, 10, 100])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; nodeB.shape</span>
<span class="sd">    torch.Size([10, 20, 100])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; print(nodeA.axes_names)</span>
<span class="sd">    [&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;]</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; print(nodeB.axes_names)</span>
<span class="sd">    [&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;]</span>
<span class="sd">    &quot;&quot;&quot;</span>

<span class="n">Edge</span><span class="o">.</span><span class="n">qr_</span> <span class="o">=</span> <span class="n">qr_edge_</span>


<div class="viewcode-block" id="rq_"><a class="viewcode-back" href="../../operations.html#tensorkrowch.rq_">[docs]</a><span class="k">def</span> <span class="nf">rq_</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Node</span><span class="p">,</span> <span class="n">Node</span><span class="p">]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Contracts an edge in-place via :func:`contract_` and splits it in-place via</span>
<span class="sd">    :func:`split_` using ``mode = &quot;rq&quot;``. See :func:`split` for a more complete</span>
<span class="sd">    explanation.</span>

<span class="sd">    Following the **PyTorch** convention, names of functions ended with an</span>
<span class="sd">    underscore indicate **in-place** operations.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation use the same names as the original</span>
<span class="sd">    nodes connected by ``edge``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    edge : Edge</span>
<span class="sd">        Edge whose nodes are to be contracted and splitted.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tuple[Node, Node]</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.randn(shape=(10, 15, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeA&#39;)</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.randn(shape=(15, 20, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeB&#39;)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; new_edge = nodeA[&#39;right&#39;] ^ nodeB[&#39;left&#39;]</span>
<span class="sd">    &gt;&gt;&gt; nodeA, nodeB = tk.rq_(new_edge)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; nodeA.shape</span>
<span class="sd">    torch.Size([10, 10, 100])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; nodeB.shape</span>
<span class="sd">    torch.Size([10, 20, 100])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; print(nodeA.axes_names)</span>
<span class="sd">    [&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;]</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; print(nodeB.axes_names)</span>
<span class="sd">    [&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">edge</span><span class="o">.</span><span class="n">is_dangling</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Edge should be connected to perform SVD&#39;</span><span class="p">)</span>

    <span class="n">node1</span><span class="p">,</span> <span class="n">node2</span> <span class="o">=</span> <span class="n">edge</span><span class="o">.</span><span class="n">node1</span><span class="p">,</span> <span class="n">edge</span><span class="o">.</span><span class="n">node2</span>
    <span class="n">node1_name</span><span class="p">,</span> <span class="n">node2_name</span> <span class="o">=</span> <span class="n">node1</span><span class="o">.</span><span class="n">_name</span><span class="p">,</span> <span class="n">node2</span><span class="o">.</span><span class="n">_name</span>
    <span class="n">axis1</span><span class="p">,</span> <span class="n">axis2</span> <span class="o">=</span> <span class="n">edge</span><span class="o">.</span><span class="n">axis1</span><span class="p">,</span> <span class="n">edge</span><span class="o">.</span><span class="n">axis2</span>

    <span class="n">batch_axes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">node1</span><span class="o">.</span><span class="n">_axes</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">axis</span><span class="o">.</span><span class="n">is_batch</span><span class="p">()</span> <span class="ow">and</span> <span class="p">(</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span> <span class="ow">in</span> <span class="n">node2</span><span class="o">.</span><span class="n">axes_names</span><span class="p">):</span>
            <span class="n">batch_axes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span>

    <span class="n">n_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_axes</span><span class="p">)</span>
    <span class="n">n_axes1</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">node1</span><span class="o">.</span><span class="n">_axes</span><span class="p">)</span> <span class="o">-</span> <span class="n">n_batches</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">n_axes2</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">node2</span><span class="o">.</span><span class="n">_axes</span><span class="p">)</span> <span class="o">-</span> <span class="n">n_batches</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="n">contracted</span> <span class="o">=</span> <span class="n">edge</span><span class="o">.</span><span class="n">contract_</span><span class="p">()</span>
    <span class="n">new_node1</span><span class="p">,</span> <span class="n">new_node2</span> <span class="o">=</span> <span class="n">split_</span><span class="p">(</span><span class="n">node</span><span class="o">=</span><span class="n">contracted</span><span class="p">,</span>
                                  <span class="n">node1_axes</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span>
                                      <span class="nb">range</span><span class="p">(</span><span class="n">n_batches</span><span class="p">,</span>
                                            <span class="n">n_batches</span> <span class="o">+</span> <span class="n">n_axes1</span><span class="p">)),</span>
                                  <span class="n">node2_axes</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span>
                                      <span class="nb">range</span><span class="p">(</span><span class="n">n_batches</span> <span class="o">+</span> <span class="n">n_axes1</span><span class="p">,</span>
                                            <span class="n">n_batches</span> <span class="o">+</span> <span class="n">n_axes1</span> <span class="o">+</span> <span class="n">n_axes2</span><span class="p">)),</span>
                                  <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;rq&#39;</span><span class="p">)</span>

    <span class="c1"># new_node1</span>
    <span class="n">prev_nums</span> <span class="o">=</span> <span class="p">[</span><span class="n">ax</span><span class="o">.</span><span class="n">_num</span> <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">batch_axes</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_node1</span><span class="o">.</span><span class="n">rank</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">prev_nums</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">i</span> <span class="o">!=</span> <span class="n">axis1</span><span class="o">.</span><span class="n">_num</span><span class="p">):</span>
            <span class="n">prev_nums</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="n">prev_nums</span> <span class="o">+=</span> <span class="p">[</span><span class="n">axis1</span><span class="o">.</span><span class="n">_num</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">prev_nums</span> <span class="o">!=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">new_node1</span><span class="o">.</span><span class="n">rank</span><span class="p">)):</span>
        <span class="n">permutation</span> <span class="o">=</span> <span class="n">inverse_permutation</span><span class="p">(</span><span class="n">prev_nums</span><span class="p">)</span>
        <span class="n">new_node1</span> <span class="o">=</span> <span class="n">new_node1</span><span class="o">.</span><span class="n">permute_</span><span class="p">(</span><span class="n">permutation</span><span class="p">)</span>

    <span class="c1"># new_node2</span>
    <span class="n">prev_nums</span> <span class="o">=</span> <span class="p">[</span><span class="n">node2</span><span class="o">.</span><span class="n">get_axis_num</span><span class="p">(</span><span class="n">node1</span><span class="o">.</span><span class="n">get_axis</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span><span class="o">.</span><span class="n">_name</span><span class="p">)</span>
                 <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">batch_axes</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">axis2</span><span class="o">.</span><span class="n">_num</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_node2</span><span class="o">.</span><span class="n">rank</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">prev_nums</span><span class="p">:</span>
            <span class="n">prev_nums</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">prev_nums</span> <span class="o">!=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">new_node2</span><span class="o">.</span><span class="n">rank</span><span class="p">)):</span>
        <span class="n">permutation</span> <span class="o">=</span> <span class="n">inverse_permutation</span><span class="p">(</span><span class="n">prev_nums</span><span class="p">)</span>
        <span class="n">new_node2</span> <span class="o">=</span> <span class="n">new_node2</span><span class="o">.</span><span class="n">permute_</span><span class="p">(</span><span class="n">permutation</span><span class="p">)</span>

    <span class="n">new_node1</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">node1_name</span>
    <span class="n">new_node1</span><span class="o">.</span><span class="n">get_axis</span><span class="p">(</span><span class="n">axis1</span><span class="o">.</span><span class="n">_num</span><span class="p">)</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">axis1</span><span class="o">.</span><span class="n">_name</span>

    <span class="n">new_node2</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">node2_name</span>
    <span class="n">new_node2</span><span class="o">.</span><span class="n">get_axis</span><span class="p">(</span><span class="n">axis2</span><span class="o">.</span><span class="n">_num</span><span class="p">)</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">axis2</span><span class="o">.</span><span class="n">_name</span>

    <span class="k">return</span> <span class="n">new_node1</span><span class="p">,</span> <span class="n">new_node2</span></div>


<span class="n">rq_edge_</span> <span class="o">=</span> <span class="n">copy_func</span><span class="p">(</span><span class="n">rq_</span><span class="p">)</span>
<span class="n">rq_edge_</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> \
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Contracts an edge in-place via :func:`~Edge.contract_` and splits</span>
<span class="sd">    it in-place via :func:`~AbstractNode.split_` using ``mode = &quot;qr&quot;``. See</span>
<span class="sd">    :func:`split` for a more complete explanation.</span>
<span class="sd">    </span>
<span class="sd">    Following the **PyTorch** convention, names of functions ended with an</span>
<span class="sd">    underscore indicate **in-place** operations.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation use the same names as the original</span>
<span class="sd">    nodes connected by ``self``.</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tuple[Node, Node]</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.randn(shape=(10, 15, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeA&#39;)</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.randn(shape=(15, 20, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeB&#39;)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; new_edge = nodeA[&#39;right&#39;] ^ nodeB[&#39;left&#39;]</span>
<span class="sd">    &gt;&gt;&gt; nodeA, nodeB = tk.rq_(new_edge)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; nodeA.shape</span>
<span class="sd">    torch.Size([10, 10, 100])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; nodeB.shape</span>
<span class="sd">    torch.Size([10, 20, 100])</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; print(nodeA.axes_names)</span>
<span class="sd">    [&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;]</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; print(nodeB.axes_names)</span>
<span class="sd">    [&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;]</span>
<span class="sd">    &quot;&quot;&quot;</span>

<span class="n">Edge</span><span class="o">.</span><span class="n">rq_</span> <span class="o">=</span> <span class="n">rq_edge_</span>


<span class="c1">################################   CONTRACT    ################################</span>
<span class="k">def</span> <span class="nf">_check_first_contract_edges</span><span class="p">(</span><span class="n">edges</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Edge</span><span class="p">],</span>
                                <span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
                                <span class="n">node2</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Successor</span><span class="p">]:</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;edges&#39;</span><span class="p">:</span> <span class="n">edges</span><span class="p">,</span>
              <span class="s1">&#39;node1&#39;</span><span class="p">:</span> <span class="n">node1</span><span class="p">,</span>
              <span class="s1">&#39;node2&#39;</span><span class="p">:</span> <span class="n">node2</span><span class="p">}</span>
    <span class="k">if</span> <span class="s1">&#39;contract_edges&#39;</span> <span class="ow">in</span> <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">succ</span> <span class="ow">in</span> <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;contract_edges&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">succ</span><span class="o">.</span><span class="n">kwargs</span> <span class="o">==</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">succ</span>
    <span class="k">return</span> <span class="kc">None</span>


<span class="k">def</span> <span class="nf">_contract_edges_first</span><span class="p">(</span><span class="n">edges</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Edge</span><span class="p">],</span>
                          <span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
                          <span class="n">node2</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
    <span class="n">shared_edges</span> <span class="o">=</span> <span class="n">get_shared_edges</span><span class="p">(</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">shared_edges</span> <span class="o">==</span> <span class="p">[]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;No batch edges or shared edges between nodes &#39;</span>
                         <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">node1</span><span class="si">!s}</span><span class="s1"> and </span><span class="si">{</span><span class="n">node2</span><span class="si">!s}</span><span class="s1"> found&#39;</span><span class="p">)</span>

    <span class="n">edges_None</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="n">edges</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">edges</span> <span class="o">=</span> <span class="n">shared_edges</span>
        <span class="n">edges_None</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">edges</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">edge</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">shared_edges</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Edges selected to be contracted must be &#39;</span>
                                 <span class="s1">&#39;shared edges between `node1` and `node2`&#39;</span><span class="p">)</span>

    <span class="c1"># Trace</span>
    <span class="k">if</span> <span class="n">node1</span> <span class="o">==</span> <span class="n">node2</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">node1</span><span class="o">.</span><span class="n">tensor</span>
        <span class="n">axes_nums</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">node1</span><span class="o">.</span><span class="n">rank</span><span class="p">),</span> <span class="nb">range</span><span class="p">(</span><span class="n">node1</span><span class="o">.</span><span class="n">rank</span><span class="p">)))</span>

        <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">edges</span><span class="p">:</span>
            <span class="n">axes</span> <span class="o">=</span> <span class="n">node1</span><span class="o">.</span><span class="n">in_which_axis</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">result</span><span class="p">,</span>
                                    <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                    <span class="n">dim1</span><span class="o">=</span><span class="n">axes_nums</span><span class="p">[</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_num</span><span class="p">],</span>
                                    <span class="n">dim2</span><span class="o">=</span><span class="n">axes_nums</span><span class="p">[</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">_num</span><span class="p">])</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">min_axis</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_num</span><span class="p">,</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">_num</span><span class="p">)</span>
            <span class="n">max_axis</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_num</span><span class="p">,</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">_num</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="n">axes_nums</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">num</span> <span class="o">&lt;</span> <span class="n">min_axis</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="k">elif</span> <span class="n">num</span> <span class="o">==</span> <span class="n">min_axis</span><span class="p">:</span>
                    <span class="n">axes_nums</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
                <span class="k">elif</span> <span class="p">(</span><span class="n">num</span> <span class="o">&gt;</span> <span class="n">min_axis</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">num</span> <span class="o">&lt;</span> <span class="n">max_axis</span><span class="p">):</span>
                    <span class="n">axes_nums</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">1</span>
                <span class="k">elif</span> <span class="n">num</span> <span class="o">==</span> <span class="n">max_axis</span><span class="p">:</span>
                    <span class="n">axes_nums</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
                <span class="k">elif</span> <span class="n">num</span> <span class="o">&gt;</span> <span class="n">max_axis</span><span class="p">:</span>
                    <span class="n">axes_nums</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">2</span>

        <span class="n">new_axes_names</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">new_edges</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">new_node1_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="n">axes_nums</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">axes_nums</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">new_axes_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node1</span><span class="o">.</span><span class="n">_axes</span><span class="p">[</span><span class="n">num</span><span class="p">]</span><span class="o">.</span><span class="n">_name</span><span class="p">)</span>
                <span class="n">new_edges</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node1</span><span class="o">.</span><span class="n">_edges</span><span class="p">[</span><span class="n">num</span><span class="p">])</span>
                <span class="n">new_node1_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node1</span><span class="o">.</span><span class="n">is_node1</span><span class="p">(</span><span class="n">num</span><span class="p">))</span>

        <span class="n">hints</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;edges&#39;</span><span class="p">:</span> <span class="n">edges</span><span class="p">}</span>

        <span class="c1"># Record in inverse_memory while tracing</span>
        <span class="n">node1</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">]</span>
        <span class="n">tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">node1</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">node2</span><span class="o">.</span><span class="n">tensor</span><span class="p">]</span>
        <span class="n">non_contract_edges</span> <span class="o">=</span> <span class="p">[</span><span class="nb">dict</span><span class="p">(),</span> <span class="nb">dict</span><span class="p">()]</span>
        <span class="n">batch_edges</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">contract_edges</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]:</span>
            <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">axis</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">_axes</span><span class="p">):</span>
                <span class="n">edge</span> <span class="o">=</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">_edges</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">edges</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">contract_edges</span><span class="p">[</span><span class="n">edge</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">j</span><span class="p">]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">contract_edges</span><span class="p">[</span><span class="n">edge</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>

                <span class="k">elif</span> <span class="n">axis</span><span class="o">.</span><span class="n">is_batch</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">batch_in_node2</span> <span class="o">=</span> <span class="kc">False</span>
                        <span class="k">for</span> <span class="n">aux_axis</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">_axes</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">aux_axis</span><span class="o">.</span><span class="n">is_batch</span><span class="p">()</span> <span class="ow">and</span> \
                                    <span class="p">(</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span> <span class="o">==</span> <span class="n">aux_axis</span><span class="o">.</span><span class="n">_name</span><span class="p">):</span>
                                <span class="n">batch_edges</span><span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">j</span><span class="p">]</span>
                                <span class="n">batch_in_node2</span> <span class="o">=</span> <span class="kc">True</span>
                                <span class="k">break</span>
                        <span class="k">if</span> <span class="ow">not</span> <span class="n">batch_in_node2</span><span class="p">:</span>
                            <span class="n">non_contract_edges</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">j</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">axis</span><span class="o">.</span><span class="n">_name</span> <span class="ow">in</span> <span class="n">batch_edges</span><span class="p">:</span>
                            <span class="n">batch_edges</span><span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">non_contract_edges</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">j</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">non_contract_edges</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">j</span>

        <span class="n">permutation_dims</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>

        <span class="n">batch_edges_perm_0</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">l</span><span class="p">:</span> <span class="n">l</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">batch_edges</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
        <span class="n">batch_edges_perm_1</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">l</span><span class="p">:</span> <span class="n">l</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">batch_edges</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>

        <span class="n">non_contract_edges_perm_0</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">non_contract_edges</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="n">non_contract_edges_perm_1</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">non_contract_edges</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

        <span class="n">contract_edges_perm_0</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
            <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">l</span><span class="p">:</span> <span class="n">l</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">contract_edges</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
        <span class="n">contract_edges_perm_1</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
            <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">l</span><span class="p">:</span> <span class="n">l</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">contract_edges</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>

        <span class="n">permutation_dims</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch_edges_perm_0</span> <span class="o">+</span> \
            <span class="n">non_contract_edges_perm_0</span> <span class="o">+</span> <span class="n">contract_edges_perm_0</span>
        <span class="n">permutation_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch_edges_perm_1</span> <span class="o">+</span> \
            <span class="n">contract_edges_perm_1</span> <span class="o">+</span> <span class="n">non_contract_edges_perm_1</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">permutation_dims</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">permutation_dims</span><span class="p">[</span><span class="n">i</span><span class="p">]))):</span>
                <span class="n">permutation_dims</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">shape_limits</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch_edges</span><span class="p">),</span>
                        <span class="nb">len</span><span class="p">(</span><span class="n">non_contract_edges</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                        <span class="nb">len</span><span class="p">(</span><span class="n">contract_edges</span><span class="p">))</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">_C</span><span class="o">.</span><span class="n">contract</span><span class="p">(</span><span class="n">tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tensors</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                             <span class="n">permutation_dims</span><span class="p">,</span>
                             <span class="n">shape_limits</span><span class="p">)</span>

        <span class="c1"># Put batch dims at the beggining</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">l</span><span class="p">:</span> <span class="n">l</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">batch_edges</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span> <span class="o">+</span> \
            <span class="nb">list</span><span class="p">(</span><span class="n">non_contract_edges</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="n">indices</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">non_contract_edges</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

        <span class="n">new_axes_names</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">new_edges</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">new_node1_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]:</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                <span class="n">new_axes_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axes_names</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
                <span class="n">new_edges</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">idx</span><span class="p">])</span>
                <span class="n">new_node1_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">is_node1</span><span class="p">())</span>

        <span class="n">hints</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;permutation_dims&#39;</span><span class="p">:</span> <span class="n">permutation_dims</span><span class="p">,</span>
                 <span class="s1">&#39;shape_limits&#39;</span><span class="p">:</span> <span class="n">shape_limits</span><span class="p">,</span>
                 <span class="s1">&#39;edges&#39;</span><span class="p">:</span> <span class="n">edges</span><span class="p">}</span>

        <span class="c1"># Record in inverse_memory while tracing</span>
        <span class="n">node1</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>
        <span class="n">node2</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>

    <span class="n">node1_is_stack</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node1</span><span class="p">,</span> <span class="p">(</span><span class="n">StackNode</span><span class="p">,</span> <span class="n">ParamStackNode</span><span class="p">))</span>
    <span class="n">node2_is_stack</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node2</span><span class="p">,</span> <span class="p">(</span><span class="n">StackNode</span><span class="p">,</span> <span class="n">ParamStackNode</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">node1_is_stack</span> <span class="ow">and</span> <span class="n">node2_is_stack</span><span class="p">:</span>
        <span class="n">new_node</span> <span class="o">=</span> <span class="n">StackNode</span><span class="o">.</span><span class="n">_create_resultant</span><span class="p">(</span><span class="n">axes_names</span><span class="o">=</span><span class="n">new_axes_names</span><span class="p">,</span>
                                               <span class="n">name</span><span class="o">=</span><span class="s1">&#39;contract_edges&#39;</span><span class="p">,</span>
                                               <span class="n">network</span><span class="o">=</span><span class="n">node1</span><span class="o">.</span><span class="n">_network</span><span class="p">,</span>
                                               <span class="n">tensor</span><span class="o">=</span><span class="n">result</span><span class="p">,</span>
                                               <span class="n">edges</span><span class="o">=</span><span class="n">new_edges</span><span class="p">,</span>
                                               <span class="n">node1_list</span><span class="o">=</span><span class="n">new_node1_list</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">node1_is_stack</span> <span class="ow">or</span> <span class="n">node2_is_stack</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Can only contract (Param)StackNode with other &#39;</span>
                        <span class="s1">&#39;(Param)StackNode&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">new_node</span> <span class="o">=</span> <span class="n">Node</span><span class="o">.</span><span class="n">_create_resultant</span><span class="p">(</span><span class="n">axes_names</span><span class="o">=</span><span class="n">new_axes_names</span><span class="p">,</span>
                                          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;contract_edges&#39;</span><span class="p">,</span>
                                          <span class="n">network</span><span class="o">=</span><span class="n">node1</span><span class="o">.</span><span class="n">_network</span><span class="p">,</span>
                                          <span class="n">tensor</span><span class="o">=</span><span class="n">result</span><span class="p">,</span>
                                          <span class="n">edges</span><span class="o">=</span><span class="n">new_edges</span><span class="p">,</span>
                                          <span class="n">node1_list</span><span class="o">=</span><span class="n">new_node1_list</span><span class="p">)</span>

    <span class="c1"># Create successor</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">node1</span><span class="o">.</span><span class="n">_network</span>
    <span class="n">successor</span> <span class="o">=</span> <span class="n">Successor</span><span class="p">(</span><span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;edges&#39;</span><span class="p">:</span> <span class="n">edges</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">edges_None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                                  <span class="s1">&#39;node1&#39;</span><span class="p">:</span> <span class="n">node1</span><span class="p">,</span>
                                  <span class="s1">&#39;node2&#39;</span><span class="p">:</span> <span class="n">node2</span><span class="p">},</span>
                          <span class="n">child</span><span class="o">=</span><span class="n">new_node</span><span class="p">,</span>
                          <span class="n">hints</span><span class="o">=</span><span class="n">hints</span><span class="p">)</span>

    <span class="c1"># Add successor to parent</span>
    <span class="k">if</span> <span class="s1">&#39;contract_edges&#39;</span> <span class="ow">in</span> <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">:</span>
        <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;contract_edges&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">successor</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;contract_edges&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">successor</span><span class="p">]</span>

    <span class="c1"># Add operation to list of performed operations of TN</span>
    <span class="n">net</span><span class="o">.</span><span class="n">_seq_ops</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;contract_edges&#39;</span><span class="p">,</span> <span class="n">successor</span><span class="o">.</span><span class="n">kwargs</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">new_node</span>


<span class="k">def</span> <span class="nf">_contract_edges_next</span><span class="p">(</span><span class="n">successor</span><span class="p">:</span> <span class="n">Successor</span><span class="p">,</span>
                         <span class="n">edges</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Edge</span><span class="p">],</span>
                         <span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
                         <span class="n">node2</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
    <span class="n">hints</span> <span class="o">=</span> <span class="n">successor</span><span class="o">.</span><span class="n">hints</span>
    <span class="n">edges</span> <span class="o">=</span> <span class="n">hints</span><span class="p">[</span><span class="s1">&#39;edges&#39;</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">node1</span> <span class="o">==</span> <span class="n">node2</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">node1</span><span class="o">.</span><span class="n">tensor</span>
        <span class="n">axes_nums</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">node1</span><span class="o">.</span><span class="n">rank</span><span class="p">),</span> <span class="nb">range</span><span class="p">(</span><span class="n">node1</span><span class="o">.</span><span class="n">rank</span><span class="p">)))</span>

        <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">edges</span><span class="p">:</span>
            <span class="n">axes</span> <span class="o">=</span> <span class="n">node1</span><span class="o">.</span><span class="n">in_which_axis</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">result</span><span class="p">,</span>
                                    <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                    <span class="n">dim1</span><span class="o">=</span><span class="n">axes_nums</span><span class="p">[</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_num</span><span class="p">],</span>
                                    <span class="n">dim2</span><span class="o">=</span><span class="n">axes_nums</span><span class="p">[</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">_num</span><span class="p">])</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">min_axis</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_num</span><span class="p">,</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">_num</span><span class="p">)</span>
            <span class="n">max_axis</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_num</span><span class="p">,</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">_num</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="n">axes_nums</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">num</span> <span class="o">&lt;</span> <span class="n">min_axis</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="k">elif</span> <span class="n">num</span> <span class="o">==</span> <span class="n">min_axis</span><span class="p">:</span>
                    <span class="n">axes_nums</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
                <span class="k">elif</span> <span class="p">(</span><span class="n">num</span> <span class="o">&gt;</span> <span class="n">min_axis</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">num</span> <span class="o">&lt;</span> <span class="n">max_axis</span><span class="p">):</span>
                    <span class="n">axes_nums</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">1</span>
                <span class="k">elif</span> <span class="n">num</span> <span class="o">==</span> <span class="n">max_axis</span><span class="p">:</span>
                    <span class="n">axes_nums</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
                <span class="k">elif</span> <span class="n">num</span> <span class="o">&gt;</span> <span class="n">max_axis</span><span class="p">:</span>
                    <span class="n">axes_nums</span><span class="p">[</span><span class="n">num</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">2</span>

        <span class="c1"># Record in inverse_memory while contracting</span>
        <span class="c1"># (to delete memory if possible)</span>
        <span class="n">node1</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">nodes</span> <span class="o">=</span> <span class="p">[</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">]</span>
        <span class="n">tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">node1</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">node2</span><span class="o">.</span><span class="n">tensor</span><span class="p">]</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">_C</span><span class="o">.</span><span class="n">contract</span><span class="p">(</span><span class="n">tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tensors</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                             <span class="n">hints</span><span class="p">[</span><span class="s1">&#39;permutation_dims&#39;</span><span class="p">],</span>
                             <span class="n">hints</span><span class="p">[</span><span class="s1">&#39;shape_limits&#39;</span><span class="p">])</span>

        <span class="c1"># Record in inverse_memory while contracting</span>
        <span class="c1"># (to delete memory if possible)</span>
        <span class="n">node1</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>
        <span class="n">node2</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>

    <span class="n">child</span> <span class="o">=</span> <span class="n">successor</span><span class="o">.</span><span class="n">child</span>
    <span class="n">child</span><span class="o">.</span><span class="n">_direct_set_tensor</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">child</span>


<span class="n">contract_edges_op</span> <span class="o">=</span> <span class="n">Operation</span><span class="p">(</span><span class="s1">&#39;contract_edges&#39;</span><span class="p">,</span>
                              <span class="n">_check_first_contract_edges</span><span class="p">,</span>
                              <span class="n">_contract_edges_first</span><span class="p">,</span>
                              <span class="n">_contract_edges_next</span><span class="p">)</span>


<div class="viewcode-block" id="contract_edges"><a class="viewcode-back" href="../../operations.html#tensorkrowch.contract_edges">[docs]</a><span class="k">def</span> <span class="nf">contract_edges</span><span class="p">(</span><span class="n">edges</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Edge</span><span class="p">],</span>
                   <span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
                   <span class="n">node2</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Contracts all selected edges between two nodes.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation are called ``&quot;contract_edges&quot;``.</span>
<span class="sd">    The node that keeps information about the :class:`Successor` is ``node1``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    edges : list[Edge]</span>
<span class="sd">        List of edges that are to be contracted. They must be edges shared</span>
<span class="sd">        between ``node1`` and ``node2``. Batch contraction is automatically</span>
<span class="sd">        performed when both nodes have batch edges with the same names.</span>
<span class="sd">    node1 : AbstractNode</span>
<span class="sd">        First node of the contraction. Its non-contracted edges will appear</span>
<span class="sd">        first in the list of inherited edges of the resultant node.</span>
<span class="sd">    node2 : AbstractNode</span>
<span class="sd">        Second node of the contraction. Its non-contracted edges will appear</span>
<span class="sd">        last in the list of inherited edges of the resultant node.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Node</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.randn(shape=(10, 15, 20),</span>
<span class="sd">    ...                  axes_names=(&#39;one&#39;, &#39;two&#39;, &#39;three&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeA&#39;)</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.randn(shape=(10, 15, 20),</span>
<span class="sd">    ...                  axes_names=(&#39;one&#39;, &#39;two&#39;, &#39;three&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeB&#39;)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; _ = nodeA[&#39;one&#39;] ^ nodeB[&#39;one&#39;]</span>
<span class="sd">    &gt;&gt;&gt; _ = nodeA[&#39;two&#39;] ^ nodeB[&#39;two&#39;]</span>
<span class="sd">    &gt;&gt;&gt; _ = nodeA[&#39;three&#39;] ^ nodeB[&#39;three&#39;]</span>
<span class="sd">    &gt;&gt;&gt; result = tk.contract_edges([nodeA[&#39;one&#39;], nodeA[&#39;three&#39;]],</span>
<span class="sd">    ...                            nodeA, nodeB)</span>
<span class="sd">    &gt;&gt;&gt; result.shape</span>
<span class="sd">    torch.Size([15, 15])</span>
<span class="sd">    </span>
<span class="sd">    If ``node1`` and ``node2`` are the same node, the contraction is a trace.</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; result2 = tk.contract_edges([result[&#39;two_0&#39;]], result, result)</span>
<span class="sd">    &gt;&gt;&gt; result2.shape</span>
<span class="sd">    torch.Size([])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">contract_edges_op</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">)</span></div>


<div class="viewcode-block" id="contract_"><a class="viewcode-back" href="../../operations.html#tensorkrowch.contract_">[docs]</a><span class="k">def</span> <span class="nf">contract_</span><span class="p">(</span><span class="n">edge</span><span class="p">:</span> <span class="n">Edge</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Contracts in-place the nodes that are connected through the edge. See</span>
<span class="sd">    :func:`contract` for a more complete explanation.</span>

<span class="sd">    Following the **PyTorch** convention, names of functions ended with an</span>
<span class="sd">    underscore indicate **in-place** operations.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation are called ``&quot;contract_edges_ip&quot;``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    edge : Edge</span>
<span class="sd">        Edges that is to be contracted. Batch contraction is automatically</span>
<span class="sd">        performed when both nodes have batch edges with the same names.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Node</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.randn(shape=(10, 15, 20),</span>
<span class="sd">    ...                  axes_names=(&#39;one&#39;, &#39;two&#39;, &#39;three&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeA&#39;)</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.randn(shape=(10, 15, 20),</span>
<span class="sd">    ...                  axes_names=(&#39;one&#39;, &#39;two&#39;, &#39;three&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeB&#39;)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; _ = nodeA[&#39;one&#39;] ^ nodeB[&#39;one&#39;]</span>
<span class="sd">    &gt;&gt;&gt; _ = nodeA[&#39;two&#39;] ^ nodeB[&#39;two&#39;]</span>
<span class="sd">    &gt;&gt;&gt; _ = nodeA[&#39;three&#39;] ^ nodeB[&#39;three&#39;]</span>
<span class="sd">    &gt;&gt;&gt; result = tk.contract_(nodeA[&#39;one&#39;])</span>
<span class="sd">    &gt;&gt;&gt; result.shape</span>
<span class="sd">    torch.Size([15, 20, 15, 20])</span>
<span class="sd">    </span>
<span class="sd">    ``nodeA`` and ``nodeB`` have been removed from the network.</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; nodeA.network is None</span>
<span class="sd">    True</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; nodeB.network is None</span>
<span class="sd">    True</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; del nodeA</span>
<span class="sd">    &gt;&gt;&gt; del nodeB</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">contract_edges</span><span class="p">([</span><span class="n">edge</span><span class="p">],</span> <span class="n">edge</span><span class="o">.</span><span class="n">node1</span><span class="p">,</span> <span class="n">edge</span><span class="o">.</span><span class="n">node2</span><span class="p">)</span>
    <span class="n">result</span><span class="o">.</span><span class="n">reattach_edges</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">result</span><span class="o">.</span><span class="n">_unrestricted_set_tensor</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

    <span class="c1"># Delete nodes (and their edges) from the TN</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">network</span>
    <span class="n">net</span><span class="o">.</span><span class="n">delete_node</span><span class="p">(</span><span class="n">edge</span><span class="o">.</span><span class="n">node1</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">delete_node</span><span class="p">(</span><span class="n">edge</span><span class="o">.</span><span class="n">node2</span><span class="p">)</span>

    <span class="c1"># Add edges of result to the TN</span>
    <span class="k">for</span> <span class="n">res_edge</span> <span class="ow">in</span> <span class="n">result</span><span class="o">.</span><span class="n">_edges</span><span class="p">:</span>
        <span class="n">net</span><span class="o">.</span><span class="n">_add_edge</span><span class="p">(</span><span class="n">res_edge</span><span class="p">)</span>

    <span class="c1"># Transform resultant to leaf nodes</span>
    <span class="n">result</span><span class="o">.</span><span class="n">_leaf</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">del</span> <span class="n">net</span><span class="o">.</span><span class="n">_resultant_nodes</span><span class="p">[</span><span class="n">result</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span>
    <span class="n">net</span><span class="o">.</span><span class="n">_leaf_nodes</span><span class="p">[</span><span class="n">result</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span>

    <span class="n">edge</span><span class="o">.</span><span class="n">node1</span><span class="o">.</span><span class="n">_successors</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">edge</span><span class="o">.</span><span class="n">node2</span><span class="o">.</span><span class="n">_successors</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">net</span><span class="o">.</span><span class="n">_seq_ops</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Remove resultant name</span>
    <span class="n">result</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;contract_edges_ip&#39;</span>

    <span class="k">return</span> <span class="n">result</span></div>


<span class="n">Edge</span><span class="o">.</span><span class="n">contract_</span> <span class="o">=</span> <span class="n">contract_</span>


<span class="k">def</span> <span class="nf">get_shared_edges</span><span class="p">(</span><span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
                     <span class="n">node2</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Edge</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns list of edges shared between two nodes.&quot;&quot;&quot;</span>
    <span class="n">edges</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i1</span><span class="p">,</span> <span class="n">edge1</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">node1</span><span class="o">.</span><span class="n">_edges</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i2</span><span class="p">,</span> <span class="n">edge2</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">node2</span><span class="o">.</span><span class="n">_edges</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">edge1</span> <span class="o">==</span> <span class="n">edge2</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">edge1</span><span class="o">.</span><span class="n">is_dangling</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">node1</span><span class="o">.</span><span class="n">is_node1</span><span class="p">(</span><span class="n">i1</span><span class="p">)</span> <span class="o">!=</span> <span class="n">node2</span><span class="o">.</span><span class="n">is_node1</span><span class="p">(</span><span class="n">i2</span><span class="p">):</span>
                    <span class="n">edges</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">edge1</span><span class="p">)</span>

    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">edges</span><span class="p">)</span>


<div class="viewcode-block" id="contract_between"><a class="viewcode-back" href="../../operations.html#tensorkrowch.contract_between">[docs]</a><span class="k">def</span> <span class="nf">contract_between</span><span class="p">(</span><span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
                     <span class="n">node2</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Contracts all edges shared between two nodes. Batch contraction is</span>
<span class="sd">    automatically performed when both nodes have batch edges with the same</span>
<span class="sd">    names.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation are called ``&quot;contract_edges&quot;``.</span>
<span class="sd">    The node that keeps information about the :class:`Successor` is ``node1``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    node1 : AbstractNode</span>
<span class="sd">        First node of the contraction. Its non-contracted edges will appear</span>
<span class="sd">        first in the list of inherited edges of the resultant node.</span>
<span class="sd">    node2 : AbstractNode</span>
<span class="sd">        Second node of the contraction. Its non-contracted edges will appear</span>
<span class="sd">        last in the list of inherited edges of the resultant node.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Node</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.randn(shape=(10, 15, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeA&#39;)</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.randn(shape=(15, 7, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeB&#39;)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; _ = nodeA[&#39;right&#39;] ^ nodeB[&#39;left&#39;]</span>
<span class="sd">    &gt;&gt;&gt; result = tk.contract_between(nodeA, nodeB)</span>
<span class="sd">    &gt;&gt;&gt; result.shape</span>
<span class="sd">    torch.Size([100, 10, 7])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">contract_edges</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">)</span></div>


<span class="n">contract_between_node</span> <span class="o">=</span> <span class="n">copy_func</span><span class="p">(</span><span class="n">contract_between</span><span class="p">)</span>
<span class="n">contract_between_node</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> \
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Contracts all edges shared between two nodes. Batch contraction is</span>
<span class="sd">    automatically performed when both nodes have batch edges with the same</span>
<span class="sd">    names. It can also be performed using the operator ``@``.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation are called ``&quot;contract_edges&quot;``.</span>
<span class="sd">    The node that keeps information about the :class:`Successor` is ``self``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    node2 : AbstractNode</span>
<span class="sd">        Second node of the contraction. Its non-contracted edges will appear</span>
<span class="sd">        last in the list of inherited edges of the resultant node.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Node</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.randn(shape=(10, 15, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeA&#39;)</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.randn(shape=(15, 7, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeB&#39;)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; _ = nodeA[&#39;right&#39;] ^ nodeB[&#39;left&#39;]</span>
<span class="sd">    &gt;&gt;&gt; result = nodeA @ nodeB</span>
<span class="sd">    &gt;&gt;&gt; result.shape</span>
<span class="sd">    torch.Size([100, 10, 7])</span>
<span class="sd">    &quot;&quot;&quot;</span>

<span class="n">AbstractNode</span><span class="o">.</span><span class="fm">__matmul__</span> <span class="o">=</span> <span class="n">contract_between_node</span>
<span class="n">AbstractNode</span><span class="o">.</span><span class="n">contract_between</span> <span class="o">=</span> <span class="n">contract_between_node</span>


<div class="viewcode-block" id="contract_between_"><a class="viewcode-back" href="../../operations.html#tensorkrowch.contract_between_">[docs]</a><span class="k">def</span> <span class="nf">contract_between_</span><span class="p">(</span><span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
                      <span class="n">node2</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    In-place version of :func:`contract_between`.</span>

<span class="sd">    Following the **PyTorch** convention, names of functions ended with an</span>
<span class="sd">    underscore indicate **in-place** operations.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation are called ``&quot;contract_edges_ip&quot;``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    node1 : AbstractNode</span>
<span class="sd">        First node of the contraction. Its non-contracted edges will appear</span>
<span class="sd">        first in the list of inherited edges of the resultant node.</span>
<span class="sd">    node2 : AbstractNode</span>
<span class="sd">        Second node of the contraction. Its non-contracted edges will appear</span>
<span class="sd">        last in the list of inherited edges of the resultant node.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Node</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.randn(shape=(10, 15, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeA&#39;)</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.randn(shape=(15, 7, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeB&#39;)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; _ = nodeA[&#39;right&#39;] ^ nodeB[&#39;left&#39;]</span>
<span class="sd">    &gt;&gt;&gt; result = tk.contract_between_(nodeA, nodeB)</span>
<span class="sd">    &gt;&gt;&gt; result.shape</span>
<span class="sd">    torch.Size([100, 10, 7])</span>
<span class="sd">    </span>
<span class="sd">    ``nodeA`` and ``nodeB`` have been removed from the network.</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; nodeA.network is None</span>
<span class="sd">    True</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; nodeB.network is None</span>
<span class="sd">    True</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; del nodeA</span>
<span class="sd">    &gt;&gt;&gt; del nodeB</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">contract_between</span><span class="p">(</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">)</span>
    <span class="n">result</span><span class="o">.</span><span class="n">reattach_edges</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">result</span><span class="o">.</span><span class="n">_unrestricted_set_tensor</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

    <span class="c1"># Delete nodes (and their edges) from the TN</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">network</span>
    <span class="n">net</span><span class="o">.</span><span class="n">delete_node</span><span class="p">(</span><span class="n">node1</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">delete_node</span><span class="p">(</span><span class="n">node2</span><span class="p">)</span>

    <span class="c1"># Add edges of result to the TN</span>
    <span class="k">for</span> <span class="n">res_edge</span> <span class="ow">in</span> <span class="n">result</span><span class="o">.</span><span class="n">_edges</span><span class="p">:</span>
        <span class="n">net</span><span class="o">.</span><span class="n">_add_edge</span><span class="p">(</span><span class="n">res_edge</span><span class="p">)</span>

    <span class="c1"># Transform resultant to leaf nodes</span>
    <span class="n">result</span><span class="o">.</span><span class="n">_leaf</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">del</span> <span class="n">net</span><span class="o">.</span><span class="n">_resultant_nodes</span><span class="p">[</span><span class="n">result</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span>
    <span class="n">net</span><span class="o">.</span><span class="n">_leaf_nodes</span><span class="p">[</span><span class="n">result</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span>

    <span class="n">node1</span><span class="o">.</span><span class="n">_successors</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">node2</span><span class="o">.</span><span class="n">_successors</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">net</span><span class="o">.</span><span class="n">_seq_ops</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Remove resultant name</span>
    <span class="n">result</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;contract_edges_ip&#39;</span>

    <span class="k">return</span> <span class="n">result</span></div>


<span class="n">contract_between_node_</span> <span class="o">=</span> <span class="n">copy_func</span><span class="p">(</span><span class="n">contract_between_</span><span class="p">)</span>
<span class="n">contract_between_node_</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> \
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    In-place version of :func:`~AbstractNode.contract_between`.</span>
<span class="sd">    </span>
<span class="sd">    Following the **PyTorch** convention, names of functions ended with an</span>
<span class="sd">    underscore indicate **in-place** operations.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation are called ``&quot;contract_edges_ip&quot;``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    node2 : AbstractNode</span>
<span class="sd">        Second node of the contraction. Its non-contracted edges will appear</span>
<span class="sd">        last in the list of inherited edges of the resultant node.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Node</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.randn(shape=(10, 15, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeA&#39;)</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.randn(shape=(15, 7, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeB&#39;)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; _ = nodeA[&#39;right&#39;] ^ nodeB[&#39;left&#39;]</span>
<span class="sd">    &gt;&gt;&gt; result = nodeA.contract_between_(nodeB)</span>
<span class="sd">    &gt;&gt;&gt; result.shape</span>
<span class="sd">    torch.Size([100, 10, 7])</span>
<span class="sd">    </span>
<span class="sd">    ``nodeA`` and ``nodeB`` have been removed from the network.</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; nodeA.network is None</span>
<span class="sd">    True</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; nodeB.network is None</span>
<span class="sd">    True</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; del nodeA</span>
<span class="sd">    &gt;&gt;&gt; del nodeB</span>
<span class="sd">    &quot;&quot;&quot;</span>

<span class="n">AbstractNode</span><span class="o">.</span><span class="n">contract_between_</span> <span class="o">=</span> <span class="n">contract_between_node_</span>


<span class="c1">#####################################   STACK   ###############################</span>
<span class="k">def</span> <span class="nf">_check_first_stack</span><span class="p">(</span><span class="n">nodes</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">AbstractNode</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Successor</span><span class="p">]:</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;nodes&#39;</span><span class="p">:</span> <span class="n">nodes</span><span class="p">}</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">nodes</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`nodes` should be a non-empty sequence of nodes&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="s1">&#39;stack&#39;</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_successors</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">succ</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;stack&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">succ</span><span class="o">.</span><span class="n">kwargs</span> <span class="o">==</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">succ</span>
    <span class="k">return</span> <span class="kc">None</span>


<span class="k">def</span> <span class="nf">_stack_first</span><span class="p">(</span><span class="n">nodes</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">AbstractNode</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">StackNode</span><span class="p">:</span>
    <span class="n">all_leaf</span> <span class="o">=</span> <span class="kc">True</span>          <span class="c1"># Check if all the nodes are leaf</span>
    <span class="n">all_non_param</span> <span class="o">=</span> <span class="kc">True</span>     <span class="c1"># Check if all the nodes are non-parametric</span>
    <span class="n">all_param</span> <span class="o">=</span> <span class="kc">True</span>         <span class="c1"># Check if all the nodes are parametric</span>
    <span class="n">all_same_ref</span> <span class="o">=</span> <span class="kc">True</span>      <span class="c1"># Check if all the nodes&#39; memories are stored in the</span>
    <span class="c1"># same reference node&#39;s memory</span>
    <span class="n">node_ref_is_stack</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># Chech if the shared reference node is a stack</span>
    <span class="n">stack_node_ref</span> <span class="o">=</span> <span class="kc">None</span>    <span class="c1"># In the case above, the reference node</span>
    <span class="n">stack_indices</span> <span class="o">=</span> <span class="p">[]</span>       <span class="c1"># In the case above, stack indices of each node in</span>
    <span class="c1"># the reference node&#39;s memory</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span> <span class="ow">and</span> \
        <span class="nb">isinstance</span><span class="p">(</span><span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">AbstractNode</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`nodes` should be a list or tuple of AbstractNodes&#39;</span><span class="p">)</span>

    <span class="n">net</span> <span class="o">=</span> <span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_network</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">node</span><span class="o">.</span><span class="n">_leaf</span><span class="p">:</span>
            <span class="n">all_leaf</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">ParamNode</span><span class="p">):</span>
            <span class="n">all_non_param</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">all_param</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">all_same_ref</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">node_ref</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;node_ref&#39;</span><span class="p">]</span>

                <span class="k">if</span> <span class="n">stack_node_ref</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">stack_node_ref</span> <span class="o">=</span> <span class="n">node_ref</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">node_ref</span> <span class="o">!=</span> <span class="n">stack_node_ref</span><span class="p">:</span>
                        <span class="n">all_same_ref</span> <span class="o">=</span> <span class="kc">False</span>
                        <span class="k">continue</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node_ref</span><span class="p">,</span> <span class="p">(</span><span class="n">StackNode</span><span class="p">,</span> <span class="n">ParamStackNode</span><span class="p">)):</span>
                    <span class="n">all_same_ref</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="n">node_ref_is_stack</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="k">continue</span>

                <span class="n">stack_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;index&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">all_same_ref</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">if</span> <span class="n">all_param</span> <span class="ow">and</span> <span class="n">node_ref_is_stack</span> <span class="ow">and</span> <span class="n">net</span><span class="o">.</span><span class="n">_auto_stack</span><span class="p">:</span>
        <span class="n">stack_node</span> <span class="o">=</span> <span class="n">ParamStackNode</span><span class="p">(</span><span class="n">nodes</span><span class="o">=</span><span class="n">nodes</span><span class="p">,</span>
                                    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;virtual_stack&#39;</span><span class="p">,</span>
                                    <span class="n">virtual</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">stack_node</span> <span class="o">=</span> <span class="n">StackNode</span><span class="o">.</span><span class="n">_create_resultant</span><span class="p">(</span><span class="n">nodes</span><span class="o">=</span><span class="n">nodes</span><span class="p">,</span>
                                                 <span class="n">name</span><span class="o">=</span><span class="s1">&#39;stack&#39;</span><span class="p">)</span>

    <span class="c1"># Both conditions can only be satisfied in index_mode</span>
    <span class="k">if</span> <span class="n">all_same_ref</span><span class="p">:</span>
        <span class="c1"># Memory of stack is just a reference to the stack_node_ref</span>
        <span class="n">stack_indices</span> <span class="o">=</span> <span class="n">list2slice</span><span class="p">(</span><span class="n">stack_indices</span><span class="p">)</span>

        <span class="k">del</span> <span class="n">net</span><span class="o">.</span><span class="n">_memory_nodes</span><span class="p">[</span><span class="n">stack_node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]]</span>
        <span class="n">stack_node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">stack_node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;node_ref&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">stack_node_ref</span>
        <span class="n">stack_node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;full&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="n">stack_indices</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">stack_node_ref</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">!=</span> <span class="n">stack_node</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">max_dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">stack_node_ref</span><span class="o">.</span><span class="n">_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span>
                                                   <span class="n">stack_node</span><span class="o">.</span><span class="n">_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])):</span>
                <span class="k">if</span> <span class="n">stack_node</span><span class="o">.</span><span class="n">_axes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">is_batch</span><span class="p">():</span>
                    <span class="c1"># Admit any size in batch edges</span>
                    <span class="n">index</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">index</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="n">max_dim</span> <span class="o">-</span> <span class="n">dim</span><span class="p">,</span> <span class="n">max_dim</span><span class="p">))</span>
        <span class="n">stack_node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;index&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">index</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">all_leaf</span> <span class="ow">and</span> <span class="p">(</span><span class="n">all_param</span> <span class="ow">or</span> <span class="n">all_non_param</span><span class="p">)</span> \
                <span class="ow">and</span> <span class="n">node_ref_is_stack</span> <span class="ow">and</span> <span class="n">net</span><span class="o">.</span><span class="n">_auto_stack</span><span class="p">:</span>
            <span class="c1"># Stacked nodes&#39; memories are replaced by a reference to a slice</span>
            <span class="c1"># of the resultant stack_node</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">nodes</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">del</span> <span class="n">net</span><span class="o">.</span><span class="n">_memory_nodes</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]]</span>
                <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;node_ref&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">stack_node</span>
                <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;full&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="p">(</span><span class="n">max_dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">stack_node</span><span class="o">.</span><span class="n">_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span>
                                                       <span class="n">node</span><span class="o">.</span><span class="n">_shape</span><span class="p">)):</span>
                    <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">_axes</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">is_batch</span><span class="p">():</span>
                        <span class="c1"># Admit any size in batch edges</span>
                        <span class="n">index</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">index</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="n">max_dim</span> <span class="o">-</span> <span class="n">dim</span><span class="p">,</span> <span class="n">max_dim</span><span class="p">))</span>
                <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;index&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">index</span>

                <span class="k">if</span> <span class="n">all_param</span><span class="p">:</span>
                    <span class="nb">delattr</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="s1">&#39;param_&#39;</span> <span class="o">+</span> <span class="n">node</span><span class="o">.</span><span class="n">_name</span><span class="p">)</span>

        <span class="c1"># Record in inverse_memory while tracing</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">:</span>
            <span class="n">node</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>

    <span class="c1"># Create successor</span>
    <span class="n">successor</span> <span class="o">=</span> <span class="n">Successor</span><span class="p">(</span><span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;nodes&#39;</span><span class="p">:</span> <span class="n">nodes</span><span class="p">},</span>
                          <span class="n">child</span><span class="o">=</span><span class="n">stack_node</span><span class="p">,</span>
                          <span class="n">hints</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;all_same_ref&#39;</span><span class="p">:</span> <span class="n">all_same_ref</span><span class="p">,</span>
                                 <span class="s1">&#39;all_leaf&#39;</span><span class="p">:</span> <span class="n">all_leaf</span> <span class="ow">and</span>
                                 <span class="p">(</span><span class="n">all_param</span> <span class="ow">or</span> <span class="n">all_non_param</span><span class="p">)</span> <span class="ow">and</span>
                                 <span class="n">node_ref_is_stack</span><span class="p">,</span>
                                 <span class="s1">&#39;auto_stack&#39;</span><span class="p">:</span> <span class="n">net</span><span class="o">.</span><span class="n">_auto_stack</span><span class="p">})</span>

    <span class="c1"># Add successor to parent</span>
    <span class="k">if</span> <span class="s1">&#39;stack&#39;</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_successors</span><span class="p">:</span>
        <span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;stack&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">successor</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;stack&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">successor</span><span class="p">]</span>

    <span class="c1"># Add operation to list of performed operations of TN</span>
    <span class="n">net</span><span class="o">.</span><span class="n">_seq_ops</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;stack&#39;</span><span class="p">,</span> <span class="n">successor</span><span class="o">.</span><span class="n">kwargs</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">stack_node</span>


<span class="k">def</span> <span class="nf">_stack_next</span><span class="p">(</span><span class="n">successor</span><span class="p">:</span> <span class="n">Successor</span><span class="p">,</span>
                <span class="n">nodes</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">AbstractNode</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">StackNode</span><span class="p">:</span>
    <span class="n">child</span> <span class="o">=</span> <span class="n">successor</span><span class="o">.</span><span class="n">child</span>
    <span class="k">if</span> <span class="n">successor</span><span class="o">.</span><span class="n">hints</span><span class="p">[</span><span class="s1">&#39;all_same_ref&#39;</span><span class="p">]</span> <span class="ow">or</span> \
            <span class="p">(</span><span class="n">successor</span><span class="o">.</span><span class="n">hints</span><span class="p">[</span><span class="s1">&#39;all_leaf&#39;</span><span class="p">]</span> <span class="ow">and</span> <span class="n">successor</span><span class="o">.</span><span class="n">hints</span><span class="p">[</span><span class="s1">&#39;auto_stack&#39;</span><span class="p">]):</span>
        <span class="k">return</span> <span class="n">child</span>

    <span class="n">stack_tensor</span> <span class="o">=</span> <span class="n">stack_unequal_tensors</span><span class="p">([</span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">])</span>
    <span class="n">child</span><span class="o">.</span><span class="n">_direct_set_tensor</span><span class="p">(</span><span class="n">stack_tensor</span><span class="p">)</span>

    <span class="c1"># Record in inverse_memory while contracting</span>
    <span class="c1"># (to delete memory if possible)</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">:</span>
        <span class="n">node</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">child</span>


<span class="n">stack_op</span> <span class="o">=</span> <span class="n">Operation</span><span class="p">(</span><span class="s1">&#39;stack&#39;</span><span class="p">,</span> <span class="n">_check_first_stack</span><span class="p">,</span> <span class="n">_stack_first</span><span class="p">,</span> <span class="n">_stack_next</span><span class="p">)</span>


<div class="viewcode-block" id="stack"><a class="viewcode-back" href="../../operations.html#tensorkrowch.stack">[docs]</a><span class="k">def</span> <span class="nf">stack</span><span class="p">(</span><span class="n">nodes</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">AbstractNode</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates a :class:`StackNode` or :class:`ParamStackNode` by stacking a</span>
<span class="sd">    collection of :class:`Nodes &lt;Nodes&gt;` or :class:`ParamNodes &lt;ParamNode&gt;`,</span>
<span class="sd">    respectively. Restrictions that are applied to the nodes in order to be</span>
<span class="sd">    `stackable` are the same as in :class:`StackNode`.</span>

<span class="sd">    The stack dimension will be the first one in the ``resultant`` node.</span>
<span class="sd">    </span>
<span class="sd">    See :class:`ParamStackNode` and :class:`TensorNetwork` to learn how the</span>
<span class="sd">    :meth:`~TensorNetwork.auto_unbind` mode affects the computation of</span>
<span class="sd">    :func:`stack`.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation are called ``&quot;stack&quot;``. If this</span>
<span class="sd">    operation returns a ``virtual`` :class:`ParamStackNode`, it will be called</span>
<span class="sd">    ``&quot;virtual_stack&quot;``. See :class:AbstractNode` to learn about this **reserved</span>
<span class="sd">    name**.  The node that keeps information about the :class:`Successor` is</span>
<span class="sd">    ``nodes[0]``, the first stacked node.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    nodes : list[AbstractNode] or tuple[AbstractNode]</span>
<span class="sd">        Sequence of nodes that are to be stacked. They must be of the same type,</span>
<span class="sd">        have the same rank and axes names, be in the same tensor network, and</span>
<span class="sd">        have edges with the same types.</span>
<span class="sd">        </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; net = tk.TensorNetwork()</span>
<span class="sd">    &gt;&gt;&gt; nodes = [tk.randn(shape=(2, 4, 2),</span>
<span class="sd">    ...                   axes_names=(&#39;left&#39;, &#39;input&#39;, &#39;right&#39;),</span>
<span class="sd">    ...                   network=net)</span>
<span class="sd">    ...          for _ in range(10)]</span>
<span class="sd">    &gt;&gt;&gt; stack_node = tk.stack(nodes)</span>
<span class="sd">    &gt;&gt;&gt; stack_node.shape</span>
<span class="sd">    torch.Size([10, 2, 4, 2])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">stack_op</span><span class="p">(</span><span class="n">nodes</span><span class="p">)</span></div>


<span class="c1">##################################   UNBIND   #################################</span>
<span class="k">def</span> <span class="nf">_check_first_unbind</span><span class="p">(</span><span class="n">node</span><span class="p">:</span> <span class="n">AbstractStackNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Successor</span><span class="p">]:</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;node&#39;</span><span class="p">:</span> <span class="n">node</span><span class="p">}</span>
    <span class="k">if</span> <span class="s1">&#39;unbind&#39;</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">_successors</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">succ</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;unbind&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">succ</span><span class="o">.</span><span class="n">kwargs</span> <span class="o">==</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">succ</span>
    <span class="k">return</span> <span class="kc">None</span>


<span class="k">def</span> <span class="nf">_unbind_first</span><span class="p">(</span><span class="n">node</span><span class="p">:</span> <span class="n">AbstractStackNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Node</span><span class="p">]:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="p">(</span><span class="n">StackNode</span><span class="p">,</span> <span class="n">ParamStackNode</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Cannot unbind node if it is not a (Param)StackNode&#39;</span><span class="p">)</span>

    <span class="n">tensors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span><span class="p">)</span>
    <span class="n">new_nodes</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Invert structure of node.edges_lists</span>
    <span class="n">edges_lists</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">node1_lists</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">batch_ids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">edge</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">_edges</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge</span><span class="p">,</span> <span class="n">StackEdge</span><span class="p">):</span>
            <span class="n">edges_lists</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">edge</span><span class="o">.</span><span class="n">_edges</span><span class="p">)</span>
            <span class="n">node1_lists</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">edge</span><span class="o">.</span><span class="n">_node1_list</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">edge</span><span class="o">.</span><span class="n">is_batch</span><span class="p">()</span> <span class="ow">and</span> <span class="p">(</span><span class="s1">&#39;batch&#39;</span> <span class="ow">in</span> <span class="n">edge</span><span class="o">.</span><span class="n">axis1</span><span class="o">.</span><span class="n">_name</span><span class="p">):</span>
                <span class="c1"># Save position of batch edge, whose dimension might change</span>
                <span class="n">batch_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">edges_lists</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">edge</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensors</span><span class="p">))</span>
            <span class="n">node1_lists</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="kc">True</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensors</span><span class="p">))</span>
    <span class="n">lst</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">edges_lists</span><span class="p">)),</span>
                   <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">node1_lists</span><span class="p">))))</span>

    <span class="n">net</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">_network</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="n">node1_list</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lst</span><span class="p">):</span>
        <span class="n">new_node</span> <span class="o">=</span> <span class="n">Node</span><span class="o">.</span><span class="n">_create_resultant</span><span class="p">(</span><span class="n">axes_names</span><span class="o">=</span><span class="n">node</span><span class="o">.</span><span class="n">axes_names</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span>
                                          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;unbind&#39;</span><span class="p">,</span>
                                          <span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">,</span>
                                          <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span>
                                          <span class="n">edges</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">edges</span><span class="p">),</span>
                                          <span class="n">node1_list</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">node1_list</span><span class="p">))</span>
        <span class="n">new_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_node</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">net</span><span class="o">.</span><span class="n">_auto_unbind</span><span class="p">:</span>
        <span class="c1"># Record in inverse_memory while tracing</span>
        <span class="n">node</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>

    <span class="k">else</span><span class="p">:</span>  <span class="c1"># index_mode</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">node_ref</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;node_ref&#39;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">node_ref</span> <span class="o">=</span> <span class="n">node</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">new_node</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">new_nodes</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">new_node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">del</span> <span class="n">new_node</span><span class="o">.</span><span class="n">_network</span><span class="o">.</span><span class="n">_memory_nodes</span><span class="p">[</span>
                    <span class="n">new_node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]]</span>
            <span class="n">new_node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">new_node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;node_ref&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">node_ref</span>
            <span class="n">new_node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;full&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="k">if</span> <span class="n">node_ref</span> <span class="o">==</span> <span class="n">node</span><span class="p">:</span>
                <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="p">(</span><span class="n">max_dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span>
                                                       <span class="n">new_node</span><span class="o">.</span><span class="n">_shape</span><span class="p">)):</span>
                    <span class="k">if</span> <span class="n">new_node</span><span class="o">.</span><span class="n">_axes</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">is_batch</span><span class="p">():</span>
                        <span class="c1"># Admit any size in batch edges</span>
                        <span class="n">index</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">index</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="n">max_dim</span> <span class="o">-</span> <span class="n">dim</span><span class="p">,</span> <span class="n">max_dim</span><span class="p">))</span>
                <span class="n">new_node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;index&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">index</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">node_index</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;index&#39;</span><span class="p">]</span>
                <span class="n">aux_slice</span> <span class="o">=</span> <span class="n">node_index</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">aux_slice</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="n">aux_slice</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="nb">range</span><span class="p">(</span><span class="n">aux_slice</span><span class="o">.</span><span class="n">start</span><span class="p">,</span>
                                   <span class="n">aux_slice</span><span class="o">.</span><span class="n">stop</span><span class="p">,</span>
                                   <span class="n">aux_slice</span><span class="o">.</span><span class="n">step</span><span class="p">)[</span><span class="n">i</span><span class="p">]]</span>

                <span class="k">if</span> <span class="n">node_index</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
                    <span class="c1"># If node is indexing from the original stack</span>
                    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="p">(</span><span class="n">aux_slice</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">node_index</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span>
                                                             <span class="n">new_node</span><span class="o">.</span><span class="n">_shape</span><span class="p">)):</span>
                        <span class="k">if</span> <span class="n">new_node</span><span class="o">.</span><span class="n">_axes</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">is_batch</span><span class="p">():</span>
                            <span class="c1"># Admit any size in batch edges</span>
                            <span class="n">index</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">index</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="n">aux_slice</span><span class="o">.</span><span class="n">stop</span> <span class="o">-</span> <span class="n">dim</span><span class="p">,</span>
                                               <span class="n">aux_slice</span><span class="o">.</span><span class="n">stop</span><span class="p">))</span>

                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># If node has the same shape as the original stack</span>
                    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="p">(</span><span class="n">max_dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span>
                                                           <span class="n">new_node</span><span class="o">.</span><span class="n">_shape</span><span class="p">)):</span>
                        <span class="k">if</span> <span class="n">new_node</span><span class="o">.</span><span class="n">_axes</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">is_batch</span><span class="p">():</span>
                            <span class="c1"># Admit any size in batch edges</span>
                            <span class="n">index</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">index</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="n">max_dim</span> <span class="o">-</span> <span class="n">dim</span><span class="p">,</span> <span class="n">max_dim</span><span class="p">))</span>

                <span class="n">new_node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;index&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">index</span>

    <span class="c1"># Create successor</span>
    <span class="n">successor</span> <span class="o">=</span> <span class="n">Successor</span><span class="p">(</span><span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;node&#39;</span><span class="p">:</span> <span class="n">node</span><span class="p">},</span>
                          <span class="n">child</span><span class="o">=</span><span class="n">new_nodes</span><span class="p">,</span>
                          <span class="n">hints</span><span class="o">=</span><span class="n">batch_ids</span><span class="p">)</span>

    <span class="c1"># Add successor to parent</span>
    <span class="k">if</span> <span class="s1">&#39;unbind&#39;</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">_successors</span><span class="p">:</span>
        <span class="n">node</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;unbind&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">successor</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">node</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;unbind&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">successor</span><span class="p">]</span>

    <span class="c1"># Add operation to list of performed operations of TN</span>
    <span class="n">net</span><span class="o">.</span><span class="n">_seq_ops</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;unbind&#39;</span><span class="p">,</span> <span class="n">successor</span><span class="o">.</span><span class="n">kwargs</span><span class="p">))</span>

    <span class="c1"># Returns copy in order not to modify the successor</span>
    <span class="c1"># if the returned list gets modified by any means</span>
    <span class="k">return</span> <span class="n">new_nodes</span><span class="p">[:]</span>


<span class="k">def</span> <span class="nf">_unbind_next</span><span class="p">(</span><span class="n">successor</span><span class="p">:</span> <span class="n">Successor</span><span class="p">,</span> <span class="n">node</span><span class="p">:</span> <span class="n">AbstractStackNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Node</span><span class="p">]:</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">_network</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">net</span><span class="o">.</span><span class="n">_auto_unbind</span><span class="p">:</span>
        <span class="n">tensors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span><span class="p">)</span>
        <span class="n">children</span> <span class="o">=</span> <span class="n">successor</span><span class="o">.</span><span class="n">child</span>
        <span class="k">for</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">child</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">children</span><span class="p">):</span>
            <span class="n">child</span><span class="o">.</span><span class="n">_direct_set_tensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Record in inverse_memory while contracting</span>
        <span class="c1"># (to delete memory if possible)</span>
        <span class="n">node</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">children</span><span class="p">[:]</span>

    <span class="k">else</span><span class="p">:</span>  <span class="c1"># index_mode</span>
        <span class="n">children</span> <span class="o">=</span> <span class="n">successor</span><span class="o">.</span><span class="n">child</span>
        <span class="n">batch_ids</span> <span class="o">=</span> <span class="n">successor</span><span class="o">.</span><span class="n">hints</span>
        <span class="n">diff_batches</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch_ids</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_shape</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">!=</span> <span class="n">node</span><span class="o">.</span><span class="n">_shape</span><span class="p">[</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]:</span>
                <span class="n">batch_ids</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
                <span class="n">diff_batches</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="n">node</span><span class="o">.</span><span class="n">_shape</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]))</span>
        
        <span class="k">for</span> <span class="n">child</span> <span class="ow">in</span> <span class="n">children</span><span class="p">:</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">child</span><span class="o">.</span><span class="n">_shape</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">diff_batches</span><span class="p">:</span>
                <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">size</span>
            <span class="n">child</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">Size</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
            
        <span class="k">return</span> <span class="n">children</span><span class="p">[:]</span>


<span class="n">unbind_op</span> <span class="o">=</span> <span class="n">Operation</span><span class="p">(</span><span class="s1">&#39;unbind&#39;</span><span class="p">,</span>
                      <span class="n">_check_first_unbind</span><span class="p">,</span>
                      <span class="n">_unbind_first</span><span class="p">,</span>
                      <span class="n">_unbind_next</span><span class="p">)</span>


<div class="viewcode-block" id="unbind"><a class="viewcode-back" href="../../operations.html#tensorkrowch.unbind">[docs]</a><span class="k">def</span> <span class="nf">unbind</span><span class="p">(</span><span class="n">node</span><span class="p">:</span> <span class="n">AbstractStackNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Node</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Unbinds a :class:`StackNode` or :class:`ParamStackNode`, where the first</span>
<span class="sd">    dimension is assumed to be the stack dimension.</span>

<span class="sd">    If :meth:`~TensorNetwork.auto_unbind` is set to ``False``, each resultant</span>
<span class="sd">    node will store its own tensor. Otherwise, they will have only a reference</span>
<span class="sd">    to the corresponding slice of the ``(Param)StackNode``.</span>
<span class="sd">    </span>
<span class="sd">    See :class:`TensorNetwork` to learn how the ``auto_unbind`` mode affects</span>
<span class="sd">    the computation of :func:`unbind`.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation are called ``&quot;unbind&quot;``. The node</span>
<span class="sd">    that keeps information about the :class:`Successor` is ``node``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    node : StackNode or ParamStackNode</span>
<span class="sd">        Node that is to be unbinded.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list[Node]</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; net = tk.TensorNetwork()</span>
<span class="sd">    &gt;&gt;&gt; nodes = [tk.randn(shape=(2, 4, 2),</span>
<span class="sd">    ...                   axes_names=(&#39;left&#39;, &#39;input&#39;, &#39;right&#39;),</span>
<span class="sd">    ...                   network=net)</span>
<span class="sd">    ...          for _ in range(10)]</span>
<span class="sd">    &gt;&gt;&gt; data = [tk.randn(shape=(4,),</span>
<span class="sd">    ...                  axes_names=(&#39;feature&#39;,),</span>
<span class="sd">    ...                  network=net)</span>
<span class="sd">    ...         for _ in range(10)]</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; for i in range(10):</span>
<span class="sd">    ...     _ = nodes[i][&#39;input&#39;] ^ data[i][&#39;feature&#39;]</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; stack_nodes = tk.stack(nodes)</span>
<span class="sd">    &gt;&gt;&gt; stack_data = tk.stack(data)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; # It is necessary to re-connect stacks</span>
<span class="sd">    &gt;&gt;&gt; _ = stack_nodes[&#39;input&#39;] ^ stack_data[&#39;feature&#39;]</span>
<span class="sd">    &gt;&gt;&gt; result = tk.unbind(stack_nodes @ stack_data)</span>
<span class="sd">    &gt;&gt;&gt; print(result[0].name)</span>
<span class="sd">    unbind_0</span>

<span class="sd">    &gt;&gt;&gt; result[0].axes</span>
<span class="sd">    [Axis( left (0) ), Axis( right (1) )]</span>

<span class="sd">    &gt;&gt;&gt; result[0].shape</span>
<span class="sd">    torch.Size([2, 2])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">unbind_op</span><span class="p">(</span><span class="n">node</span><span class="p">)</span></div>


<span class="c1">##################################   EINSUM   #################################</span>
<span class="k">def</span> <span class="nf">_check_first_einsum</span><span class="p">(</span><span class="n">string</span><span class="p">:</span> <span class="n">Text</span><span class="p">,</span>
                        <span class="o">*</span><span class="n">nodes</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Successor</span><span class="p">]:</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;string&#39;</span><span class="p">:</span> <span class="n">string</span><span class="p">,</span>
              <span class="s1">&#39;nodes&#39;</span><span class="p">:</span> <span class="n">nodes</span><span class="p">}</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">nodes</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;No nodes were provided&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="s1">&#39;einsum&#39;</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_successors</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">succ</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;einsum&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">succ</span><span class="o">.</span><span class="n">kwargs</span> <span class="o">==</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">succ</span>
    <span class="k">return</span> <span class="kc">None</span>


<span class="k">def</span> <span class="nf">_einsum_first</span><span class="p">(</span><span class="n">string</span><span class="p">:</span> <span class="n">Text</span><span class="p">,</span> <span class="o">*</span><span class="n">nodes</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">nodes</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])):</span>
        <span class="k">if</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">_network</span> <span class="o">!=</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">_network</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;All `nodes` must be in the same network&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="s1">&#39;-&gt;&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">string</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Einsum `string` should have an arrow `-&gt;` separating &#39;</span>
                         <span class="s1">&#39;inputs and output strings&#39;</span><span class="p">)</span>

    <span class="n">input_strings</span> <span class="o">=</span> <span class="n">string</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;-&gt;&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_strings</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">nodes</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Number of einsum subscripts must be equal to the &#39;</span>
                         <span class="s1">&#39;number of operands&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;-&gt;&#39;</span><span class="p">))</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">output_string</span> <span class="o">=</span> <span class="n">string</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;-&gt;&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">output_string</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

    <span class="c1"># Used for counting appearances of output subscripts in the input strings</span>
    <span class="n">output_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">output_string</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_string</span><span class="p">)))</span>

    <span class="n">output_char_index</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">output_string</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">output_string</span><span class="p">))))</span>

    <span class="c1"># Used for counting how many times a contracted edge&#39;s</span>
    <span class="c1"># subscript appears among input strings</span>
    <span class="n">contracted_edges</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

    <span class="c1"># Used for counting how many times a batch edge&#39;s</span>
    <span class="c1"># subscript appears among input strings</span>
    <span class="n">batch_edges</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

    <span class="n">axes_names</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">output_string</span><span class="p">)),</span>
                          <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_string</span><span class="p">)))</span>
    <span class="n">edges</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">output_string</span><span class="p">)),</span>
                     <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_string</span><span class="p">)))</span>
    <span class="n">node1_list</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">output_string</span><span class="p">)),</span>
                          <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_string</span><span class="p">)))</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">input_string</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">input_strings</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">char</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">input_string</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">char</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">output_dict</span><span class="p">:</span>
                <span class="n">edge</span> <span class="o">=</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">char</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">contracted_edges</span><span class="p">:</span>
                    <span class="n">contracted_edges</span><span class="p">[</span><span class="n">char</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">edge</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">contracted_edges</span><span class="p">[</span><span class="n">char</span><span class="p">])</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Subscript </span><span class="si">{</span><span class="n">char</span><span class="si">}</span><span class="s1"> appearing more than&#39;</span>
                                         <span class="s1">&#39; once in the input should be a batch &#39;</span>
                                         <span class="s1">&#39;index, but it does not appear among &#39;</span>
                                         <span class="s1">&#39;the output subscripts&#39;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">edge</span> <span class="o">!=</span> <span class="n">contracted_edges</span><span class="p">[</span><span class="n">char</span><span class="p">][</span><span class="mi">0</span><span class="p">]:</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge</span><span class="p">,</span> <span class="n">StackEdge</span><span class="p">)</span> <span class="ow">and</span> \
                                <span class="nb">isinstance</span><span class="p">(</span><span class="n">contracted_edges</span><span class="p">[</span><span class="n">char</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">StackEdge</span><span class="p">):</span>
                            <span class="n">edge</span> <span class="o">=</span> <span class="n">edge</span> <span class="o">^</span> <span class="n">contracted_edges</span><span class="p">[</span><span class="n">char</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Subscript </span><span class="si">{</span><span class="n">char</span><span class="si">}</span><span class="s1"> appears in two &#39;</span>
                                             <span class="s1">&#39;nodes that do not share a connected&#39;</span>
                                             <span class="s1">&#39; edge at the specified axis&#39;</span><span class="p">)</span>
                    <span class="n">contracted_edges</span><span class="p">[</span><span class="n">char</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">edge</span> <span class="o">=</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">output_dict</span><span class="p">[</span><span class="n">char</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">edge</span><span class="o">.</span><span class="n">is_batch</span><span class="p">():</span>
                        <span class="n">batch_edges</span><span class="p">[</span><span class="n">char</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="n">k</span> <span class="o">=</span> <span class="n">output_char_index</span><span class="p">[</span><span class="n">char</span><span class="p">]</span>
                    <span class="n">axes_names</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">_axes</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">_name</span>
                    <span class="n">edges</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">edge</span>
                    <span class="n">node1_list</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">_axes</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">is_node1</span><span class="p">()</span>
                <span class="n">output_dict</span><span class="p">[</span><span class="n">char</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">char</span> <span class="ow">in</span> <span class="n">batch_edges</span><span class="p">)</span> <span class="ow">and</span> <span class="n">edge</span><span class="o">.</span><span class="n">is_batch</span><span class="p">():</span>
                    <span class="n">batch_edges</span><span class="p">[</span><span class="n">char</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">output_dict</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">output_dict</span><span class="p">[</span><span class="n">char</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Output subscript </span><span class="si">{</span><span class="n">char</span><span class="si">}</span><span class="s1"> must appear among &#39;</span>
                             <span class="sa">f</span><span class="s1">&#39;the input subscripts&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">output_dict</span><span class="p">[</span><span class="n">char</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">batch_edges</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">batch_edges</span><span class="p">[</span><span class="n">char</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">output_dict</span><span class="p">[</span><span class="n">char</span><span class="p">]:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Subscript </span><span class="si">{</span><span class="n">char</span><span class="si">}</span><span class="s1"> used as batch, but some&#39;</span>
                                     <span class="s1">&#39; of those edges are not batch edges&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Subscript </span><span class="si">{</span><span class="n">char</span><span class="si">}</span><span class="s1"> used as batch, but none &#39;</span>
                                 <span class="sa">f</span><span class="s1">&#39;of those edges is a batch edge&#39;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">contracted_edges</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">contracted_edges</span><span class="p">[</span><span class="n">char</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Subscript </span><span class="si">{</span><span class="n">char</span><span class="si">}</span><span class="s1"> appears only once in the input &#39;</span>
                             <span class="sa">f</span><span class="s1">&#39;but none among the output subscripts&#39;</span><span class="p">)</span>

    <span class="n">input_string</span> <span class="o">=</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">input_strings</span><span class="p">)</span>
    <span class="n">einsum_string</span> <span class="o">=</span> <span class="n">input_string</span> <span class="o">+</span> <span class="s1">&#39;-&gt;&#39;</span> <span class="o">+</span> <span class="n">output_string</span>
    <span class="n">tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">]</span>
    <span class="n">path</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">opt_einsum</span><span class="o">.</span><span class="n">contract_path</span><span class="p">(</span><span class="n">einsum_string</span><span class="p">,</span> <span class="o">*</span><span class="n">tensors</span><span class="p">)</span>
    <span class="n">new_tensor</span> <span class="o">=</span> <span class="n">opt_einsum</span><span class="o">.</span><span class="n">contract</span><span class="p">(</span><span class="n">einsum_string</span><span class="p">,</span> <span class="o">*</span><span class="n">tensors</span><span class="p">,</span> <span class="n">optimize</span><span class="o">=</span><span class="n">path</span><span class="p">)</span>

    <span class="n">all_stack</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">all_non_stack</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="p">(</span><span class="n">StackNode</span><span class="p">,</span> <span class="n">ParamStackNode</span><span class="p">)):</span>
            <span class="n">all_stack</span> <span class="o">&amp;=</span> <span class="kc">True</span>
            <span class="n">all_non_stack</span> <span class="o">&amp;=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">all_stack</span> <span class="o">&amp;=</span> <span class="kc">False</span>
            <span class="n">all_non_stack</span> <span class="o">&amp;=</span> <span class="kc">True</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">all_stack</span> <span class="ow">or</span> <span class="n">all_non_stack</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Cannot operate (Param)StackNode</span><span class="se">\&#39;</span><span class="s1">s with &#39;</span>
                        <span class="s1">&#39;other (non-stack) nodes&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">all_stack</span><span class="p">:</span>
        <span class="n">new_node</span> <span class="o">=</span> <span class="n">StackNode</span><span class="o">.</span><span class="n">_create_resultant</span><span class="p">(</span><span class="n">axes_names</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">axes_names</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span>
                                               <span class="n">name</span><span class="o">=</span><span class="s1">&#39;einsum&#39;</span><span class="p">,</span>
                                               <span class="n">network</span><span class="o">=</span><span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_network</span><span class="p">,</span>
                                               <span class="n">tensor</span><span class="o">=</span><span class="n">new_tensor</span><span class="p">,</span>
                                               <span class="n">edges</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">edges</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span>
                                               <span class="n">node1_list</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">node1_list</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">new_node</span> <span class="o">=</span> <span class="n">Node</span><span class="o">.</span><span class="n">_create_resultant</span><span class="p">(</span><span class="n">axes_names</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">axes_names</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span>
                                          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;einsum&#39;</span><span class="p">,</span>
                                          <span class="n">network</span><span class="o">=</span><span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_network</span><span class="p">,</span>
                                          <span class="n">tensor</span><span class="o">=</span><span class="n">new_tensor</span><span class="p">,</span>
                                          <span class="n">edges</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">edges</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span>
                                          <span class="n">node1_list</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">node1_list</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>

    <span class="c1"># Create successor</span>
    <span class="n">successor</span> <span class="o">=</span> <span class="n">Successor</span><span class="p">(</span><span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;string&#39;</span><span class="p">:</span> <span class="n">string</span><span class="p">,</span>
                                  <span class="s1">&#39;nodes&#39;</span><span class="p">:</span> <span class="n">nodes</span><span class="p">},</span>
                          <span class="n">child</span><span class="o">=</span><span class="n">new_node</span><span class="p">,</span>
                          <span class="n">hints</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;einsum_string&#39;</span><span class="p">:</span> <span class="n">einsum_string</span><span class="p">,</span>
                                 <span class="s1">&#39;path&#39;</span><span class="p">:</span> <span class="n">path</span><span class="p">})</span>

    <span class="c1"># Add successor to parent</span>
    <span class="k">if</span> <span class="s1">&#39;einsum&#39;</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_successors</span><span class="p">:</span>
        <span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;einsum&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">successor</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="s1">&#39;einsum&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">successor</span><span class="p">]</span>

    <span class="c1"># Add operation to list of performed operations of TN</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_network</span>
    <span class="n">net</span><span class="o">.</span><span class="n">_seq_ops</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;einsum&#39;</span><span class="p">,</span> <span class="n">successor</span><span class="o">.</span><span class="n">kwargs</span><span class="p">))</span>

    <span class="c1"># Record in inverse_memory while tracing</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">:</span>
        <span class="n">node</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">new_node</span>


<span class="k">def</span> <span class="nf">_einsum_next</span><span class="p">(</span><span class="n">successor</span><span class="p">:</span> <span class="n">Successor</span><span class="p">,</span>
                 <span class="n">string</span><span class="p">:</span> <span class="n">Text</span><span class="p">,</span>
                 <span class="o">*</span><span class="n">nodes</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
    <span class="n">hints</span> <span class="o">=</span> <span class="n">successor</span><span class="o">.</span><span class="n">hints</span>

    <span class="n">tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">]</span>
    <span class="n">new_tensor</span> <span class="o">=</span> <span class="n">opt_einsum</span><span class="o">.</span><span class="n">contract</span><span class="p">(</span><span class="n">hints</span><span class="p">[</span><span class="s1">&#39;einsum_string&#39;</span><span class="p">],</span> <span class="o">*</span><span class="n">tensors</span><span class="p">,</span>
                                     <span class="n">optimize</span><span class="o">=</span><span class="n">hints</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">])</span>

    <span class="n">child</span> <span class="o">=</span> <span class="n">successor</span><span class="o">.</span><span class="n">child</span>
    <span class="n">child</span><span class="o">.</span><span class="n">_direct_set_tensor</span><span class="p">(</span><span class="n">new_tensor</span><span class="p">)</span>

    <span class="c1"># Record in inverse_memory while contracting</span>
    <span class="c1"># (to delete memory if possible)</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">:</span>
        <span class="n">node</span><span class="o">.</span><span class="n">_record_in_inverse_memory</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">child</span>


<span class="n">einsum_op</span> <span class="o">=</span> <span class="n">Operation</span><span class="p">(</span><span class="s1">&#39;einsum&#39;</span><span class="p">,</span>
                      <span class="n">_check_first_einsum</span><span class="p">,</span>
                      <span class="n">_einsum_first</span><span class="p">,</span>
                      <span class="n">_einsum_next</span><span class="p">)</span>


<div class="viewcode-block" id="einsum"><a class="viewcode-back" href="../../operations.html#tensorkrowch.einsum">[docs]</a><span class="k">def</span> <span class="nf">einsum</span><span class="p">(</span><span class="n">string</span><span class="p">:</span> <span class="n">Text</span><span class="p">,</span> <span class="o">*</span><span class="n">nodes</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs einsum contraction based on `opt_einsum</span>
<span class="sd">    &lt;https://optimized-einsum.readthedocs.io/en/stable/autosummary/opt_einsum.contract.html&gt;`_.</span>
<span class="sd">    This operation facilitates contracting several nodes at once, specifying</span>
<span class="sd">    directly the order of appearance of the resultant edges. Without this</span>
<span class="sd">    operation, several contractions and permutations would be needed.</span>

<span class="sd">    Since it adapts a tensor operation for nodes, certain nodes&#39; properties are</span>
<span class="sd">    first checked. Thus, it verifies that all edges are correctly connected and</span>
<span class="sd">    all nodes are in the same network. It also performs batch contraction</span>
<span class="sd">    whenever corresponding edges are batch edges.</span>
<span class="sd">    </span>
<span class="sd">    Nodes ``resultant`` from this operation are called ``&quot;einsum&quot;``. The node</span>
<span class="sd">    that keeps information about the :class:`Successor` is ``nodes[0]``, the</span>
<span class="sd">    first node involved in the operation.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    string : str</span>
<span class="sd">        Einsum-like string indicating how the contraction should be performed.</span>
<span class="sd">        It consists of a comma-separated list of inputs and an output separated</span>
<span class="sd">        by an arrow. For instance, the contraction</span>

<span class="sd">        .. math::</span>

<span class="sd">            T_{j,l} = \sum_{i,k,m}{A_{i,j,k}B_{k,l,m}C_{i,m}}</span>

<span class="sd">        can be expressed as::</span>

<span class="sd">            string = &#39;ijk,klm,im-&gt;jl&#39;</span>
<span class="sd">    nodes : AbstractNode...</span>
<span class="sd">        Nodes that are involved in the contraction. Should appear in the same</span>
<span class="sd">        order as it is specified in the ``string``. They should either be all</span>
<span class="sd">        ``(Param)StackNode``&#39;s or none of them be a ``(Param)StackNode``.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Node</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.randn(shape=(10, 15, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeA&#39;)</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.randn(shape=(15, 7, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeB&#39;)</span>
<span class="sd">    &gt;&gt;&gt; nodeC = tk.randn(shape=(7, 10, 100),</span>
<span class="sd">    ...                  axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                  name=&#39;nodeC&#39;)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; _ = nodeA[&#39;right&#39;] ^ nodeB[&#39;left&#39;]</span>
<span class="sd">    &gt;&gt;&gt; _ = nodeB[&#39;right&#39;] ^ nodeC[&#39;left&#39;]</span>
<span class="sd">    &gt;&gt;&gt; _ = nodeC[&#39;right&#39;] ^ nodeA[&#39;left&#39;]</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; result = tk.einsum(&#39;ijb,jkb,kib-&gt;b&#39;, nodeA, nodeB, nodeC)</span>
<span class="sd">    &gt;&gt;&gt; result.shape</span>
<span class="sd">    torch.Size([100])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">einsum_op</span><span class="p">(</span><span class="n">string</span><span class="p">,</span> <span class="o">*</span><span class="n">nodes</span><span class="p">)</span></div>


<span class="c1">##############################   STACKED EINSUM   #############################</span>
<div class="viewcode-block" id="stacked_einsum"><a class="viewcode-back" href="../../operations.html#tensorkrowch.stacked_einsum">[docs]</a><span class="k">def</span> <span class="nf">stacked_einsum</span><span class="p">(</span><span class="n">string</span><span class="p">:</span> <span class="n">Text</span><span class="p">,</span>
                   <span class="o">*</span><span class="n">nodes_lists</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">AbstractNode</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Node</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies the same :func:`einsum` operation (same ``string``) to a sequence</span>
<span class="sd">    of groups of nodes (all groups having the same amount of nodes, with the</span>
<span class="sd">    same properties, etc.). That is, it stacks these groups of nodes into a</span>
<span class="sd">    single collection of ``StackNodes`` that is then contracted via</span>
<span class="sd">    :func:`einsum` (using the stack dimensions as **batch**), and</span>
<span class="sd">    :func:`unbinded &lt;unbind&gt;` afterwards.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    string : str</span>
<span class="sd">        Einsum-like string indicating how the contraction should be performed.</span>
<span class="sd">        It consists of a comma-separated list of inputs and an output separated</span>
<span class="sd">        by an arrow. For instance, the contraction</span>

<span class="sd">        .. math::</span>

<span class="sd">            T_{j,l} = \sum_{i,k,m}{A_{i,j,k}B_{k,l,m}C_{i,m}}</span>

<span class="sd">        can be expressed as::</span>

<span class="sd">            string = &#39;ijk,klm,im-&gt;jl&#39;</span>
<span class="sd">    nodes : List[Node or ParamNode]...</span>
<span class="sd">        Nodes that are involved in the contraction. Should appear in the same</span>
<span class="sd">        order as it is specified in the ``string``.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list[Node]</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; net = tk.TensorNetwork()</span>
<span class="sd">    &gt;&gt;&gt; nodesA = [tk.randn(shape=(10, 15, 100),</span>
<span class="sd">    ...                    axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                    name=&#39;nodeA&#39;,</span>
<span class="sd">    ...                    network=net)</span>
<span class="sd">    ...           for _ in range(10)]</span>
<span class="sd">    &gt;&gt;&gt; nodesB = [tk.randn(shape=(15, 7, 100),</span>
<span class="sd">    ...                    axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                    name=&#39;nodeB&#39;,</span>
<span class="sd">    ...                    network=net)</span>
<span class="sd">    ...           for _ in range(10)]</span>
<span class="sd">    &gt;&gt;&gt; nodesC = [tk.randn(shape=(7, 10, 100),</span>
<span class="sd">    ...                    axes_names=(&#39;left&#39;, &#39;right&#39;, &#39;batch&#39;),</span>
<span class="sd">    ...                    name=&#39;nodeC&#39;,</span>
<span class="sd">    ...                    network=net)</span>
<span class="sd">    ...           for _ in range(10)]</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; for i in range(10):</span>
<span class="sd">    ...     _ = nodesA[i][&#39;right&#39;] ^ nodesB[i][&#39;left&#39;]</span>
<span class="sd">    ...     _ = nodesB[i][&#39;right&#39;] ^ nodesC[i][&#39;left&#39;]</span>
<span class="sd">    ...     _ = nodesC[i][&#39;right&#39;] ^ nodesA[i][&#39;left&#39;]</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; result = tk.stacked_einsum(&#39;ijb,jkb,kib-&gt;b&#39;, nodesA, nodesB, nodesC)</span>
<span class="sd">    &gt;&gt;&gt; len(result)</span>
<span class="sd">    10</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; result[0].shape</span>
<span class="sd">    torch.Size([100])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">stacks_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">nodes_list</span> <span class="ow">in</span> <span class="n">nodes_lists</span><span class="p">:</span>
        <span class="n">stacks_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stack</span><span class="p">(</span><span class="n">nodes_list</span><span class="p">))</span>

    <span class="n">input_strings</span> <span class="o">=</span> <span class="n">string</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;-&gt;&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
    <span class="n">output_string</span> <span class="o">=</span> <span class="n">string</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;-&gt;&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">stack_char</span> <span class="o">=</span> <span class="n">opt_einsum</span><span class="o">.</span><span class="n">get_symbol</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">input_string</span> <span class="ow">in</span> <span class="n">input_strings</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">input_char</span> <span class="ow">in</span> <span class="n">input_string</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">input_char</span> <span class="o">==</span> <span class="n">stack_char</span><span class="p">:</span>
                <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">stack_char</span> <span class="o">=</span> <span class="n">opt_einsum</span><span class="o">.</span><span class="n">get_symbol</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

    <span class="n">input_strings</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="n">stack_char</span> <span class="o">+</span> <span class="n">s</span><span class="p">,</span> <span class="n">input_strings</span><span class="p">))</span>
    <span class="n">input_string</span> <span class="o">=</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">input_strings</span><span class="p">)</span>
    <span class="n">output_string</span> <span class="o">=</span> <span class="n">stack_char</span> <span class="o">+</span> <span class="n">output_string</span>
    <span class="n">string</span> <span class="o">=</span> <span class="n">input_string</span> <span class="o">+</span> <span class="s1">&#39;-&gt;&#39;</span> <span class="o">+</span> <span class="n">output_string</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">einsum</span><span class="p">(</span><span class="n">string</span><span class="p">,</span> <span class="o">*</span><span class="n">stacks_list</span><span class="p">)</span>
    <span class="n">unbinded_result</span> <span class="o">=</span> <span class="n">unbind</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">unbinded_result</span></div>
</pre></div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By José Ramón Pareja Monturiol<br/>
  
      &copy; Copyright 2023, José Ramón Pareja Monturiol.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>