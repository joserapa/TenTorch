
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>tensorkrowch.models.tree &#8212; TensorKrowch 1.0.0 documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="shortcut icon" href="../../../_static/tensorkrowch_favicon_light.svg"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../_static/tensorkrowch_logo_light.svg" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Contents:
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../tutorials.html">
   Tutorials
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../tutorials/0_first_steps.html">
     First Steps with TensorKrowch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../tutorials/1_creating_tensor_network.html">
     Creating a Tensor Network in TensorKrowch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../tutorials/2_contracting_tensor_network.html">
     Contracting and Differentiating the Tensor Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../tutorials/3_memory_management.html">
     How to save Memory and Time with TensorKrowch (ADVANCED)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../tutorials/4_types_of_nodes.html">
     The different Types of Nodes (ADVANCED)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../tutorials/5_subclass_tensor_network.html">
     How to subclass TensorNetwork to build Custom Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../tutorials/6_mix_with_pytorch.html">
     Creating a Hybrid Neural-Tensor Network Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../api.html">
   API Reference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../components.html">
     Components
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../operations.html">
     Operations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models.html">
     Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../initializers.html">
     Initializers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../embeddings.html">
     Embeddings
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<a href="https://github.com/joserapa98/tensorkrowch"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="bottom"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <h1>Source code for tensorkrowch.models.tree</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This script contains:</span>
<span class="sd">    * Tree</span>
<span class="sd">    * UTree</span>
<span class="sd">    * ConvTree</span>
<span class="sd">    * ConvUTree</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="p">(</span><span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span>
                    <span class="n">Text</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="kn">import</span> <span class="nn">tensorkrowch.operations</span> <span class="k">as</span> <span class="nn">op</span>
<span class="kn">from</span> <span class="nn">tensorkrowch.components</span> <span class="kn">import</span> <span class="n">Node</span><span class="p">,</span> <span class="n">ParamNode</span>
<span class="kn">from</span> <span class="nn">tensorkrowch.components</span> <span class="kn">import</span> <span class="n">TensorNetwork</span>


<div class="viewcode-block" id="Tree"><a class="viewcode-back" href="../../../models.html#tensorkrowch.models.Tree">[docs]</a><span class="k">class</span> <span class="nc">Tree</span><span class="p">(</span><span class="n">TensorNetwork</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class for Tree States. These states form a tree structure where the ``data``</span>
<span class="sd">    nodes are in the base. All nodes have a sequence of input edges and an</span>
<span class="sd">    output edge. Thus the contraction of the Tree returns a `vector` node.</span>
<span class="sd">    </span>
<span class="sd">    All nodes in the network are in ``self.layers``, a list containing the lists</span>
<span class="sd">    of nodes in each layer (starting from the bottom).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sites_per_layer : list[int] or tuple[int]</span>
<span class="sd">        Number of sites in each layer of the tree. All nodes in the same layer</span>
<span class="sd">        have the same shape. Number of nodes in each layer times the number of</span>
<span class="sd">        input edges these have should match the number ot output edges in the</span>
<span class="sd">        previous layer. The last element of ``sites_per_layer`` should be always</span>
<span class="sd">        1, which corresponds to the output node.</span>
<span class="sd">    bond_dim : list[list[int]] or tuple[tuple[int]]</span>
<span class="sd">        Bond dimensions of nodes in each layer. Each sequence corresponds to the</span>
<span class="sd">        shape of the nodes in each layer, starting from the bottom (some input</span>
<span class="sd">        edges and an output edge in the last position).</span>
<span class="sd">    n_batches : int</span>
<span class="sd">        Number of batch edges of input ``data`` nodes. Usually ``n_batches = 1``</span>
<span class="sd">        (where the batch edge is used for the data batched) but it could also</span>
<span class="sd">        be ``n_batches = 2`` (one edge for data batched, other edge for image</span>
<span class="sd">        patches in convolutional layers).</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; tree = tk.models.Tree(sites_per_layer=[4, 2, 1],</span>
<span class="sd">    ...                       bond_dim=[[3, 3, 4], [4, 4, 2], [2, 2, 2]])</span>
<span class="sd">    &gt;&gt;&gt; data = torch.ones(20, 8, 3) # batch_size x n_features x feature_size</span>
<span class="sd">    &gt;&gt;&gt; result = tree(data)</span>
<span class="sd">    &gt;&gt;&gt; result.shape</span>
<span class="sd">    torch.Size([20, 2])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">sites_per_layer</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
                 <span class="n">bond_dim</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
                 <span class="n">n_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;tree&#39;</span><span class="p">)</span>

        <span class="c1"># sites_per_layer</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sites_per_layer</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">sites_per_layer</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`sites_per_layer` cannot be empty, at least &#39;</span>
                                 <span class="s1">&#39;one node is required&#39;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">el</span> <span class="ow">in</span> <span class="n">sites_per_layer</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">el</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`sites_per_layer` should be a sequence of &#39;</span>
                                    <span class="s1">&#39;ints&#39;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">el</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Elements of `sites_per_layer` should be &#39;</span>
                                     <span class="s1">&#39;ints greater than 0&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">sites_per_layer</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The last element of `sites_per_layer` should &#39;</span>
                                 <span class="s1">&#39;be always 1&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`sites_per_layer` should be a sequence &#39;</span>
                            <span class="s1">&#39;(list or tuple type)&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sites_per_layer</span> <span class="o">=</span> <span class="n">sites_per_layer</span>

        <span class="c1"># bond_dim</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bond_dim</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">aux_bond_dim</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">lst</span> <span class="ow">in</span> <span class="n">bond_dim</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lst</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`bond_dim` sequences should have at &#39;</span>
                                         <span class="s1">&#39;least two elements, one for input &#39;</span>
                                         <span class="s1">&#39;and one for output&#39;</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">el</span> <span class="ow">in</span> <span class="n">lst</span><span class="p">:</span>
                        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">el</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`bond_dim` should be a sequence of &#39;</span>
                                            <span class="s1">&#39;sequences of ints&#39;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`bond_dim` should be a sequence of &#39;</span>
                                    <span class="s1">&#39;sequences of ints&#39;</span><span class="p">)</span>
                <span class="n">aux_bond_dim</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">lst</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`bond_dim` should be a sequence of sequences of &#39;</span>
                            <span class="s1">&#39;ints&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_bond_dim</span> <span class="o">=</span> <span class="n">aux_bond_dim</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sites_per_layer</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">bond_dim</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`sites_per_layer` and `bond_dim` should have the &#39;</span>
                             <span class="s1">&#39;same number of elements&#39;</span><span class="p">)</span>

        <span class="c1"># n_batches</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n_batches</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`n_batches should be int type&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_batches</span> <span class="o">=</span> <span class="n">n_batches</span>

        <span class="c1"># Create Tensor Network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_make_nodes</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">sites_per_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns number of sites in each layer of the tree.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sites_per_layer</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">bond_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
                                <span class="n">Sequence</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns bond dimensions of nodes in each layer. Each sequence</span>
<span class="sd">        corresponds to the shape of the nodes in each layer (some input edges</span>
<span class="sd">        and an output edge in the last position).</span>
<span class="sd">        </span>
<span class="sd">        It can have two forms:</span>
<span class="sd">        </span>
<span class="sd">        1) ``[shape_all_nodes_layer_1, ..., shape_all_nodes_layer_N]``</span>
<span class="sd">        2) ``[[shape_node_1_layer_1, ..., shape_node_i1_layer_1], ...,</span>
<span class="sd">           [shape_node_1_layer_N, ..., shape_node_iN_layer_N]]``</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bond_dim</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">n_batches</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns number of batch edges of the ``data`` nodes.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_batches</span>

    <span class="k">def</span> <span class="nf">_make_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Creates all the nodes of the Tree.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_leaf_nodes</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Cannot create Tree nodes if the Tree already has&#39;</span>
                             <span class="s1">&#39; nodes&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n_sites</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sites_per_layer</span><span class="p">):</span>
            <span class="n">layer_lst</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_sites</span><span class="p">):</span>
                <span class="n">node</span> <span class="o">=</span> <span class="n">ParamNode</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">bond_dim</span><span class="p">[</span><span class="n">i</span><span class="p">],),</span>
                                 <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="o">*</span><span class="p">([</span><span class="s1">&#39;input&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span>
                                         <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bond_dim</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)),</span>
                                             <span class="s1">&#39;output&#39;</span><span class="p">),</span>
                                 <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;tree_node_(</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">,</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">,</span>
                                 <span class="n">network</span><span class="o">=</span><span class="bp">self</span><span class="p">)</span>
                <span class="n">layer_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">idx_last_layer</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">layer_lst</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">_edges</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                        <span class="k">if</span> <span class="n">idx_last_layer</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
                            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;There are more input edges in &#39;</span>
                                             <span class="sa">f</span><span class="s1">&#39;layer </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> than output edges in &#39;</span>
                                             <span class="sa">f</span><span class="s1">&#39;layer </span><span class="si">{</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

                        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="n">idx_last_layer</span><span class="p">][</span><span class="s1">&#39;output&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">edge</span>
                        <span class="n">idx_last_layer</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="k">if</span> <span class="n">idx_last_layer</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;There are more output edges in &#39;</span>
                                     <span class="sa">f</span><span class="s1">&#39;layer </span><span class="si">{</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="si">}</span><span class="s1"> than input edges in &#39;</span>
                                     <span class="sa">f</span><span class="s1">&#39;layer </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer_lst</span><span class="p">)</span>

<div class="viewcode-block" id="Tree.initialize"><a class="viewcode-back" href="../../../models.html#tensorkrowch.models.Tree.initialize">[docs]</a>    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-9</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Initializes all the nodes.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">layer</span><span class="p">:</span>
                <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">std</span>
                <span class="n">tensor</span><span class="p">[(</span><span class="mi">0</span><span class="p">,)</span> <span class="o">*</span> <span class="n">node</span><span class="o">.</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>
                <span class="n">node</span><span class="o">.</span><span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span></div>

<div class="viewcode-block" id="Tree.set_data_nodes"><a class="viewcode-back" href="../../../models.html#tensorkrowch.models.Tree.set_data_nodes">[docs]</a>    <span class="k">def</span> <span class="nf">set_data_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates data nodes and connects each of them to the physical edge of</span>
<span class="sd">        an input node.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">input_edges</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="n">input_edges</span> <span class="o">+=</span> <span class="n">node</span><span class="o">.</span><span class="n">edges</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">set_data_nodes</span><span class="p">(</span><span class="n">input_edges</span><span class="o">=</span><span class="n">input_edges</span><span class="p">,</span>
                               <span class="n">num_batch_edges</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_batches</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_input_contraction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                           <span class="n">layer1</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Node</span><span class="p">],</span>
                           <span class="n">layer2</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Node</span><span class="p">],</span>
                           <span class="n">inline</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Node</span><span class="p">]],</span>
                                                  <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Node</span><span class="p">]]]:</span>
        <span class="sd">&quot;&quot;&quot;Contracts two consecutive layers of the tree.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">inline</span><span class="p">:</span>
            <span class="n">result_lst</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">layer2</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
                    <span class="n">node</span> <span class="o">=</span> <span class="n">layer1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">@</span> <span class="n">node</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">result_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">result_lst</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">n_input</span> <span class="o">=</span> <span class="n">layer2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="n">stack2</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">layer2</span><span class="p">)</span>

            <span class="n">layer1_stacks</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_input</span><span class="p">):</span>
                <span class="n">stack_lst</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer1</span><span class="p">),</span> <span class="n">n_input</span><span class="p">):</span>
                    <span class="n">stack_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer1</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
                <span class="n">layer1_stacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">stack_lst</span><span class="p">))</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_input</span><span class="p">):</span>
                <span class="n">stack2</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">^</span> <span class="n">layer1_stacks</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="n">result</span> <span class="o">=</span> <span class="n">stack2</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_input</span><span class="p">):</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">layer1_stacks</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">@</span> <span class="n">result</span>

            <span class="n">result_lst</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">result_lst</span>

<div class="viewcode-block" id="Tree.contract"><a class="viewcode-back" href="../../../models.html#tensorkrowch.models.Tree.contract">[docs]</a>    <span class="k">def</span> <span class="nf">contract</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inline</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Contracts the whole Tree Tensor Network.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        inline : bool</span>
<span class="sd">            Boolean indicating whether consecutive layers should be contracted</span>
<span class="sd">            inline or in parallel (using a single stacked contraction).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Node</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_nodes</span><span class="o">.</span><span class="n">values</span><span class="p">())]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">layer1</span> <span class="o">=</span> <span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">layer2</span> <span class="o">=</span> <span class="n">layers</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">result_lst</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_contraction</span><span class="p">(</span><span class="n">layer1</span><span class="p">,</span>
                                                 <span class="n">layer2</span><span class="p">,</span>
                                                 <span class="n">inline</span><span class="o">=</span><span class="n">inline</span><span class="p">)</span>
            <span class="n">layers</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">result_lst</span>

        <span class="k">return</span> <span class="n">result_lst</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></div>

    <span class="k">def</span> <span class="nf">_canonicalize_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                            <span class="n">layer1</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ParamNode</span><span class="p">],</span>
                            <span class="n">layer2</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ParamNode</span><span class="p">],</span>
                            <span class="n">mode</span><span class="p">:</span> <span class="n">Text</span> <span class="o">=</span> <span class="s1">&#39;svd&#39;</span><span class="p">,</span>
                            <span class="n">rank</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                            <span class="n">cum_percentage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                            <span class="n">cutoff</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">ParamNode</span><span class="p">],</span>
                                                                     <span class="n">List</span><span class="p">[</span><span class="n">ParamNode</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Turns each layer into canonical form, moving singular values matrices</span>
<span class="sd">        or non-isometries to the upper layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_layer1</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">new_layer2</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">layer2</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;svd&#39;</span><span class="p">:</span>
                    <span class="n">result1</span><span class="p">,</span> <span class="n">node</span> <span class="o">=</span> <span class="n">layer1</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;output&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">svd_</span><span class="p">(</span>
                        <span class="n">side</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">,</span>
                        <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
                        <span class="n">cum_percentage</span><span class="o">=</span><span class="n">cum_percentage</span><span class="p">,</span>
                        <span class="n">cutoff</span><span class="o">=</span><span class="n">cutoff</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;svdr&#39;</span><span class="p">:</span>
                    <span class="n">result1</span><span class="p">,</span> <span class="n">node</span> <span class="o">=</span> <span class="n">layer1</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;output&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">svdr_</span><span class="p">(</span>
                        <span class="n">side</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">,</span>
                        <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
                        <span class="n">cum_percentage</span><span class="o">=</span><span class="n">cum_percentage</span><span class="p">,</span>
                        <span class="n">cutoff</span><span class="o">=</span><span class="n">cutoff</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;qr&#39;</span><span class="p">:</span>
                    <span class="n">result1</span><span class="p">,</span> <span class="n">node</span> <span class="o">=</span> <span class="n">layer1</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;output&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">qr_</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`mode` can only be &quot;svd&quot;, &quot;svdr&quot; or &quot;qr&quot;&#39;</span><span class="p">)</span>

                <span class="n">new_layer1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result1</span><span class="o">.</span><span class="n">parameterize</span><span class="p">())</span>
                <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="n">new_layer2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">parameterize</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">new_layer1</span><span class="p">,</span> <span class="n">new_layer2</span>

<div class="viewcode-block" id="Tree.canonicalize"><a class="viewcode-back" href="../../../models.html#tensorkrowch.models.Tree.canonicalize">[docs]</a>    <span class="k">def</span> <span class="nf">canonicalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                     <span class="n">mode</span><span class="p">:</span> <span class="n">Text</span> <span class="o">=</span> <span class="s1">&#39;svd&#39;</span><span class="p">,</span>
                     <span class="n">rank</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                     <span class="n">cum_percentage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                     <span class="n">cutoff</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Turns Tree into canonical form via local SVD/QR decompositions, moving</span>
<span class="sd">        singular values matrices or non-isometries to the upper layers.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        mode : {&quot;svd&quot;, &quot;svdr&quot;, &quot;qr&quot;}</span>
<span class="sd">            Indicates which decomposition should be used to split a node after</span>
<span class="sd">            contracting it. See more at :func:`svd_`, :func:`svdr_`, :func:`qr_`.</span>
<span class="sd">            If mode is &quot;qr&quot;, operation :func:`qr_` will be performed on nodes at</span>
<span class="sd">            the left of the output node, whilst operation :func:`rq_` will be</span>
<span class="sd">            used for nodes at the right.</span>
<span class="sd">        rank : int, optional</span>
<span class="sd">            Number of singular values to keep.</span>
<span class="sd">        cum_percentage : float, optional</span>
<span class="sd">            Proportion that should be satisfied between the sum of all singular</span>
<span class="sd">            values kept and the total sum of all singular values.</span>
<span class="sd">            </span>
<span class="sd">            .. math::</span>
<span class="sd">            </span>
<span class="sd">                \frac{\sum_{i \in \{kept\}}{s_i}}{\sum_{i \in \{all\}}{s_i}} \ge</span>
<span class="sd">                cum\_percentage</span>
<span class="sd">        cutoff : float, optional</span>
<span class="sd">            Quantity that lower bounds singular values in order to be kept.</span>
<span class="sd">            </span>
<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; tree = tk.models.Tree(sites_per_layer=[4, 2, 1],</span>
<span class="sd">        ...                       bond_dim=[[3, 3, 4], [4, 4, 2], [2, 2, 2]])</span>
<span class="sd">        &gt;&gt;&gt; tree.canonicalize(rank=2)</span>
<span class="sd">        &gt;&gt;&gt; tree.bond_dim</span>
<span class="sd">        [[[3, 3, 2], [3, 3, 2], [3, 3, 2], [3, 3, 2]], [[2, 2, 2], [2, 2, 2]], [[2, 2, 2]]]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

            <span class="n">prev_auto_stack</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_auto_stack</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">auto_stack</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
                <span class="n">layer1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">layer2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
                <span class="n">layer1</span><span class="p">,</span> <span class="n">layer2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_canonicalize_layer</span><span class="p">(</span>
                    <span class="n">layer1</span><span class="p">,</span> <span class="n">layer2</span><span class="p">,</span>
                    <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span>
                    <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
                    <span class="n">cum_percentage</span><span class="o">=</span><span class="n">cum_percentage</span><span class="p">,</span>
                    <span class="n">cutoff</span><span class="o">=</span><span class="n">cutoff</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">layer1</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">layer2</span>

            <span class="n">bond_dim</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
                <span class="n">layer_bond_dim</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">layer</span><span class="p">:</span>
                    <span class="n">layer_bond_dim</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
                <span class="n">bond_dim</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer_bond_dim</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_bond_dim</span> <span class="o">=</span> <span class="n">bond_dim</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">auto_stack</span> <span class="o">=</span> <span class="n">prev_auto_stack</span></div></div>


<div class="viewcode-block" id="UTree"><a class="viewcode-back" href="../../../models.html#tensorkrowch.models.UTree">[docs]</a><span class="k">class</span> <span class="nc">UTree</span><span class="p">(</span><span class="n">TensorNetwork</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class for Uniform Tree States where all nodes have the same shape. It is</span>
<span class="sd">    the uniform version of :class:`Tree`, that is, all nodes share the same</span>
<span class="sd">    tensor.</span>
<span class="sd">    </span>
<span class="sd">    All nodes in the network are in ``self.layers``, a list containing the lists</span>
<span class="sd">    of nodes in each layer (starting from the bottom).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sites_per_layer : list[int] or tuple[int]</span>
<span class="sd">        Number of sites in each layer of the tree. All nodes have the same</span>
<span class="sd">        shape. Number of nodes in each layer times the number of input edges</span>
<span class="sd">        these have should match the number ot output edges in the previous</span>
<span class="sd">        layer. The last element of ``sites_per_layer`` should be always 1,</span>
<span class="sd">        which corresponds to the output node.</span>
<span class="sd">    bond_dim : list[int] or tuple[int]</span>
<span class="sd">        Bond dimensions of nodes in each layer. Since all nodes have the same</span>
<span class="sd">        shape, it is enough to pass a single sequence of dimensions (some input</span>
<span class="sd">        edges and an output edge in the last position).</span>
<span class="sd">    n_batches : int</span>
<span class="sd">        Number of batch edges of input ``data`` nodes. Usually ``n_batches = 1``</span>
<span class="sd">        (where the batch edge is used for the data batched) but it could also</span>
<span class="sd">        be ``n_batches = 2`` (one edge for data batched, other edge for image</span>
<span class="sd">        patches in convolutional layers).</span>
<span class="sd">        </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; tree = tk.models.UTree(sites_per_layer=[4, 2, 1],</span>
<span class="sd">    ...                        bond_dim=[3, 3, 3])</span>
<span class="sd">    &gt;&gt;&gt; for layer in tree.layers:</span>
<span class="sd">    ...     for node in layer:</span>
<span class="sd">    ...         assert node.tensor_address() == &#39;virtual_uniform&#39;</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; data = torch.ones(20, 8, 3) # batch_size x n_features x feature_size</span>
<span class="sd">    &gt;&gt;&gt; result = tree(data)</span>
<span class="sd">    &gt;&gt;&gt; result.shape</span>
<span class="sd">    torch.Size([20, 3])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">sites_per_layer</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
                 <span class="n">bond_dim</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
                 <span class="n">n_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;tree&#39;</span><span class="p">)</span>

        <span class="c1"># sites_per_layer</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sites_per_layer</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">sites_per_layer</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`sites_per_layer` cannot be empty, at least &#39;</span>
                                 <span class="s1">&#39;one node is required&#39;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">el</span> <span class="ow">in</span> <span class="n">sites_per_layer</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">el</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`sites_per_layer` should be a sequence of&#39;</span>
                                    <span class="s1">&#39; ints&#39;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">el</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Elements of `sites_per_layer` should be &#39;</span>
                                     <span class="s1">&#39;ints greater than 0&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">sites_per_layer</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The last element of `sites_per_layer` should &#39;</span>
                                 <span class="s1">&#39;be always 1&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`sites_per_layer` should be a sequence &#39;</span>
                            <span class="s1">&#39;(list or tuple type)&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sites_per_layer</span> <span class="o">=</span> <span class="n">sites_per_layer</span>

        <span class="c1"># bond_dim</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bond_dim</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">bond_dim</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`bond_dim` should have at least two elements, &#39;</span>
                                 <span class="s1">&#39;one for input and one for output&#39;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">el</span> <span class="ow">in</span> <span class="n">bond_dim</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">el</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`bond_dim` should be a sequence of ints&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`bond_dim` should be a sequence of ints&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_bond_dim</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">bond_dim</span><span class="p">)</span>

        <span class="c1"># n_batches</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n_batches</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`n_batches should be int type&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_batches</span> <span class="o">=</span> <span class="n">n_batches</span>

        <span class="c1"># Create Tensor Network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_make_nodes</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">sites_per_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns number of sites in each layer of the tree.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sites_per_layer</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">bond_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns bond dimensions of nodes in each layer. Since all nodes have</span>
<span class="sd">        the same shape, it is a single sequence of dimensions (some input edges</span>
<span class="sd">        and an output edge in the last position).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bond_dim</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">n_batches</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns number of batch edges of the ``data`` nodes.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_batches</span>

    <span class="k">def</span> <span class="nf">_make_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Creates all the nodes of the Tree.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_leaf_nodes</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Cannot create Tree nodes if the Tree already has&#39;</span>
                             <span class="s1">&#39; nodes&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n_sites</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_sites_per_layer</span><span class="p">):</span>
            <span class="n">layer_lst</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_sites</span><span class="p">):</span>
                <span class="n">node</span> <span class="o">=</span> <span class="n">ParamNode</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">bond_dim</span><span class="p">,),</span>
                                 <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="o">*</span><span class="p">([</span><span class="s1">&#39;input&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bond_dim</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)),</span>
                                             <span class="s1">&#39;output&#39;</span><span class="p">),</span>
                                 <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;tree_node_(</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">,</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">,</span>
                                 <span class="n">network</span><span class="o">=</span><span class="bp">self</span><span class="p">)</span>
                <span class="n">layer_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">idx_last_layer</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">layer_lst</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">_edges</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                        <span class="k">if</span> <span class="n">idx_last_layer</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
                            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;There are more input edges in &#39;</span>
                                             <span class="sa">f</span><span class="s1">&#39;layer </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> than output edges in &#39;</span>
                                             <span class="sa">f</span><span class="s1">&#39;layer </span><span class="si">{</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

                        <span class="n">edge</span> <span class="o">^</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="n">idx_last_layer</span><span class="p">][</span><span class="s1">&#39;output&#39;</span><span class="p">]</span>
                        <span class="n">idx_last_layer</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="k">if</span> <span class="n">idx_last_layer</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;There are more output edges in &#39;</span>
                                     <span class="sa">f</span><span class="s1">&#39;layer </span><span class="si">{</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="si">}</span><span class="s1"> than input edges in &#39;</span>
                                     <span class="sa">f</span><span class="s1">&#39;layer </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer_lst</span><span class="p">)</span>

        <span class="c1"># Virtual node</span>
        <span class="n">uniform_memory</span> <span class="o">=</span> <span class="n">node</span> <span class="o">=</span> <span class="n">ParamNode</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">bond_dim</span><span class="p">,),</span>
                                          <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="o">*</span><span class="p">([</span><span class="s1">&#39;input&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span>
                                                  <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bond_dim</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)),</span>
                                                      <span class="s1">&#39;output&#39;</span><span class="p">),</span>
                                          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;virtual_uniform&#39;</span><span class="p">,</span>
                                          <span class="n">network</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
                                          <span class="n">virtual</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">uniform_memory</span> <span class="o">=</span> <span class="n">uniform_memory</span>

<div class="viewcode-block" id="UTree.initialize"><a class="viewcode-back" href="../../../models.html#tensorkrowch.models.UTree.initialize">[docs]</a>    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-9</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Initializes all the nodes.&quot;&quot;&quot;</span>
        <span class="c1"># Virtual node</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">uniform_memory</span><span class="o">.</span><span class="n">_shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">std</span>
        <span class="n">tensor</span><span class="p">[(</span><span class="mi">0</span><span class="p">,)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">1.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">uniform_memory</span><span class="o">.</span><span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">layer</span><span class="p">:</span>
                <span class="n">node</span><span class="o">.</span><span class="n">set_tensor_from</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">uniform_memory</span><span class="p">)</span></div>

<div class="viewcode-block" id="UTree.set_data_nodes"><a class="viewcode-back" href="../../../models.html#tensorkrowch.models.UTree.set_data_nodes">[docs]</a>    <span class="k">def</span> <span class="nf">set_data_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates data nodes and connects each of them to the physical edge of</span>
<span class="sd">        an input node.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">input_edges</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="n">input_edges</span> <span class="o">+=</span> <span class="n">node</span><span class="o">.</span><span class="n">_edges</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">set_data_nodes</span><span class="p">(</span><span class="n">input_edges</span><span class="o">=</span><span class="n">input_edges</span><span class="p">,</span>
                               <span class="n">num_batch_edges</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_batches</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_input_contraction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                           <span class="n">layer1</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Node</span><span class="p">],</span>
                           <span class="n">layer2</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ParamNode</span><span class="p">],</span>
                           <span class="n">inline</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Node</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Contracts two consecutive layers of the tree.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">inline</span><span class="p">:</span>
            <span class="n">result_lst</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">layer2</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
                    <span class="n">node</span> <span class="o">=</span> <span class="n">layer1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">@</span> <span class="n">node</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">result_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">result_lst</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">n_input</span> <span class="o">=</span> <span class="n">layer2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="n">stack2</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">layer2</span><span class="p">)</span>

            <span class="n">layer1_stacks</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_input</span><span class="p">):</span>
                <span class="n">stack_lst</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer1</span><span class="p">),</span> <span class="n">n_input</span><span class="p">):</span>
                    <span class="n">stack_lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer1</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
                <span class="n">layer1_stacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">stack_lst</span><span class="p">))</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_input</span><span class="p">):</span>
                <span class="n">stack2</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">^</span> <span class="n">layer1_stacks</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="n">result</span> <span class="o">=</span> <span class="n">stack2</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_input</span><span class="p">):</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">layer1_stacks</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">@</span> <span class="n">result</span>

            <span class="n">result_lst</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">result_lst</span>

<div class="viewcode-block" id="UTree.contract"><a class="viewcode-back" href="../../../models.html#tensorkrowch.models.UTree.contract">[docs]</a>    <span class="k">def</span> <span class="nf">contract</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inline</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Node</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Contracts the whole Tree Tensor Network.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        inline : bool</span>
<span class="sd">            Boolean indicating whether consecutive layers should be contracted</span>
<span class="sd">            inline or in parallel (using a single stacked contraction).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Node</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_nodes</span><span class="o">.</span><span class="n">values</span><span class="p">())]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">layer1</span> <span class="o">=</span> <span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">layer2</span> <span class="o">=</span> <span class="n">layers</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">result_lst</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_contraction</span><span class="p">(</span><span class="n">layer1</span><span class="p">,</span>
                                                 <span class="n">layer2</span><span class="p">,</span>
                                                 <span class="n">inline</span><span class="o">=</span><span class="n">inline</span><span class="p">)</span>
            <span class="n">layers</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">result_lst</span>

        <span class="k">return</span> <span class="n">result_lst</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></div></div>


<div class="viewcode-block" id="ConvTree"><a class="viewcode-back" href="../../../models.html#tensorkrowch.models.ConvTree">[docs]</a><span class="k">class</span> <span class="nc">ConvTree</span><span class="p">(</span><span class="n">Tree</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class for Tree States where the input data is a batch of images. It is the</span>
<span class="sd">    convolutional version of :class:`Tree`.</span>
<span class="sd">    </span>
<span class="sd">    Input data as well as initialization parameters are described in `torch.nn.Conv2d</span>
<span class="sd">    &lt;https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html&gt;`_.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sites_per_layer : list[int] or tuple[int]</span>
<span class="sd">        Number of sites in each layer of the tree. All nodes in the same layer</span>
<span class="sd">        have the same shape. Number of nodes in each layer times the number of</span>
<span class="sd">        input edges these have should match the number ot output edges in the</span>
<span class="sd">        previous layer.</span>
<span class="sd">    bond_dim : list[list[int]] or tuple[tuple[int]]</span>
<span class="sd">        Bond dimensions of nodes in each layer. Each sequence corresponds to the</span>
<span class="sd">        shape of the nodes in each layer (some input edges and an output edge in</span>
<span class="sd">        the last position).</span>
<span class="sd">    kernel_size : int, list[int] or tuple[int]</span>
<span class="sd">        Kernel size used in `torch.nn.Unfold</span>
<span class="sd">        &lt;https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold&gt;`_.</span>
<span class="sd">        If given as an ``int``, the actual kernel size will be</span>
<span class="sd">        ``(kernel_size, kernel_size)``.</span>
<span class="sd">    stride : int</span>
<span class="sd">        Stride used in `torch.nn.Unfold</span>
<span class="sd">        &lt;https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold&gt;`_.</span>
<span class="sd">    padding : int</span>
<span class="sd">        Padding used in `torch.nn.Unfold</span>
<span class="sd">        &lt;https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold&gt;`_.</span>
<span class="sd">        If given as an ``int``, the actual kernel size will be</span>
<span class="sd">        ``(kernel_size, kernel_size)``.</span>
<span class="sd">    dilation : int</span>
<span class="sd">        Dilation used in `torch.nn.Unfold</span>
<span class="sd">        &lt;https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold&gt;`_.</span>
<span class="sd">        If given as an ``int``, the actual kernel size will be</span>
<span class="sd">        ``(kernel_size, kernel_size)``.</span>
<span class="sd">        </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; conv_tree = tk.models.ConvTree(sites_per_layer=[2, 1],</span>
<span class="sd">    ...                                bond_dim=[[2, 2, 3], [3, 3, 5]],</span>
<span class="sd">    ...                                kernel_size=2)</span>
<span class="sd">    &gt;&gt;&gt; data = torch.ones(20, 2, 2, 2) # batch_size x in_channels x height x width</span>
<span class="sd">    &gt;&gt;&gt; result = conv_tree(data)</span>
<span class="sd">    &gt;&gt;&gt; print(result.shape)</span>
<span class="sd">    torch.Size([20, 5, 1, 1])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">sites_per_layer</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
                 <span class="n">bond_dim</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
                 <span class="n">kernel_size</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">],</span>
                 <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                 <span class="n">padding</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                 <span class="n">dilation</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`kernel_size` must be int or Sequence&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">stride</span> <span class="o">=</span> <span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="n">stride</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`stride` must be int or Sequence&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">padding</span> <span class="o">=</span> <span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="n">padding</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`padding` must be int or Sequence&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dilation</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">dilation</span> <span class="o">=</span> <span class="p">(</span><span class="n">dilation</span><span class="p">,</span> <span class="n">dilation</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dilation</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`dilation` must be int or Sequence&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_padding</span> <span class="o">=</span> <span class="n">padding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dilation</span> <span class="o">=</span> <span class="n">dilation</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">sites_per_layer</span><span class="o">=</span><span class="n">sites_per_layer</span><span class="p">,</span>
                         <span class="n">bond_dim</span><span class="o">=</span><span class="n">bond_dim</span><span class="p">,</span>
                         <span class="n">n_batches</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_in_channels</span> <span class="o">=</span> <span class="n">bond_dim</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">unfold</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Unfold</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
                                <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
                                <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
                                <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">in_channels</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns ``in_channels``. Same as the first elements in ``bond_dim``</span>
<span class="sd">        from :class:`Tree`, corresponding to dimensions of the input.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_in_channels</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">kernel_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns ``kernel_size``, corresponding to number of ``data`` nodes.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_kernel_size</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">stride</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns stride used in `torch.nn.Unfold</span>
<span class="sd">        &lt;https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold&gt;`_.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stride</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">padding</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns padding used in `torch.nn.Unfold</span>
<span class="sd">        &lt;https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold&gt;`_.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_padding</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">dilation</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns dilation used in `torch.nn.Unfold</span>
<span class="sd">        &lt;https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold&gt;`_.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dilation</span>

<div class="viewcode-block" id="ConvTree.forward"><a class="viewcode-back" href="../../../models.html#tensorkrowch.models.ConvTree.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overrides ``torch.nn.Module``&#39;s forward to compute a convolution on the</span>
<span class="sd">        input image.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        image : torch.Tensor</span>
<span class="sd">            Input batch of images with shape</span>
<span class="sd">            </span>
<span class="sd">            .. math::</span>
<span class="sd">            </span>
<span class="sd">                batch\_size \times in\_channels \times height \times width</span>
<span class="sd">        args :</span>
<span class="sd">            Arguments that might be used in :meth:`~Tree.contract`.</span>
<span class="sd">        kwargs :</span>
<span class="sd">            Keyword arguments that might be used in :meth:`~Tree.contract`,</span>
<span class="sd">            like ``inline``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Input image shape: batch_size x in_channels x height x width</span>

        <span class="n">patches</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="n">image</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># batch_size x nb_windows x (in_channels * nb_pixels)</span>

        <span class="n">patches</span> <span class="o">=</span> <span class="n">patches</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">patches</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># batch_size x nb_windows x in_channels x nb_pixels</span>

        <span class="n">patches</span> <span class="o">=</span> <span class="n">patches</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="c1"># batch_size x nb_windows x nb_pixels x in_channels</span>

        <span class="n">result</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">patches</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># batch_size x nb_windows x out_channels</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># batch_size x out_channels x nb_windows</span>

        <span class="n">h_in</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">w_in</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>

        <span class="n">h_out</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">h_in</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span>
                     <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">w_out</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">w_in</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span>
                     <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">result</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">h_out</span><span class="p">,</span> <span class="n">w_out</span><span class="p">)</span>
        <span class="c1"># batch_size x out_channels x height_out x width_out</span>

        <span class="k">return</span> <span class="n">result</span></div></div>


<div class="viewcode-block" id="ConvUTree"><a class="viewcode-back" href="../../../models.html#tensorkrowch.models.ConvUTree">[docs]</a><span class="k">class</span> <span class="nc">ConvUTree</span><span class="p">(</span><span class="n">UTree</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class for Uniform Tree States where the input data is a batch of images. It</span>
<span class="sd">    is the convolutional version of :class:`UTree`.</span>
<span class="sd">    </span>
<span class="sd">    Input data as well as initialization parameters are described in `torch.nn.Conv2d</span>
<span class="sd">    &lt;https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html&gt;`_.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sites_per_layer : list[int] or tuple[int]</span>
<span class="sd">        Number of sites in each layer of the tree. All nodes have the same</span>
<span class="sd">        shape. Number of nodes in each layer times the number of input edges</span>
<span class="sd">        these have should match the number ot output edges in the previous</span>
<span class="sd">        layer.</span>
<span class="sd">    bond_dim : list[int] or tuple[int]</span>
<span class="sd">        Bond dimensions of nodes in each layer. Since all nodes have the same</span>
<span class="sd">        shape, it is enough to pass a single sequence of dimensions (some input</span>
<span class="sd">        edges and an output edge in the last position).</span>
<span class="sd">    kernel_size : int, list[int] or tuple[int]</span>
<span class="sd">        Kernel size used in `torch.nn.Unfold</span>
<span class="sd">        &lt;https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold&gt;`_.</span>
<span class="sd">        If given as an ``int``, the actual kernel size will be</span>
<span class="sd">        ``(kernel_size, kernel_size)``.</span>
<span class="sd">    stride : int</span>
<span class="sd">        Stride used in `torch.nn.Unfold</span>
<span class="sd">        &lt;https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold&gt;`_.</span>
<span class="sd">    padding : int</span>
<span class="sd">        Padding used in `torch.nn.Unfold</span>
<span class="sd">        &lt;https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold&gt;`_.</span>
<span class="sd">        If given as an ``int``, the actual kernel size will be</span>
<span class="sd">        ``(kernel_size, kernel_size)``.</span>
<span class="sd">    dilation : int</span>
<span class="sd">        Dilation used in `torch.nn.Unfold</span>
<span class="sd">        &lt;https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold&gt;`_.</span>
<span class="sd">        If given as an ``int``, the actual kernel size will be</span>
<span class="sd">        ``(kernel_size, kernel_size)``.</span>
<span class="sd">        </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; conv_tree = tk.models.ConvUTree(sites_per_layer=[2, 1],</span>
<span class="sd">    ...                                 bond_dim=[2, 2, 2],</span>
<span class="sd">    ...                                 kernel_size=2)</span>
<span class="sd">    &gt;&gt;&gt; for layer in conv_tree.layers:</span>
<span class="sd">    ...     for node in layer:</span>
<span class="sd">    ...         assert node.tensor_address() == &#39;virtual_uniform&#39;</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; data = torch.ones(20, 2, 2, 2) # batch_size x in_channels x height x width</span>
<span class="sd">    &gt;&gt;&gt; result = conv_tree(data)</span>
<span class="sd">    &gt;&gt;&gt; print(result.shape)</span>
<span class="sd">    torch.Size([20, 2, 1, 1])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">sites_per_layer</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
                 <span class="n">bond_dim</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
                 <span class="n">kernel_size</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">],</span>
                 <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                 <span class="n">padding</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                 <span class="n">dilation</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`kernel_size` must be int or Sequence&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">stride</span> <span class="o">=</span> <span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="n">stride</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`stride` must be int or Sequence&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">padding</span> <span class="o">=</span> <span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="n">padding</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`padding` must be int or Sequence&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dilation</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">dilation</span> <span class="o">=</span> <span class="p">(</span><span class="n">dilation</span><span class="p">,</span> <span class="n">dilation</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dilation</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`dilation` must be int or Sequence&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_padding</span> <span class="o">=</span> <span class="n">padding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dilation</span> <span class="o">=</span> <span class="n">dilation</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">sites_per_layer</span><span class="o">=</span><span class="n">sites_per_layer</span><span class="p">,</span>
                         <span class="n">bond_dim</span><span class="o">=</span><span class="n">bond_dim</span><span class="p">,</span>
                         <span class="n">n_batches</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_in_channels</span> <span class="o">=</span> <span class="n">bond_dim</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">unfold</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Unfold</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
                                <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
                                <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
                                <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">in_channels</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns ``in_channels``. Same as the first elements in ``bond_dim``</span>
<span class="sd">        from :class:`UTree`, corresponding to dimensions of the input.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_in_channels</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">kernel_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns ``kernel_size``, corresponding to number of ``data`` nodes.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_kernel_size</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">stride</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns stride used in `torch.nn.Unfold</span>
<span class="sd">        &lt;https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold&gt;`_.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stride</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">padding</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns padding used in `torch.nn.Unfold</span>
<span class="sd">        &lt;https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold&gt;`_.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_padding</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">dilation</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns dilation used in `torch.nn.Unfold</span>
<span class="sd">        &lt;https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold&gt;`_.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dilation</span>

<div class="viewcode-block" id="ConvUTree.forward"><a class="viewcode-back" href="../../../models.html#tensorkrowch.models.ConvUTree.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Overrides ``torch.nn.Module``&#39;s forward to compute a convolution on the</span>
<span class="sd">        input image.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        image : torch.Tensor</span>
<span class="sd">            Input batch of images with shape</span>
<span class="sd">            </span>
<span class="sd">            .. math::</span>
<span class="sd">            </span>
<span class="sd">                batch\_size \times in\_channels \times height \times width</span>
<span class="sd">        args :</span>
<span class="sd">            Arguments that might be used in :meth:`~UTree.contract`.</span>
<span class="sd">        kwargs :</span>
<span class="sd">            Keyword arguments that might be used in :meth:`~UTree.contract`,</span>
<span class="sd">            like ``inline``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Input image shape: batch_size x in_channels x height x width</span>

        <span class="n">patches</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="n">image</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># batch_size x nb_windows x (in_channels * nb_pixels)</span>

        <span class="n">patches</span> <span class="o">=</span> <span class="n">patches</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">patches</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># batch_size x nb_windows x in_channels x nb_pixels</span>

        <span class="n">patches</span> <span class="o">=</span> <span class="n">patches</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="c1"># batch_size x nb_windows x nb_pixels x in_channels</span>

        <span class="n">result</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">patches</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># batch_size x nb_windows x out_channels</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># batch_size x out_channels x nb_windows</span>

        <span class="n">h_in</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">w_in</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>

        <span class="n">h_out</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">h_in</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span>
                     <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">w_out</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">w_in</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span>
                     <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">result</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">h_out</span><span class="p">,</span> <span class="n">w_out</span><span class="p">)</span>
        <span class="c1"># batch_size x out_channels x height_out x width_out</span>

        <span class="k">return</span> <span class="n">result</span></div></div>
</pre></div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By José Ramón Pareja Monturiol<br/>
  
      &copy; Copyright 2023, José Ramón Pareja Monturiol.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>