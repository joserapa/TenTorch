{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Tensorial Neural Network model\n",
    "\n",
    "This is an example of how one can combine tensor networks and neural networks\n",
    "to build hybrid models. We will create a convolutional layer whose output will be\n",
    "given to 4 MPS layers in different orderings. This model was introduced in [[GPC20']](https://arxiv.org/abs/1806.05964)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir data\n",
    "%mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorkrowch as tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FashionMNIST Dataset\n",
    "dataset_name = 'fashion_mnist'\n",
    "batch_size = 64\n",
    "image_size = 28\n",
    "input_size = image_size ** 2\n",
    "num_classes = 10\n",
    "\n",
    "# Load data\n",
    "train_dataset = datasets.FashionMNIST(root='data/',\n",
    "                                      train=True,\n",
    "                                      transform=transforms.ToTensor(),\n",
    "                                      download=True)\n",
    "test_dataset = datasets.FashionMNIST(root='data/',\n",
    "                                     train=False,\n",
    "                                     transform=transforms.ToTensor(),\n",
    "                                     download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdoElEQVR4nO3df2yV5f3G8etQ6BGkPbWU/pLCCiqoSOdQaoMgjgboMiPiNn8u4AxEVsywOg2Liu5Hui8mxmiY7h9BM0FlEYgaWbTYIq6gIISxaaVNXcHSgkx6SoGC9P7+QThbBYT74Zx+2vJ+JU9Cz3muPh8enp6L03N6N+SccwIAoIv1sR4AAHB+ooAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgoq/1AN/W0dGhxsZGpaSkKBQKWY8DAPDknFNra6tyc3PVp8/pn+d0uwJqbGxUXl6e9RgAgHO0c+dODRky5LT3d7sCSklJkXR88NTUVONpAAC+otGo8vLyYo/np5OwAlq8eLGeeuopNTU1qaCgQM8995zGjRt3xtyJb7ulpqZSQADQg53pZZSEvAnhtddeU1lZmRYuXKhPPvlEBQUFmjp1qvbs2ZOIwwEAeqCEFNDTTz+t2bNn65577tEVV1yhF154QQMGDNCLL76YiMMBAHqguBfQkSNHtHnzZhUXF//3IH36qLi4WNXV1Sft397ermg02mkDAPR+cS+gr776SseOHVNWVlan27OystTU1HTS/uXl5YpEIrGNd8ABwPnB/AdRFyxYoJaWlti2c+dO65EAAF0g7u+Cy8jIUFJSkpqbmzvd3tzcrOzs7JP2D4fDCofD8R4DANDNxf0ZUHJyssaOHauKiorYbR0dHaqoqFBRUVG8DwcA6KES8nNAZWVlmjlzpq655hqNGzdOzzzzjNra2nTPPfck4nAAgB4oIQV02223ae/evXr88cfV1NSk73//+1qzZs1Jb0wAAJy/Qs45Zz3E/4pGo4pEImppaWElBADogc72cdz8XXAAgPMTBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATMS9gJ544gmFQqFO26hRo+J9GABAD9c3EZ/0yiuv1Hvvvfffg/RNyGEAAD1YQpqhb9++ys7OTsSnBgD0Egl5DWjHjh3Kzc3V8OHDddddd6mhoeG0+7a3tysajXbaAAC9X9wLqLCwUEuXLtWaNWv0/PPPq76+XhMmTFBra+sp9y8vL1ckEolteXl58R4JANANhZxzLpEH2L9/v4YNG6ann35a995770n3t7e3q729PfZxNBpVXl6eWlpalJqamsjRAAAJEI1GFYlEzvg4nvB3B6Slpemyyy5TbW3tKe8Ph8MKh8OJHgMA0M0k/OeADhw4oLq6OuXk5CT6UACAHiTuBfTQQw+pqqpKX3zxhf7+97/rlltuUVJSku644454HwoA0IPF/Vtwu3bt0h133KF9+/Zp8ODBuv7667VhwwYNHjw43ocCAPRgcS+gV199Nd6fEgDQC7EWHADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADDR13oAoDtxznlnQqFQAiaJj6ampkC5LVu2eGdKSkoCHas7623XQ3fDMyAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmWIwU3V5HR4d3pk+fYP+36qqFJD/88EPvTGVlpXfm6quv9s5I0pIlS7wz2dnZ3pmg83WVrlqM9NixY96Z+fPne2ck6YknnvDODBo0KNCxzoRnQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAEywGCm6vaALiwbR0NDgnXn22We9M0EWuczKyvLO/OUvf/HOSNLOnTu9M3PmzPHOPPPMM96Z8ePHe2eC6qpr78svv/TO1NbWBjrW+vXrvTM333xzoGOdCc+AAAAmKCAAgAnvAlq3bp1uuukm5ebmKhQKadWqVZ3ud87p8ccfV05Ojvr376/i4mLt2LEjXvMCAHoJ7wJqa2tTQUGBFi9efMr7Fy1apGeffVYvvPCCNm7cqAsvvFBTp07V4cOHz3lYAEDv4f0mhJKSEpWUlJzyPuecnnnmGT366KOxF61efvllZWVladWqVbr99tvPbVoAQK8R19eA6uvr1dTUpOLi4thtkUhEhYWFqq6uPmWmvb1d0Wi00wYA6P3iWkBNTU2STn67aFZWVuy+bysvL1ckEolteXl58RwJANBNmb8LbsGCBWppaYltQX7+AADQ88S1gLKzsyVJzc3NnW5vbm6O3fdt4XBYqampnTYAQO8X1wLKz89Xdna2KioqYrdFo1Ft3LhRRUVF8TwUAKCH834X3IEDBzotAVFfX6+tW7cqPT1dQ4cO1fz58/X73/9el156qfLz8/XYY48pNzdX06dPj+fcAIAezruANm3apBtvvDH2cVlZmSRp5syZWrp0qR5++GG1tbVpzpw52r9/v66//nqtWbNGF1xwQfymBgD0eCEXZFXEBIpGo4pEImppaTnvXw/qqn+aUCjUJccJ6nTvoPwuf/3rXwMd63+/fXy2gizC+fbbb3tnPvzwQ+9MkAVMJWngwIHema1bt3pnWltbvTPp6enemZ/97GfeGUmaNGmSd+abb77xzrz44ovembS0NO+MFOz8/eEPf/Da/2wfx83fBQcAOD9RQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAEx029Wwv/76a6/VsPv08e/SbvZXP0l3X6X6P//5j3fmjTfe8M4sW7bMOzNhwgTvjCTNmDHDO/PRRx95Zz744APvzHXXXeed8V3F+IQrrrjCO3PgwAHvTJCv28bGRu9MkFW3JSkpKalLMikpKd6ZINeDFOzf6aWXXvLaPxqN6uKLL2Y1bABA90QBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMBEX+sBTicUCiV8Mc7uvthnEAcPHvTOPPXUU4GOtX79eu9MXl6ed+bHP/6xd6a2ttY7I0llZWXemV/84hfemSCLcEajUe/M3Xff7Z2RpD//+c/emauvvto7c+jQIe9MUVGRdyY5Odk7I0ltbW3embS0NO/MN998450JsuipJO3du9c743sezvZxiGdAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATJzXi5EGVVdX55354IMPvDOVlZXemUgk4p0ZPHiwd0aSfv7zn3tngiyEuG7dOu9MRkaGd0aSRo0a5Z3Zt2+fd+bSSy/1zrz++uvemZ/+9KfeGSnYefj000+9M1OmTPHOHD161DsTZJFeKdjXRpBjBVmc9sILL/TOSFK/fv28M75ftwcOHDir/XgGBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwES3XYzUV2Njo3emoqIi0LE2btzonRkwYIB3ZvTo0d6ZYcOGeWeCLO4oBTsPO3bs8M7s2rXLOxONRr0zklRQUOCdeeedd7wzI0eO9M6MHTvWO/PRRx95ZyRpzJgx3pkg/7ZfffWVd+abb77xzgT5+pOkw4cPe2c6Ojq8M0eOHPHODBw40DsjSUlJSd4Z38eIs92fZ0AAABMUEADAhHcBrVu3TjfddJNyc3MVCoW0atWqTvfPmjUr9rt8TmzTpk2L17wAgF7Cu4Da2tpUUFCgxYsXn3afadOmaffu3bFt+fLl5zQkAKD38X4TQklJiUpKSr5zn3A4rOzs7MBDAQB6v4S8BlRZWanMzEyNHDlSc+fO/c5fWdze3q5oNNppAwD0fnEvoGnTpunll19WRUWF/u///k9VVVUqKSnRsWPHTrl/eXm5IpFIbMvLy4v3SACAbijuPwd0++23x/581VVXacyYMRoxYoQqKys1efLkk/ZfsGCBysrKYh9Ho1FKCADOAwl/G/bw4cOVkZGh2traU94fDoeVmpraaQMA9H4JL6Bdu3Zp3759ysnJSfShAAA9iPe34A4cONDp2Ux9fb22bt2q9PR0paen68knn9Stt96q7Oxs1dXV6eGHH9Yll1yiqVOnxnVwAEDP5l1AmzZt0o033hj7+MTrNzNnztTzzz+vbdu26aWXXtL+/fuVm5urKVOm6He/+53C4XD8pgYA9HjeBTRp0iQ55057/9/+9rdzGuiE/fv3ey3q9/bbb3sfo0+fYN+BvOaaa7wzQV7bOnTokHfm888/98588cUX3hkp2AKPQc55kMUng/6dgpzzvXv3emeCLD6Zn5/vnbngggu8M9Lx73T4Gj58uHfmdK8Nf5dLLrnEOxP0PARZjPR07/j9LkGuh5aWFu+MFOx6zcjI8Nr/bJ9wsBYcAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMBE3H8ld7x8/PHHXqstr1ixwvsYgwYN8s5IwVbWTUpK8s74rkArSbm5ud6Zyy+/3DsjSV9//bV3ZsKECd6ZIOfu448/9s5IwVaBrqur884kJyd7Z6644grvTFZWlndGCrZ6e5Brr6GhwTtz9OhR78xFF13knZGCrfgeCoW8M0FWfA9yrUrSyJEjvTO+/7bRaPSs9uMZEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABPddjHS4uJirwUR//nPf3ofo7Gx0TsjSV9++aV3pr293Tvz4osvemeCLJT6wx/+0DsjBVtAMT093TszePBg78yRI0e8M1KwBR6Li4u9M0EWx4xEIt6Z1tZW74wkff7554Fyvr744gvvzNkudPm//vGPf3hnJKmlpcU7c+zYMe9MR0eHdyboIsKffvqpd8b36+ls9+cZEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMh55yzHuJ/RaNRRSIRtbS0eC1G2t0dOnTIOxNkIcSamhrvTJCFXKVgi7I2NTV5Z5KSkrwzycnJ3hkp2EKSffr4/z+uq77sgswmBVvMtW9f/7WNg/zbdtVxJCkjI8M7k5KS4p3JzMz0zqSlpXlnJGnIkCHeGd+FT8/2cZxnQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAEz4r+qHQPr3798lmezsbO/MDTfc4J0BgHPFMyAAgAkKCABgwquAysvLde211yolJUWZmZmaPn36Sb9/5vDhwyotLdWgQYM0cOBA3XrrrWpubo7r0ACAns+rgKqqqlRaWqoNGzbo3Xff1dGjRzVlyhS1tbXF9nnggQf05ptvasWKFaqqqlJjY6NmzJgR98EBAD3bOf1G1L179yozM1NVVVWaOHGiWlpaNHjwYC1btkw/+clPJEmfffaZLr/8clVXV+u666474+fsrb8RFQDOF13yG1FP/Mro9PR0SdLmzZt19OhRFRcXx/YZNWqUhg4dqurq6lN+jvb2dkWj0U4bAKD3C1xAHR0dmj9/vsaPH6/Ro0dLkpqampScnHzS7yrPyspSU1PTKT9PeXm5IpFIbMvLyws6EgCgBwlcQKWlpdq+fbteffXVcxpgwYIFamlpiW07d+48p88HAOgZAv0g6rx58/TWW29p3bp1GjJkSOz27OxsHTlyRPv37+/0LKi5ufm0PyAZDocVDoeDjAEA6MG8ngE55zRv3jytXLlSa9euVX5+fqf7x44dq379+qmioiJ2W01NjRoaGlRUVBSfiQEAvYLXM6DS0lItW7ZMq1evVkpKSux1nUgkov79+ysSiejee+9VWVmZ0tPTlZqaqvvvv19FRUVn9Q44AMD5w+tt2KFQ6JS3L1myRLNmzZJ0/AdRH3zwQS1fvlzt7e2aOnWq/vSnP531GmW8DRsAerazfRw/p58DSgQKCAB6ti75OSAAAIKigAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACa8CKi8v17XXXquUlBRlZmZq+vTpqqmp6bTPpEmTFAqFOm333XdfXIcGAPR8XgVUVVWl0tJSbdiwQe+++66OHj2qKVOmqK2trdN+s2fP1u7du2PbokWL4jo0AKDn6+uz85o1azp9vHTpUmVmZmrz5s2aOHFi7PYBAwYoOzs7PhMCAHqlc3oNqKWlRZKUnp7e6fZXXnlFGRkZGj16tBYsWKCDBw+e9nO0t7crGo122gAAvZ/XM6D/1dHRofnz52v8+PEaPXp07PY777xTw4YNU25urrZt26ZHHnlENTU1euONN075ecrLy/Xkk08GHQMA0EOFnHMuSHDu3Ll65513tH79eg0ZMuS0+61du1aTJ09WbW2tRowYcdL97e3tam9vj30cjUaVl5enlpYWpaamBhkNAGAoGo0qEomc8XE80DOgefPm6a233tK6deu+s3wkqbCwUJJOW0DhcFjhcDjIGACAHsyrgJxzuv/++7Vy5UpVVlYqPz//jJmtW7dKknJycgINCADonbwKqLS0VMuWLdPq1auVkpKipqYmSVIkElH//v1VV1enZcuW6Uc/+pEGDRqkbdu26YEHHtDEiRM1ZsyYhPwFAAA9k9drQKFQ6JS3L1myRLNmzdLOnTt19913a/v27Wpra1NeXp5uueUWPfroo2f9es7Zfu8QANA9JeQ1oDN1VV5enqqqqnw+JQDgPMVacAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAE32tB/g255wkKRqNGk8CAAjixOP3icfz0+l2BdTa2ipJysvLM54EAHAuWltbFYlETnt/yJ2porpYR0eHGhsblZKSolAo1Om+aDSqvLw87dy5U6mpqUYT2uM8HMd5OI7zcBzn4bjucB6cc2ptbVVubq769Dn9Kz3d7hlQnz59NGTIkO/cJzU19by+wE7gPBzHeTiO83Ac5+E46/PwXc98TuBNCAAAExQQAMBEjyqgcDishQsXKhwOW49iivNwHOfhOM7DcZyH43rSeeh2b0IAAJwfetQzIABA70EBAQBMUEAAABMUEADARI8poMWLF+t73/ueLrjgAhUWFuqjjz6yHqnLPfHEEwqFQp22UaNGWY+VcOvWrdNNN92k3NxchUIhrVq1qtP9zjk9/vjjysnJUf/+/VVcXKwdO3bYDJtAZzoPs2bNOun6mDZtms2wCVJeXq5rr71WKSkpyszM1PTp01VTU9Npn8OHD6u0tFSDBg3SwIEDdeutt6q5udlo4sQ4m/MwadKkk66H++67z2jiU+sRBfTaa6+prKxMCxcu1CeffKKCggJNnTpVe/bssR6ty1155ZXavXt3bFu/fr31SAnX1tamgoICLV68+JT3L1q0SM8++6xeeOEFbdy4URdeeKGmTp2qw4cPd/GkiXWm8yBJ06ZN63R9LF++vAsnTLyqqiqVlpZqw4YNevfdd3X06FFNmTJFbW1tsX0eeOABvfnmm1qxYoWqqqrU2NioGTNmGE4df2dzHiRp9uzZna6HRYsWGU18Gq4HGDdunCstLY19fOzYMZebm+vKy8sNp+p6CxcudAUFBdZjmJLkVq5cGfu4o6PDZWdnu6eeeip22/79+104HHbLly83mLBrfPs8OOfczJkz3c0332wyj5U9e/Y4Sa6qqso5d/zfvl+/fm7FihWxfT799FMnyVVXV1uNmXDfPg/OOXfDDTe4X/3qV3ZDnYVu/wzoyJEj2rx5s4qLi2O39enTR8XFxaqurjaczMaOHTuUm5ur4cOH66677lJDQ4P1SKbq6+vV1NTU6fqIRCIqLCw8L6+PyspKZWZmauTIkZo7d6727dtnPVJCtbS0SJLS09MlSZs3b9bRo0c7XQ+jRo3S0KFDe/X18O3zcMIrr7yijIwMjR49WgsWLNDBgwctxjutbrcY6bd99dVXOnbsmLKysjrdnpWVpc8++8xoKhuFhYVaunSpRo4cqd27d+vJJ5/UhAkTtH37dqWkpFiPZ6KpqUmSTnl9nLjvfDFt2jTNmDFD+fn5qqur029+8xuVlJSourpaSUlJ1uPFXUdHh+bPn6/x48dr9OjRko5fD8nJyUpLS+u0b2++Hk51HiTpzjvv1LBhw5Sbm6tt27bpkUceUU1Njd544w3DaTvr9gWE/yopKYn9ecyYMSosLNSwYcP0+uuv69577zWcDN3B7bffHvvzVVddpTFjxmjEiBGqrKzU5MmTDSdLjNLSUm3fvv28eB30u5zuPMyZMyf256uuuko5OTmaPHmy6urqNGLEiK4e85S6/bfgMjIylJSUdNK7WJqbm5WdnW00VfeQlpamyy67TLW1tdajmDlxDXB9nGz48OHKyMjoldfHvHnz9NZbb+n999/v9OtbsrOzdeTIEe3fv7/T/r31ejjdeTiVwsJCSepW10O3L6Dk5GSNHTtWFRUVsds6OjpUUVGhoqIiw8nsHThwQHV1dcrJybEexUx+fr6ys7M7XR/RaFQbN24876+PXbt2ad++fb3q+nDOad68eVq5cqXWrl2r/Pz8TvePHTtW/fr163Q91NTUqKGhoVddD2c6D6eydetWSepe14P1uyDOxquvvurC4bBbunSp+9e//uXmzJnj0tLSXFNTk/VoXerBBx90lZWVrr6+3n344YeuuLjYZWRkuD179liPllCtra1uy5YtbsuWLU6Se/rpp92WLVvcv//9b+ecc3/84x9dWlqaW716tdu2bZu7+eabXX5+vjt06JDx5PH1XeehtbXVPfTQQ666utrV19e79957z/3gBz9wl156qTt8+LD16HEzd+5cF4lEXGVlpdu9e3dsO3jwYGyf++67zw0dOtStXbvWbdq0yRUVFbmioiLDqePvTOehtrbW/fa3v3WbNm1y9fX1bvXq1W748OFu4sSJxpN31iMKyDnnnnvuOTd06FCXnJzsxo0b5zZs2GA9Upe77bbbXE5OjktOTnYXX3yxu+2221xtba31WAn3/vvvO0knbTNnznTOHX8r9mOPPeaysrJcOBx2kydPdjU1NbZDJ8B3nYeDBw+6KVOmuMGDB7t+/fq5YcOGudmzZ/e6/6Sd6u8vyS1ZsiS2z6FDh9wvf/lLd9FFF7kBAwa4W265xe3evdtu6AQ403loaGhwEydOdOnp6S4cDrtLLrnE/frXv3YtLS22g38Lv44BAGCi278GBADonSggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJj4fxMB0CUpQ8vIAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "random_sample = torch.randint(low=0, high=len(train_dataset), size=(1,)).item()\n",
    "\n",
    "plt.imshow(train_dataset[random_sample][0].squeeze(0), cmap='Greys')\n",
    "plt.show()\n",
    "\n",
    "print(train_dataset[random_sample][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_SnakeSBS(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 bond_dim,\n",
    "                 image_size,\n",
    "                 num_classes,\n",
    "                 init_method,\n",
    "                 inline_input,\n",
    "                 inline_mats,\n",
    "                 renormalize,\n",
    "                 *args,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        # image = batch_size x in_channels x 28 x 28\n",
    "        self.cnn = nn.Conv2d(in_channels=in_channels,\n",
    "                             out_channels=6,\n",
    "                             kernel_size=5,\n",
    "                             stride=1,\n",
    "                             padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)  # 6 X 14 x 14\n",
    "        \n",
    "        self.mps_layers = nn.ModuleList()\n",
    "        for _ in range(4):\n",
    "            mps = tk.models.ConvMPSLayer(in_channels=7,\n",
    "                                         bond_dim=bond_dim,\n",
    "                                         out_channels=num_classes,\n",
    "                                         kernel_size=image_size // 2,\n",
    "                                         init_method=init_method,\n",
    "                                         *args,\n",
    "                                         **kwargs)\n",
    "            self.mps_layers.append(mps)\n",
    "        \n",
    "        self.inline_input = inline_input\n",
    "        self.inline_mats = inline_mats\n",
    "        self.renormalize = renormalize\n",
    "    \n",
    "    @staticmethod\n",
    "    def embedding(x):\n",
    "        ones = torch.ones_like(x[:, :1])\n",
    "        return torch.cat([ones, x], dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.cnn(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        flips_x = [x, x.transpose(2, 3), x.flip(2), x.transpose(2, 3).flip(2)]\n",
    "        lst_ys = []\n",
    "        for i in range(4):\n",
    "            y = self.mps_layers[i](flips_x[i],\n",
    "                                   mode='snake',\n",
    "                                   inline_input=self.inline_input,\n",
    "                                   inline_mats=self.inline_mats,\n",
    "                                   renormalize=self.renormalize)\n",
    "            lst_ys.append(y)\n",
    "        \n",
    "        y = torch.stack(lst_ys, dim=0)\n",
    "        y = y.prod(dim=0).view(-1, 10)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "output_dim = num_classes\n",
    "bond_dim = 10\n",
    "init_method = 'randn_eye' # rand, randn, randn_eye, canonical, unit\n",
    "\n",
    "# Contraction options\n",
    "inline_input = False\n",
    "inline_mats = False\n",
    "renormalize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cnn_snakes'\n",
    "cnn_snakes = CNN_SnakeSBS(in_channels=1,\n",
    "                          bond_dim=bond_dim,\n",
    "                          image_size=image_size,\n",
    "                          num_classes=num_classes,\n",
    "                          init_method=init_method,\n",
    "                          inline_input=inline_input,\n",
    "                          inline_mats=inline_mats,\n",
    "                          renormalize=renormalize,\n",
    "                          std=1e-6)  # This can be changed or ignored\n",
    "cnn_snakes = cnn_snakes.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace MPSs in model\n",
    "for mps in cnn_snakes.mps_layers:\n",
    "    mps.trace(torch.zeros(1, 7, image_size // 2, image_size // 2).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-6\n",
    "num_epochs = 10\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_snakes.parameters(),\n",
    "                       lr=learning_rate,\n",
    "                       weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on training & test to see how good our model is\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "        \n",
    "        accuracy = float(num_correct) / float(num_samples) * 100\n",
    "    model.train()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 1   => Train. Acc.: 80.64, Test Acc.: 79.98\n",
      "* Epoch 2   => Train. Acc.: 85.18, Test Acc.: 83.80\n",
      "* Epoch 3   => Train. Acc.: 85.38, Test Acc.: 84.17\n",
      "* Epoch 4   => Train. Acc.: 87.40, Test Acc.: 86.35\n",
      "* Epoch 5   => Train. Acc.: 87.38, Test Acc.: 85.88\n",
      "* Epoch 6   => Train. Acc.: 88.33, Test Acc.: 86.81\n",
      "* Epoch 7   => Train. Acc.: 89.28, Test Acc.: 87.95\n",
      "* Epoch 8   => Train. Acc.: 89.16, Test Acc.: 87.55\n",
      "* Epoch 9   => Train. Acc.: 89.50, Test Acc.: 88.22\n",
      "* Epoch 10  => Train. Acc.: 88.45, Test Acc.: 86.86\n"
     ]
    }
   ],
   "source": [
    "# Train network\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        scores = cnn_snakes(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient descent\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_acc = check_accuracy(train_loader, cnn_snakes)\n",
    "    test_acc = check_accuracy(test_loader, cnn_snakes)\n",
    "    \n",
    "    print(f'* Epoch {epoch + 1:<3} => Train. Acc.: {train_acc:.2f},'\n",
    "          f' Test Acc.: {test_acc:.2f}')\n",
    "\n",
    "# Reset before saving the model\n",
    "for mps in cnn_snakes.mps_layers:\n",
    "    mps.reset()\n",
    "torch.save(cnn_snakes.state_dict(), f'models/{model_name}_{dataset_name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_params(model):\n",
    "    n = 0\n",
    "    for p in model.parameters():\n",
    "        n += p.numel()\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86.98, 553036)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = n_params(cnn_snakes)\n",
    "test_acc = check_accuracy(test_loader, cnn_snakes)\n",
    "test_acc, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mps in cnn_snakes.mps_layers:\n",
    "    mps.canonicalize(cum_percentage=0.99, renormalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86.61, 462803)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = n_params(cnn_snakes)\n",
    "test_acc = check_accuracy(test_loader, cnn_snakes)\n",
    "test_acc, n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_tk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
