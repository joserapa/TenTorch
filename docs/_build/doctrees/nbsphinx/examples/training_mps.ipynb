{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training MPS in different ways\n",
    "\n",
    "Here we show different configurations for training MPS models. One can try\n",
    "different combinations of initializations and embeddings to look for the best\n",
    "model for a certain dataset.\n",
    "\n",
    "With this code, one can reproduce the results from [[SS16']](https://arxiv.org/abs/1605.05775)\n",
    "and [[NTO16']](https://arxiv.org/abs/1605.03795), although training is performed\n",
    "by optimizing all MPS cores at the same time, in contrast with the DMRG-like\n",
    "approach of the first reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir data\n",
    "%mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorkrowch as tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Dataset\n",
    "dataset_name = 'mnist'\n",
    "batch_size = 64\n",
    "image_size = 28\n",
    "input_size = image_size ** 2\n",
    "num_classes = 10\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Resize(image_size, antialias=True),\n",
    "                               ])\n",
    "\n",
    "# Load data\n",
    "train_dataset = datasets.MNIST(root='data/',\n",
    "                               train=True,\n",
    "                               transform=transform,\n",
    "                               download=True)\n",
    "test_dataset = datasets.MNIST(root='data/',\n",
    "                              train=False,\n",
    "                              transform=transform,\n",
    "                              download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "random_sample = torch.randint(low=0, high=len(train_dataset), size=(1,)).item()\n",
    "\n",
    "plt.imshow(train_dataset[random_sample][0].squeeze(0), cmap='Greys')\n",
    "plt.show()\n",
    "\n",
    "print(train_dataset[random_sample][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate MPS models\n",
    "\n",
    "One can choose between different initialization schemes, as well as different\n",
    "contraction options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "embedding_dim = 3\n",
    "output_dim = num_classes\n",
    "bond_dim = 10\n",
    "init_method = 'randn_eye' # rand, randn, randn_eye, canonical, unit\n",
    "\n",
    "# Contraction options\n",
    "inline_input = False\n",
    "inline_mats = False\n",
    "renormalize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize network\n",
    "model_name = 'mps'\n",
    "mps = tk.models.MPSLayer(n_features=input_size + 1,\n",
    "                         in_dim=embedding_dim,\n",
    "                         out_dim=num_classes,\n",
    "                         bond_dim=bond_dim,\n",
    "                         boundary='obc',\n",
    "                         init_method=init_method,\n",
    "                         std=1e-6,  # This can be changed or ignored\n",
    "                         device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose an embedding, which may depend on the choice of the `init_method`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding(x):\n",
    "    x = tk.embeddings.poly(x, degree=embedding_dim - 1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding(x):\n",
    "    x = tk.embeddings.unit(x, dim=embedding_dim)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding(x):\n",
    "    x = tk.embeddings.discretize(x, base=embedding_dim, level=1).squeeze(-1).int()\n",
    "    x = tk.embeddings.basis(x, dim=embedding_dim).float() # batch x n_features x dim\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace the model to accelerate training\n",
    "mps.trace(torch.zeros(1, input_size, embedding_dim, device=device),\n",
    "          inline_input=inline_input,\n",
    "          inline_mats=inline_mats,\n",
    "          renormalize=renormalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-6\n",
    "num_epochs = 10\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mps.parameters(),\n",
    "                       lr=learning_rate,\n",
    "                       weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on training & test to see how good our model is\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "            \n",
    "            scores = model(embedding(x),\n",
    "                           inline_input=inline_input,\n",
    "                           inline_mats=inline_mats,\n",
    "                           renormalize=renormalize)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "        \n",
    "        accuracy = float(num_correct) / float(num_samples) * 100\n",
    "    model.train()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 1   => Train. Acc.: 92.03, Test Acc.: 91.79\n",
      "* Epoch 2   => Train. Acc.: 96.01, Test Acc.: 95.74\n",
      "* Epoch 3   => Train. Acc.: 97.52, Test Acc.: 97.12\n",
      "* Epoch 4   => Train. Acc.: 97.93, Test Acc.: 97.55\n",
      "* Epoch 5   => Train. Acc.: 97.67, Test Acc.: 96.92\n",
      "* Epoch 6   => Train. Acc.: 98.09, Test Acc.: 97.21\n",
      "* Epoch 7   => Train. Acc.: 98.40, Test Acc.: 97.57\n",
      "* Epoch 8   => Train. Acc.: 98.58, Test Acc.: 97.55\n",
      "* Epoch 9   => Train. Acc.: 98.84, Test Acc.: 97.83\n",
      "* Epoch 10  => Train. Acc.: 98.69, Test Acc.: 97.76\n"
     ]
    }
   ],
   "source": [
    "# Train network\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Get to correct shape\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "        \n",
    "        # Forward\n",
    "        scores = mps(embedding(data),\n",
    "                     inline_input=inline_input,\n",
    "                     inline_mats=inline_mats,\n",
    "                     renormalize=renormalize)\n",
    "        loss = criterion(scores, targets)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient descent\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_acc = check_accuracy(train_loader, mps)\n",
    "    test_acc = check_accuracy(test_loader, mps)\n",
    "    \n",
    "    print(f'* Epoch {epoch + 1:<3} => Train. Acc.: {train_acc:.2f},'\n",
    "          f' Test Acc.: {test_acc:.2f}')\n",
    "\n",
    "# Reset before saving the model\n",
    "mps.reset()\n",
    "torch.save(mps.state_dict(), f'models/{model_name}_{dataset_name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_params(model):\n",
    "    n = 0\n",
    "    for p in model.parameters():\n",
    "        n += p.numel()\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97.76, 236220)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = n_params(mps)\n",
    "test_acc = check_accuracy(test_loader, mps)\n",
    "test_acc, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune and retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load network\n",
    "mps = tk.models.MPSLayer(n_features=input_size + 1,\n",
    "                         in_dim=embedding_dim,\n",
    "                         out_dim=num_classes,\n",
    "                         bond_dim=bond_dim,\n",
    "                         boundary='obc',\n",
    "                         device=device)\n",
    "mps.load_state_dict(torch.load(f'models/{model_name}_{dataset_name}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mps.canonicalize(cum_percentage=0.98, renormalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93.4, 159962)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = n_params(mps)\n",
    "test_acc = check_accuracy(test_loader, mps)\n",
    "test_acc, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bond_dim = mps.bond_dim\n",
    "\n",
    "# Contraction options\n",
    "inline_input = False\n",
    "inline_mats = True\n",
    "renormalize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace the model to accelerate training\n",
    "mps.trace(torch.zeros(1, input_size, embedding_dim, device=device),\n",
    "          inline_input=inline_input,\n",
    "          inline_mats=inline_mats,\n",
    "          renormalize=renormalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-6\n",
    "num_epochs = 1\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mps.parameters(),\n",
    "                       lr=learning_rate,\n",
    "                       weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 1   => Train. Acc.: 98.65, Test Acc.: 97.72\n"
     ]
    }
   ],
   "source": [
    "# Train network\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Get to correct shape\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "        \n",
    "        # Forward\n",
    "        scores = mps(embedding(data),\n",
    "                     inline_input=inline_input,\n",
    "                     inline_mats=inline_mats,\n",
    "                     renormalize=renormalize)\n",
    "        loss = criterion(scores, targets)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient descent\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_acc = check_accuracy(train_loader, mps)\n",
    "    test_acc = check_accuracy(test_loader, mps)\n",
    "    \n",
    "    print(f'* Epoch {epoch + 1:<3} => Train. Acc.: {train_acc:.2f},'\n",
    "          f' Test Acc.: {test_acc:.2f}')\n",
    "\n",
    "# Reset before saving the model\n",
    "mps.reset()\n",
    "# torch.save(mps.state_dict(), f'models/{model_name}_{dataset_name}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can prune and retrain the model again, repeating the process until *convergence*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mps.canonicalize(cum_percentage=0.98, renormalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97.72, 159674)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = n_params(mps)\n",
    "test_acc = check_accuracy(test_loader, mps)\n",
    "test_acc, n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_tk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
